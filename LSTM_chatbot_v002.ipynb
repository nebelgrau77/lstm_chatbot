{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaf389c-7ea8-4635-838f-8fc9c9984e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /shared/home/u076079/.local/lib/python3.8/site-packages (8.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (6.17.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (8.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /shared/home/u076079/.local/lib/python3.8/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /shared/home/u076079/.local/lib/python3.8/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.31)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (2.13.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /usr/lib/python3/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.8)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cac7a65-ec61-41de-b1b3-2e4b948878af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b268895-2c44-4e5e-b670-fe5afa5e483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/u076079/envs/LSTM_torch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9638f7f9-9f5d-4b07-b1f8-bc606d72a5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu116'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbed174-194d-4c25-96cc-5e1edb7c328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9581050a-b891-4dd7-bad9-33831d6b5688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfb1200-1c60-4adc-a8da-8ef0e15b57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8329a5c-c38e-4972-ac41-9f62a99e5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a595278-1d94-4a2b-bf14-8bd33cf3d286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d2581e-1792-4661-8bc5-d69f0c431183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import SQuAD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136c9494-58b0-467e-a3ed-299f5d74ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = SQuAD1(\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d556db-92d3-4fb8-bd37-b7859e661c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /shared/home/u076079/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /shared/home/u076079/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /shared/home/u076079/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from modules.data import get_dataframe,  get_pairs_from_df, cols, sample_df_perc, get_thresholds, get_outliers, tokenize_sentence, remove_least_common, to_tensor,  filter_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b3ff98-f08c-4dd4-823f-517c04d18954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test dataframes of sentences\n",
    "train_df, test_df = get_dataframe(train), get_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ea0c62-1f46-4d6c-b2e5-24be9f2391ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sample_df_perc(train_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b23621-67b7-48aa-ba11-a3e596837a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sample_df_perc(test_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8730f375-d6ed-4967-95dc-0a51ab303b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17519, 2), (2114, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1890f013-d804-4aa2-9909-d4cfcbf4ff80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What language family is Somali a part of?</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For what was most of the the Bitumont plant's ...</td>\n",
       "      <td>roofs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did the financial institution crisis hit ...</td>\n",
       "      <td>September and October 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which cost less in stores: PS3 or Wii?</td>\n",
       "      <td>Wii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the alternate name of Chuck Ford Park?</td>\n",
       "      <td>Lakeside Park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0          What language family is Somali a part of?   \n",
       "1  For what was most of the the Bitumont plant's ...   \n",
       "2  When did the financial institution crisis hit ...   \n",
       "3             Which cost less in stores: PS3 or Wii?   \n",
       "4     What is the alternate name of Chuck Ford Park?   \n",
       "\n",
       "                       Answer  \n",
       "0                Afro-Asiatic  \n",
       "1                       roofs  \n",
       "2  September and October 2008  \n",
       "3                         Wii  \n",
       "4               Lakeside Park  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34317e15-c531-4fe8-af27-cfbce8348003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What region of the Philippines has a large Muslim population?\n",
      "['what', 'region', 'philippines', 'large', 'muslim', 'population']\n",
      "['what', 'region', 'philippin', 'larg', 'muslim', 'popul']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "rand_question = train_df.at[random.randint(0,train_df.shape[0]), 'Question']\n",
    "print(rand_question)\n",
    "\n",
    "print(tokenize_sentence(rand_question))\n",
    "print(tokenize_sentence(rand_question, normalization='stem'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42619f3-808a-4386-b814-29b605b45eb0",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8074228e-0725-49b0-994c-0a6a7f2c3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211b3a2-cc03-4742-8cc6-bb700b1efbf3",
   "metadata": {},
   "source": [
    "## Make pairs to add to the vocabularies. \n",
    "\n",
    "#### Only the questions will be normalized (stemmed) but not the answers - otherwise we would get stemmed words in the chatbot answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05a5fafb-9725-4dfc-b2fd-95be53922126",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, norm in zip(cols, ['stem', None]):\n",
    "    train_df[f'{col}_tokens'] = train_df[col].apply(lambda s: tokenize_sentence(s, normalization=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c54bd574-67e0-462c-97e8-9cb0e039ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, norm in zip(cols, ['stem', None]):\n",
    "    test_df[f'{col}_tokens'] = test_df[col].apply(lambda s: tokenize_sentence(s, normalization=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22dc471e-79f9-4803-95f5-9f9cc75fa245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_tokens</th>\n",
       "      <th>Answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13865</th>\n",
       "      <td>What was the new Ottoman court system known as?</td>\n",
       "      <td>Nizamiye</td>\n",
       "      <td>[what, new, ottoman, court, system, known]</td>\n",
       "      <td>[nizamiye]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>When in his life did Spielberg 'feel like an a...</td>\n",
       "      <td>during childhood</td>\n",
       "      <td>[when, life, spielberg, feel, like, alien]</td>\n",
       "      <td>[childhood]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11295</th>\n",
       "      <td>Which theory proposes that adults and adolesce...</td>\n",
       "      <td>behavioral decision-making theory</td>\n",
       "      <td>[which, theori, propos, adult, adolesc, weigh,...</td>\n",
       "      <td>[behavioral, decisionmaking, theory]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "13865    What was the new Ottoman court system known as?   \n",
       "10359  When in his life did Spielberg 'feel like an a...   \n",
       "11295  Which theory proposes that adults and adolesce...   \n",
       "\n",
       "                                  Answer  \\\n",
       "13865                           Nizamiye   \n",
       "10359                   during childhood   \n",
       "11295  behavioral decision-making theory   \n",
       "\n",
       "                                         Question_tokens  \\\n",
       "13865         [what, new, ottoman, court, system, known]   \n",
       "10359         [when, life, spielberg, feel, like, alien]   \n",
       "11295  [which, theori, propos, adult, adolesc, weigh,...   \n",
       "\n",
       "                              Answer_tokens  \n",
       "13865                            [nizamiye]  \n",
       "10359                           [childhood]  \n",
       "11295  [behavioral, decisionmaking, theory]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7db09e17-4729-452b-9a87-7648a8e62570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_tokens</th>\n",
       "      <th>Answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>In what year was same-sex marriage legalized n...</td>\n",
       "      <td>2016</td>\n",
       "      <td>[what, year, samesex, marriag, legal, nationwid]</td>\n",
       "      <td>[2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>How old was Peyton Manning when he played in S...</td>\n",
       "      <td>39</td>\n",
       "      <td>[how, old, peyton, man, when, play, super, bow...</td>\n",
       "      <td>[39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>What was the name for the new radio concept de...</td>\n",
       "      <td>LOVE Radio</td>\n",
       "      <td>[what, name, new, radio, concept, design, alle...</td>\n",
       "      <td>[love, radio]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question      Answer  \\\n",
       "1912  In what year was same-sex marriage legalized n...        2016   \n",
       "1542  How old was Peyton Manning when he played in S...          39   \n",
       "1469  What was the name for the new radio concept de...  LOVE Radio   \n",
       "\n",
       "                                        Question_tokens  Answer_tokens  \n",
       "1912   [what, year, samesex, marriag, legal, nationwid]         [2016]  \n",
       "1542  [how, old, peyton, man, when, play, super, bow...           [39]  \n",
       "1469  [what, name, new, radio, concept, design, alle...  [love, radio]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24afe769-580f-4867-acfd-d7bb226fa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tokens = [f'{col}_tokens' for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9b0972b-6e60-4f80-838d-07e0237f71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = get_pairs_from_df(train_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c48f3440-c41a-4bad-bed0-b0c02eabc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = get_pairs_from_df(test_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a45c26b-0c95-4e47-88ca-786e39fe9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_vocab, A_vocab = Vocab(), Vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0445aeef-c890-416d-b920-8a818e27917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in train_pairs:\n",
    "    Q_vocab.add_sentence(pair.question)\n",
    "    A_vocab.add_sentence(pair.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea9d035a-0692-48cb-97be-d79d34f6caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13051, 15991)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.n_words, A_vocab.n_words, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c429759-d81c-4efd-abb1-d1d4a0275a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in test_pairs:\n",
    "    Q_vocab.add_sentence(pair.question)\n",
    "    A_vocab.add_sentence(pair.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "454e54b7-aaa5-4528-8661-a02ab7ccb176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13964, 17179)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.n_words, A_vocab.n_words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b59c1-0728-4b76-b34d-8509fb6a30f4",
   "metadata": {},
   "source": [
    "## Functions for some data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2587a5f-77e6-4738-9683-8b03d3c76bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.stats import sentences_stats, histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aca76fbf-fa8a-49b6-8a6c-392e276f93e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.42\n",
      "\t         median: 6.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 20)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.45\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 22)\n"
     ]
    }
   ],
   "source": [
    "# statistics for tokenized sentences\n",
    "sentences_stats(train_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0fe5a7c-8fb8-4bac-87df-402088578244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.47\n",
      "\t         median: 6.00\n",
      "\t         minimum: 2\n",
      "\t         maximum: 17)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.32\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 14)\n"
     ]
    }
   ],
   "source": [
    "# statistics for tokenized sentences\n",
    "sentences_stats(test_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414c03f-828b-4176-a329-df927df12723",
   "metadata": {},
   "source": [
    "## Remove the least common words from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b6c91a6-0c40-4898-a554-0f2fe1859806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times at most a word occurs to be considered an outlier\n",
    "outlier_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82a06d1d-9380-42c1-875a-aebc5bea498a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bitumont',\n",
       "  'waterproof',\n",
       "  'chuck',\n",
       "  'pup',\n",
       "  'finder',\n",
       "  'interrog',\n",
       "  'geeche',\n",
       "  'plini',\n",
       "  'puppi',\n",
       "  'slice',\n",
       "  '1624',\n",
       "  'architechtur',\n",
       "  'philippi',\n",
       "  'toofast',\n",
       "  'declassif',\n",
       "  'passov',\n",
       "  'shavuot',\n",
       "  'biologist',\n",
       "  'eugen',\n",
       "  'blackbird',\n",
       "  'aboard',\n",
       "  'fg',\n",
       "  'panorama',\n",
       "  'soka',\n",
       "  'gakkai',\n",
       "  'dowtown',\n",
       "  'leisur',\n",
       "  'pork',\n",
       "  'pickl',\n",
       "  'crisp',\n",
       "  'overhelm',\n",
       "  'heidegg',\n",
       "  'mildr',\n",
       "  'kemper',\n",
       "  'isoiec',\n",
       "  '138183',\n",
       "  'hardcor',\n",
       "  'techno',\n",
       "  'nun',\n",
       "  'dualshock',\n",
       "  'okinawa',\n",
       "  'solidar',\n",
       "  'wang',\n",
       "  'mang',\n",
       "  'undocu',\n",
       "  'shore',\n",
       "  'jaun',\n",
       "  'bermudez',\n",
       "  'hockfield',\n",
       "  'armagm',\n",
       "  'merton',\n",
       "  'bloem',\n",
       "  'bouquet',\n",
       "  'upanishad',\n",
       "  'antitax',\n",
       "  'geodes',\n",
       "  'ibrahim',\n",
       "  'i2a1b1',\n",
       "  'cenozo',\n",
       "  'thiazid',\n",
       "  'antihypertens',\n",
       "  'cooker',\n",
       "  'motet',\n",
       "  'wider',\n",
       "  'sputnik',\n",
       "  'inviron',\n",
       "  'serotonin',\n",
       "  'limbic',\n",
       "  'jacki',\n",
       "  'vicin',\n",
       "  'bosniaherzegovina',\n",
       "  'cleanup',\n",
       "  'shramana',\n",
       "  'berti',\n",
       "  'tidewat',\n",
       "  'conglomer',\n",
       "  'preliminari',\n",
       "  'conservat',\n",
       "  'interc',\n",
       "  'mimamsa',\n",
       "  'barri',\n",
       "  '19601970s',\n",
       "  'dawkin',\n",
       "  'milieu',\n",
       "  'stationari',\n",
       "  'olfactori',\n",
       "  'heiji',\n",
       "  'rosemari',\n",
       "  'gore',\n",
       "  'sownturn',\n",
       "  'arsacid',\n",
       "  'longev',\n",
       "  'kautilya',\n",
       "  'vishnugupta',\n",
       "  'vende',\n",
       "  'westermann',\n",
       "  'harshest',\n",
       "  'mahayanist',\n",
       "  '1781',\n",
       "  'subprim',\n",
       "  'ariarath',\n",
       "  'roderick',\n",
       "  'triumph',\n",
       "  '1330',\n",
       "  'usaaf',\n",
       "  'keoladeo',\n",
       "  'antholog',\n",
       "  'syntheism',\n",
       "  'perfer',\n",
       "  'coleoptera',\n",
       "  'prechristian',\n",
       "  '63',\n",
       "  'creditworthi',\n",
       "  'hess',\n",
       "  'nearer',\n",
       "  'intimid',\n",
       "  'educaton',\n",
       "  'chamonix',\n",
       "  'patch',\n",
       "  'elongatus',\n",
       "  'thursday',\n",
       "  'cbr',\n",
       "  'ravin',\n",
       "  'arguabl',\n",
       "  'dad',\n",
       "  'duel',\n",
       "  'magist',\n",
       "  'nielsen',\n",
       "  'richmondpetersburg',\n",
       "  'swamp',\n",
       "  'begain',\n",
       "  'twain',\n",
       "  'adjud',\n",
       "  'mysor',\n",
       "  'alexandropol',\n",
       "  'güshi',\n",
       "  'enthron',\n",
       "  'seclus',\n",
       "  'balmor',\n",
       "  'heliumneon',\n",
       "  'berechiah',\n",
       "  'wpd',\n",
       "  'tailo',\n",
       "  'trochophor',\n",
       "  'longdist',\n",
       "  'cinningham',\n",
       "  'corve',\n",
       "  'xavier',\n",
       "  '286',\n",
       "  'kjmol',\n",
       "  'preworld',\n",
       "  'yamamoto',\n",
       "  'rosarium',\n",
       "  'mirella',\n",
       "  'biano',\n",
       "  'hebron',\n",
       "  'concerto',\n",
       "  'op',\n",
       "  'mellus',\n",
       "  'christiansen',\n",
       "  'gwamil',\n",
       "  'barelona',\n",
       "  'ce',\n",
       "  'desagr',\n",
       "  'drugresist',\n",
       "  'grecolatin',\n",
       "  'fangyun',\n",
       "  'intercontinent',\n",
       "  'i95',\n",
       "  'neoeriksonian',\n",
       "  'paradigm',\n",
       "  'ellington',\n",
       "  'iowa',\n",
       "  'laurasia',\n",
       "  'clergymen',\n",
       "  'overtheair',\n",
       "  'madonlin',\n",
       "  'torah',\n",
       "  'absorpt',\n",
       "  'catholico',\n",
       "  'cilicia',\n",
       "  'deregul',\n",
       "  'terri',\n",
       "  'intransig',\n",
       "  'saltation',\n",
       "  'durham',\n",
       "  'gualdap',\n",
       "  'incept',\n",
       "  'cainhoy',\n",
       "  '1746',\n",
       "  'hydroplan',\n",
       "  'rabi',\n",
       "  'gruyer',\n",
       "  'revolunt',\n",
       "  'falekaupul',\n",
       "  'unansw',\n",
       "  'nl',\n",
       "  'rockstar',\n",
       "  'footprint',\n",
       "  'acoust',\n",
       "  'wanda',\n",
       "  'zamoyski',\n",
       "  'kunsthall',\n",
       "  'faust',\n",
       "  'margaret',\n",
       "  'reconfigur',\n",
       "  'desfil',\n",
       "  'llamada',\n",
       "  'empric',\n",
       "  'formul',\n",
       "  'arpanet',\n",
       "  'damp',\n",
       "  'bruch',\n",
       "  '1736',\n",
       "  'impract',\n",
       "  'elsi',\n",
       "  'irrig',\n",
       "  'sibera',\n",
       "  'cambrian',\n",
       "  'inerti',\n",
       "  'gloria',\n",
       "  'wilbur',\n",
       "  'escort',\n",
       "  'cremat',\n",
       "  'whitehal',\n",
       "  'lomonosov',\n",
       "  'sewer',\n",
       "  'synthpop',\n",
       "  'proceed',\n",
       "  'bilateria',\n",
       "  'templecent',\n",
       "  'eylau',\n",
       "  'mendel',\n",
       "  'baroqu',\n",
       "  'oppress',\n",
       "  'whithout',\n",
       "  'phylum',\n",
       "  'orvieto',\n",
       "  'invertedu',\n",
       "  'abolis',\n",
       "  'immunologist',\n",
       "  'grappl',\n",
       "  'counterpart',\n",
       "  'brokendamag',\n",
       "  'seto',\n",
       "  'võro',\n",
       "  'surrog',\n",
       "  'otzi',\n",
       "  'iceman',\n",
       "  'linnaeus',\n",
       "  'relativist',\n",
       "  'thereof',\n",
       "  'morrison',\n",
       "  'twickenham',\n",
       "  'subdistrict',\n",
       "  'bluebird',\n",
       "  '4404',\n",
       "  'steep',\n",
       "  'stagnat',\n",
       "  'suleiman',\n",
       "  'ppna',\n",
       "  'eritran',\n",
       "  'offlin',\n",
       "  'palladian',\n",
       "  'outrag',\n",
       "  'palai',\n",
       "  'garnier',\n",
       "  'seventh',\n",
       "  'jacobi',\n",
       "  'ccirc',\n",
       "  'gumb',\n",
       "  'coolidg',\n",
       "  'yeltsin',\n",
       "  'czechoslav',\n",
       "  'cubic',\n",
       "  'doublelay',\n",
       "  'vinegar',\n",
       "  'septuagint',\n",
       "  'gubernatori',\n",
       "  'spill',\n",
       "  'behaviori',\n",
       "  'trooper',\n",
       "  'congressmen',\n",
       "  'exam',\n",
       "  'wilber',\n",
       "  'paperwork',\n",
       "  'curonian',\n",
       "  'cypus',\n",
       "  'ashkenazim',\n",
       "  'matern',\n",
       "  'sperri',\n",
       "  '100fold',\n",
       "  'doomsday',\n",
       "  'wc',\n",
       "  'handi',\n",
       "  'ichigo',\n",
       "  'hypodesc',\n",
       "  'qiantang',\n",
       "  '1660',\n",
       "  'colonel',\n",
       "  'famer',\n",
       "  'oasi',\n",
       "  'britpop',\n",
       "  'basil',\n",
       "  'maloelap',\n",
       "  'jaluit',\n",
       "  'patrol',\n",
       "  'biospher',\n",
       "  'annapoli',\n",
       "  'biscayn',\n",
       "  'binari',\n",
       "  'boran',\n",
       "  'goat',\n",
       "  'buick',\n",
       "  'aegat',\n",
       "  'spatial',\n",
       "  'jk',\n",
       "  '20134',\n",
       "  'wrongdo',\n",
       "  'ada',\n",
       "  'hanoverian',\n",
       "  'ferranti',\n",
       "  'tetrahedr',\n",
       "  'alpha',\n",
       "  'dev',\n",
       "  '1794',\n",
       "  'writeup',\n",
       "  'hulk',\n",
       "  'hogan',\n",
       "  'cod',\n",
       "  'fisheri',\n",
       "  'mid1944',\n",
       "  '1183',\n",
       "  'interchang',\n",
       "  'undri',\n",
       "  'laurissilva',\n",
       "  'unallot',\n",
       "  'airtim',\n",
       "  'eusoci',\n",
       "  'formalist',\n",
       "  'alai',\n",
       "  'semiautobiograph',\n",
       "  '10925',\n",
       "  'nemann',\n",
       "  'workabl',\n",
       "  'atc',\n",
       "  'ot',\n",
       "  'postwar',\n",
       "  'manhatten',\n",
       "  'mario',\n",
       "  'jurisprud',\n",
       "  'wether',\n",
       "  'congoocean',\n",
       "  'chitin',\n",
       "  '5000',\n",
       "  'lenninist',\n",
       "  'starch',\n",
       "  'oshikundu',\n",
       "  'ote',\n",
       "  'nesticl',\n",
       "  'zener',\n",
       "  'uninterest',\n",
       "  'postmoderm',\n",
       "  'pal',\n",
       "  'federl',\n",
       "  'granit',\n",
       "  'semicurs',\n",
       "  'freighter',\n",
       "  'nightingal',\n",
       "  'aground',\n",
       "  'bdf',\n",
       "  '2300',\n",
       "  'pertit',\n",
       "  'algeria',\n",
       "  'maghreb',\n",
       "  'us100000',\n",
       "  'banská',\n",
       "  'akadémia',\n",
       "  'siouxsi',\n",
       "  'dodger',\n",
       "  'shevchenko',\n",
       "  'exoner',\n",
       "  'stigma',\n",
       "  'troublesom',\n",
       "  'macaron',\n",
       "  'latent',\n",
       "  'ederhecht',\n",
       "  'abkhazia',\n",
       "  'hegemoni',\n",
       "  'unrecogn',\n",
       "  'publiclyavail',\n",
       "  'info',\n",
       "  'nbs',\n",
       "  'nazisoviet',\n",
       "  'takeda',\n",
       "  '150th',\n",
       "  'ladder',\n",
       "  'braunschweig',\n",
       "  'ozark',\n",
       "  'sucros',\n",
       "  'standalon',\n",
       "  'rurik',\n",
       "  'eddington',\n",
       "  'darkey',\n",
       "  'junco',\n",
       "  'curat',\n",
       "  'ringneck',\n",
       "  'pheasant',\n",
       "  'aaronovitch',\n",
       "  'jax',\n",
       "  'juarez',\n",
       "  'pontifax',\n",
       "  'maximus',\n",
       "  'horribl',\n",
       "  'langag',\n",
       "  'brewer',\n",
       "  'wizard',\n",
       "  'scn',\n",
       "  'causal',\n",
       "  'pluck',\n",
       "  '1499',\n",
       "  'cp1251',\n",
       "  'calcutta',\n",
       "  'delo',\n",
       "  'laywer',\n",
       "  'huldah',\n",
       "  'feat',\n",
       "  'transfigur',\n",
       "  'authorit',\n",
       "  'dobruja',\n",
       "  'atherton',\n",
       "  'sidearm',\n",
       "  'haul',\n",
       "  'reimagin',\n",
       "  'jiangsu',\n",
       "  'sainti',\n",
       "  'tottenham',\n",
       "  'hotspur',\n",
       "  'whate',\n",
       "  'molest',\n",
       "  'freeview',\n",
       "  'stejpan',\n",
       "  'mesic',\n",
       "  'bounti',\n",
       "  'captian',\n",
       "  'ganjisawai',\n",
       "  '300th',\n",
       "  'sicilian',\n",
       "  'reddishbrown',\n",
       "  'streak',\n",
       "  'airplon',\n",
       "  'withdrew',\n",
       "  '976',\n",
       "  'allindia',\n",
       "  'kilmuir',\n",
       "  'xml',\n",
       "  'nonselfexecut',\n",
       "  'yahct',\n",
       "  'culinari',\n",
       "  'groban',\n",
       "  'ochr',\n",
       "  'daisi',\n",
       "  '2122',\n",
       "  'trombon',\n",
       "  'athanasian',\n",
       "  'victorien',\n",
       "  'sardous',\n",
       "  'madam',\n",
       "  'sansgên',\n",
       "  'dragonfli',\n",
       "  'spear',\n",
       "  'battista',\n",
       "  'freeman',\n",
       "  'elisabeth',\n",
       "  'bumil',\n",
       "  'clitel',\n",
       "  'tempor',\n",
       "  'κλῆς',\n",
       "  'klês',\n",
       "  'kamikaz',\n",
       "  'summerwood',\n",
       "  'faro',\n",
       "  '3kv',\n",
       "  '19151917',\n",
       "  'fisk',\n",
       "  'corridor',\n",
       "  'theyv',\n",
       "  'franciscan',\n",
       "  'friari',\n",
       "  'dasarath',\n",
       "  'rangasala',\n",
       "  'furthest',\n",
       "  '1644',\n",
       "  'carpathian',\n",
       "  'nhl',\n",
       "  'ou',\n",
       "  'gorton',\n",
       "  'dupe',\n",
       "  'palladio',\n",
       "  'kappel',\n",
       "  'bacchus',\n",
       "  'subvers',\n",
       "  'aunt',\n",
       "  'salli',\n",
       "  'bull',\n",
       "  'benetiz',\n",
       "  'procreat',\n",
       "  'ifpi',\n",
       "  'hrf',\n",
       "  'anglodutch',\n",
       "  'constantin',\n",
       "  'balus',\n",
       "  'resetar',\n",
       "  'dubrovnik',\n",
       "  'capacit',\n",
       "  'cincinnati',\n",
       "  'videocal',\n",
       "  'parerga',\n",
       "  'paralipomena',\n",
       "  'yang',\n",
       "  'sanbao',\n",
       "  'camel',\n",
       "  'nhs',\n",
       "  'frontal',\n",
       "  'denmark',\n",
       "  'anglophon',\n",
       "  'glori',\n",
       "  'gestat',\n",
       "  'purview',\n",
       "  'theo',\n",
       "  'epstein',\n",
       "  'franklin',\n",
       "  'septermb',\n",
       "  'synthesi',\n",
       "  'toy',\n",
       "  'tazz',\n",
       "  'reconquest',\n",
       "  'sheep',\n",
       "  'banknot',\n",
       "  'acadia',\n",
       "  'pronass',\n",
       "  'warlik',\n",
       "  'geopolit',\n",
       "  'crucifict',\n",
       "  'antisoci',\n",
       "  'emmett',\n",
       "  'till',\n",
       "  'homesexu',\n",
       "  'politecnici',\n",
       "  'nonmilitari',\n",
       "  'maxen',\n",
       "  'helv',\n",
       "  'tortur',\n",
       "  'empower',\n",
       "  'oca',\n",
       "  'counterpoint',\n",
       "  'fugu',\n",
       "  '400room',\n",
       "  'annoy',\n",
       "  'subsum',\n",
       "  'kakatiya',\n",
       "  'enviroment',\n",
       "  'risen',\n",
       "  'valett',\n",
       "  'soyuz',\n",
       "  'agri',\n",
       "  'decum',\n",
       "  'kondo',\n",
       "  'bangladesh',\n",
       "  'haiti',\n",
       "  'rumsfeld',\n",
       "  'heterogen',\n",
       "  'moot',\n",
       "  'smelt',\n",
       "  'ordovician',\n",
       "  'inducte',\n",
       "  'settlment',\n",
       "  'oak',\n",
       "  'jim',\n",
       "  'khetri',\n",
       "  'jhunjhunu',\n",
       "  'tottonian',\n",
       "  '155th',\n",
       "  'tessera',\n",
       "  'nelson',\n",
       "  'tongu',\n",
       "  'mc',\n",
       "  'irreligi',\n",
       "  'devon',\n",
       "  'preprocess',\n",
       "  'optimis',\n",
       "  'utopia',\n",
       "  'heisman',\n",
       "  'terra',\n",
       "  'australi',\n",
       "  'sassous',\n",
       "  'borman',\n",
       "  'lovel',\n",
       "  'ander',\n",
       "  'theft',\n",
       "  'reclam',\n",
       "  '73',\n",
       "  '1841',\n",
       "  'mistwalk',\n",
       "  'ƿ',\n",
       "  'austerlitz',\n",
       "  'jena',\n",
       "  'schauspielhaus',\n",
       "  'magellan',\n",
       "  'zeigarnik',\n",
       "  'nonstat',\n",
       "  'fachhochschulen',\n",
       "  'synnecrosi',\n",
       "  'surburban',\n",
       "  '37',\n",
       "  'huayang',\n",
       "  '500th',\n",
       "  'bahai',\n",
       "  'fairground',\n",
       "  'buget',\n",
       "  'interdict',\n",
       "  'unrestrict',\n",
       "  'enamour',\n",
       "  'pelayo',\n",
       "  'homomorph',\n",
       "  'pommel',\n",
       "  'fivepart',\n",
       "  'longmenshan',\n",
       "  'ewel',\n",
       "  'aflaq',\n",
       "  'urin',\n",
       "  'phosphoresc',\n",
       "  'magnesium',\n",
       "  'mick',\n",
       "  'cornett',\n",
       "  'smolensk',\n",
       "  'heinegg',\n",
       "  'ülküspor',\n",
       "  'satir',\n",
       "  'climacus',\n",
       "  'běidǒu',\n",
       "  'sudan',\n",
       "  'gastropub',\n",
       "  'newfronti',\n",
       "  'gang',\n",
       "  'hyacinthus',\n",
       "  '402a',\n",
       "  'medines',\n",
       "  'bilaterian',\n",
       "  'colin',\n",
       "  'campbel',\n",
       "  'alma',\n",
       "  'imf',\n",
       "  'flagcarri',\n",
       "  'simsa',\n",
       "  '24th',\n",
       "  'gettysburg',\n",
       "  'boe',\n",
       "  'robertson',\n",
       "  'dungeon',\n",
       "  'pubbas',\n",
       "  'arid',\n",
       "  'nohitt',\n",
       "  'spetemb',\n",
       "  'vmware',\n",
       "  'pteryla',\n",
       "  'deporte',\n",
       "  'gamelan',\n",
       "  'resurg',\n",
       "  'sntv',\n",
       "  'daphn',\n",
       "  'interpubl',\n",
       "  'us21',\n",
       "  'osamu',\n",
       "  'tezuka',\n",
       "  'northward',\n",
       "  'paleocen',\n",
       "  'nonmet',\n",
       "  'désiré',\n",
       "  'nowday',\n",
       "  'beauxart',\n",
       "  'unicodebas',\n",
       "  'bathsheba',\n",
       "  'postral',\n",
       "  'concess',\n",
       "  'myrtl',\n",
       "  'roundback',\n",
       "  'parousia',\n",
       "  'genit',\n",
       "  'illat',\n",
       "  'iness',\n",
       "  'elat',\n",
       "  'allat',\n",
       "  'adess',\n",
       "  'ablat',\n",
       "  '20002007',\n",
       "  'dissatisfact',\n",
       "  'photoelectr',\n",
       "  'bogl',\n",
       "  'edna',\n",
       "  'ferber',\n",
       "  'timekeep',\n",
       "  'pretti',\n",
       "  'whad',\n",
       "  'duo',\n",
       "  'yom',\n",
       "  'kippur',\n",
       "  'baena',\n",
       "  'schwarzeneggershriv',\n",
       "  'clariti',\n",
       "  'obsidian',\n",
       "  'gershwin',\n",
       "  'heyward',\n",
       "  'dietri',\n",
       "  'brightest',\n",
       "  'bethnal',\n",
       "  'muthappan',\n",
       "  'qay',\n",
       "  'trask',\n",
       "  'detat',\n",
       "  'grung',\n",
       "  'boer',\n",
       "  'counterbal',\n",
       "  '1540',\n",
       "  '195',\n",
       "  'ceefax',\n",
       "  '175556',\n",
       "  'asif',\n",
       "  'jah',\n",
       "  'beidou2',\n",
       "  'maryland',\n",
       "  'singledoubl',\n",
       "  'birch',\n",
       "  'scatter',\n",
       "  'guamanian',\n",
       "  'stipul',\n",
       "  '143',\n",
       "  'cablevis',\n",
       "  'monastic',\n",
       "  'm1',\n",
       "  'talent',\n",
       "  'ectabana',\n",
       "  'persepoli',\n",
       "  'susa',\n",
       "  'bodyguard',\n",
       "  'terrorismrel',\n",
       "  'commune',\n",
       "  'consensu',\n",
       "  'pn',\n",
       "  'japanesecoinag',\n",
       "  'procopius',\n",
       "  'sclaveni',\n",
       "  'anta',\n",
       "  'compania',\n",
       "  'tranvia',\n",
       "  'molino',\n",
       "  'cerro',\n",
       "  'kanavel',\n",
       "  'etiquett',\n",
       "  'decibel',\n",
       "  'oliv',\n",
       "  'nagdaha',\n",
       "  'ridicul',\n",
       "  'meristem',\n",
       "  'adgb',\n",
       "  'streptococci',\n",
       "  'comt',\n",
       "  'uta',\n",
       "  'stiffen',\n",
       "  'chehab',\n",
       "  'raytheon',\n",
       "  'presidio',\n",
       "  'jd',\n",
       "  'osborn',\n",
       "  'shade',\n",
       "  'gut',\n",
       "  'lawson',\n",
       "  'monophon',\n",
       "  '527',\n",
       "  'vedantin',\n",
       "  'halfway',\n",
       "  'hellgat',\n",
       "  'naturalborn',\n",
       "  'stupa',\n",
       "  '129',\n",
       "  'patronag',\n",
       "  'carrierlaunch',\n",
       "  'fliegerkorp',\n",
       "  'kms',\n",
       "  'eacg',\n",
       "  'exud',\n",
       "  'freemen',\n",
       "  'unpopular',\n",
       "  'essenc',\n",
       "  'coelom',\n",
       "  'contrabass',\n",
       "  'southbank',\n",
       "  'blockbust',\n",
       "  'ai',\n",
       "  'tsunami',\n",
       "  'cope',\n",
       "  'clube',\n",
       "  'braga',\n",
       "  'provinci',\n",
       "  'knuth',\n",
       "  'supercomput',\n",
       "  'expiat',\n",
       "  'conferenc',\n",
       "  'attun',\n",
       "  'halflif',\n",
       "  'uranium234',\n",
       "  'majerteen',\n",
       "  'coextens',\n",
       "  'widest',\n",
       "  'worldpow',\n",
       "  'kirant',\n",
       "  'mudhum',\n",
       "  'lepidus',\n",
       "  'elbow',\n",
       "  'exclusionari',\n",
       "  'pelagija',\n",
       "  'belousava',\n",
       "  'marqu',\n",
       "  'deeper',\n",
       "  'capot',\n",
       "  'cerron',\n",
       "  'mami',\n",
       "  'purs',\n",
       "  'swing',\n",
       "  'devote',\n",
       "  'vll',\n",
       "  'bosworth',\n",
       "  'adversari',\n",
       "  'slovenian',\n",
       "  'unseat',\n",
       "  'hamid',\n",
       "  'sextus',\n",
       "  'aaup',\n",
       "  'sepulchr',\n",
       "  '1040s',\n",
       "  'leon',\n",
       "  'redbon',\n",
       "  'congressman',\n",
       "  'charminar',\n",
       "  'algebra',\n",
       "  'quaternion',\n",
       "  'humbl',\n",
       "  'hygien',\n",
       "  '9050',\n",
       "  'pcled',\n",
       "  'pulcinella',\n",
       "  'zheng',\n",
       "  'filtrat',\n",
       "  'vanuatu',\n",
       "  'aryabhata',\n",
       "  'smartcamp',\n",
       "  'gemmul',\n",
       "  'semiton',\n",
       "  '1701',\n",
       "  'gastric',\n",
       "  'pagan',\n",
       "  'kraftwerk',\n",
       "  'buffalo',\n",
       "  'sabr',\n",
       "  'alarabiah',\n",
       "  'alislamiah',\n",
       "  'recover',\n",
       "  'undiscov',\n",
       "  'tempat',\n",
       "  'pavilion',\n",
       "  'automot',\n",
       "  'redirect',\n",
       "  'beam',\n",
       "  'patro',\n",
       "  'slippag',\n",
       "  'notifi',\n",
       "  'abhidharma',\n",
       "  '13053',\n",
       "  'sixyear',\n",
       "  'lockett',\n",
       "  'mandala',\n",
       "  'interconnect',\n",
       "  'pippi',\n",
       "  'sorbonn',\n",
       "  'waist',\n",
       "  'catapult',\n",
       "  'sadat',\n",
       "  'nonnat',\n",
       "  'yugoslav',\n",
       "  'stalinist',\n",
       "  'hightech',\n",
       "  'enthusiast',\n",
       "  'brasília',\n",
       "  'hg',\n",
       "  'i2a2',\n",
       "  'arisen',\n",
       "  'erector',\n",
       "  'harper',\n",
       "  'exportori',\n",
       "  'agrobusi',\n",
       "  'emerald',\n",
       "  'necklac',\n",
       "  'nabatean',\n",
       "  'tinkhundla',\n",
       "  'yengal',\n",
       "  'resent',\n",
       "  '2017',\n",
       "  'newsborn',\n",
       "  'marjon',\n",
       "  'obstic',\n",
       "  'apprim',\n",
       "  'photodermat',\n",
       "  'nausea',\n",
       "  'allerg',\n",
       "  'anaphylaxi',\n",
       "  'hyderabadi',\n",
       "  'sworn',\n",
       "  'faber',\n",
       "  'salvadoran',\n",
       "  'matsushita',\n",
       "  'shekel',\n",
       "  'mina',\n",
       "  'bon',\n",
       "  'jovi',\n",
       "  '356',\n",
       "  'lear',\n",
       "  'savaii',\n",
       "  'upolu',\n",
       "  'krispi',\n",
       "  'kreme',\n",
       "  'minster',\n",
       "  'demot',\n",
       "  '1080i25',\n",
       "  '1080i50',\n",
       "  'interlac',\n",
       "  'vase',\n",
       "  'episkyro',\n",
       "  'tern',\n",
       "  'nonbilaterian',\n",
       "  'kierkegaard',\n",
       "  'existenti',\n",
       "  'raimon',\n",
       "  'panikkar',\n",
       "  'counten',\n",
       "  'paramount',\n",
       "  'mauch',\n",
       "  'presper',\n",
       "  'eckert',\n",
       "  'eniac',\n",
       "  'memorabilia',\n",
       "  'polyth',\n",
       "  'proseccessionist',\n",
       "  'gallic',\n",
       "  'susanna',\n",
       "  'janet',\n",
       "  'nicol',\n",
       "  'slavon',\n",
       "  'luminesc',\n",
       "  'forens',\n",
       "  'subsist',\n",
       "  'mpi',\n",
       "  'hellcat',\n",
       "  'cobb',\n",
       "  'viaduct',\n",
       "  'khatchaturian',\n",
       "  'zink',\n",
       "  'mesolith',\n",
       "  'thamess',\n",
       "  '60s',\n",
       "  'stuco',\n",
       "  '713',\n",
       "  'influx',\n",
       "  'bortolazzi',\n",
       "  'strung',\n",
       "  'materia',\n",
       "  'medica',\n",
       "  'pyre',\n",
       "  'rlc',\n",
       "  'defer',\n",
       "  'mpeg25',\n",
       "  'ric',\n",
       "  'flair',\n",
       "  'http',\n",
       "  'expectaion',\n",
       "  'persona',\n",
       "  'trusteeship',\n",
       "  'taxonomi',\n",
       "  'upload',\n",
       "  'premiss',\n",
       "  'cascaj',\n",
       "  'jiadong',\n",
       "  'immacul',\n",
       "  'petrochem',\n",
       "  'summari',\n",
       "  'newpap',\n",
       "  'tabloid',\n",
       "  'licenc',\n",
       "  '20s',\n",
       "  'naitv',\n",
       "  'gurian',\n",
       "  ...],\n",
       " ['roofs',\n",
       "  'lakeside',\n",
       "  'labours',\n",
       "  'seal',\n",
       "  'gps',\n",
       "  'migrants',\n",
       "  'arrived',\n",
       "  'stayed',\n",
       "  'dock',\n",
       "  'constitutions',\n",
       "  'smoking',\n",
       "  'historia',\n",
       "  'fullscale',\n",
       "  'navigation',\n",
       "  'reception',\n",
       "  'litter',\n",
       "  'heqin',\n",
       "  'farthest',\n",
       "  'confirmation',\n",
       "  'mitzvahs',\n",
       "  'quinceañeras',\n",
       "  'sixteens',\n",
       "  'cotillions',\n",
       "  'débutante',\n",
       "  'timesharing',\n",
       "  'rosalia',\n",
       "  'dissolution',\n",
       "  'reconstitution',\n",
       "  'threedimensional',\n",
       "  'contraction',\n",
       "  'transresistance',\n",
       "  'semimourning',\n",
       "  'lagos',\n",
       "  '128000',\n",
       "  'gaze',\n",
       "  'coadaptations',\n",
       "  '8960',\n",
       "  'tricks',\n",
       "  'fenerty',\n",
       "  'deceased',\n",
       "  'tin',\n",
       "  'aggregators',\n",
       "  '1641',\n",
       "  'improvements',\n",
       "  'nightclubs',\n",
       "  'composers',\n",
       "  'iwo',\n",
       "  'jima',\n",
       "  'stimulating',\n",
       "  'snacks',\n",
       "  'bernadotte',\n",
       "  'rostislav',\n",
       "  'romanov',\n",
       "  'akiiki',\n",
       "  'nyabongo',\n",
       "  'prouille',\n",
       "  'statesbased',\n",
       "  'wwe',\n",
       "  'cheshire',\n",
       "  'rifleman',\n",
       "  'taoism',\n",
       "  'confucianism',\n",
       "  'chyme',\n",
       "  'clothes',\n",
       "  'ecstasis',\n",
       "  'douay',\n",
       "  'holt',\n",
       "  'franja',\n",
       "  'barça',\n",
       "  'gabber',\n",
       "  'vinaya',\n",
       "  'rank',\n",
       "  'observe',\n",
       "  '117000',\n",
       "  '3577',\n",
       "  'shark',\n",
       "  'ketton',\n",
       "  'floods',\n",
       "  'jokhang',\n",
       "  'lhasa',\n",
       "  'reggie',\n",
       "  'bros',\n",
       "  'bsnl',\n",
       "  'reliance',\n",
       "  'infocomm',\n",
       "  'indicom',\n",
       "  'docomo',\n",
       "  'aircel',\n",
       "  'vodafone',\n",
       "  'airtel',\n",
       "  'klaproth',\n",
       "  '1503',\n",
       "  'emergence',\n",
       "  'holism',\n",
       "  'maundy',\n",
       "  'lauterbacher',\n",
       "  'doves',\n",
       "  'bald',\n",
       "  'redtailed',\n",
       "  'hawks',\n",
       "  'pheasants',\n",
       "  'puritanism',\n",
       "  'pietism',\n",
       "  'patarini',\n",
       "  'dulcinians',\n",
       "  'waldensians',\n",
       "  '700000',\n",
       "  'bloemetje',\n",
       "  'shot',\n",
       "  'coverage',\n",
       "  'taxation',\n",
       "  'inertial',\n",
       "  'congressional',\n",
       "  'gipper',\n",
       "  'mani',\n",
       "  'heartbeat',\n",
       "  'breathing',\n",
       "  'bosniaherzegovina',\n",
       "  'osman',\n",
       "  'metamorphic',\n",
       "  'cochrane',\n",
       "  'saussure',\n",
       "  '138',\n",
       "  '272481',\n",
       "  'jamail',\n",
       "  'skatepark',\n",
       "  'spirituality',\n",
       "  '157',\n",
       "  'gamerankings',\n",
       "  'metacritic',\n",
       "  'tehran',\n",
       "  'bid',\n",
       "  'keynes',\n",
       "  'expel',\n",
       "  'homes',\n",
       "  'montmartre',\n",
       "  'corsica',\n",
       "  'sfsr',\n",
       "  'chungking',\n",
       "  'valette',\n",
       "  'belly',\n",
       "  'rituals',\n",
       "  'nonbreeding',\n",
       "  'díaz',\n",
       "  'nbcuniversal',\n",
       "  '117',\n",
       "  'internationalism',\n",
       "  'subway',\n",
       "  'tortolita',\n",
       "  'urged',\n",
       "  'buccaneer',\n",
       "  'scheduled',\n",
       "  'landbased',\n",
       "  'aeroplanes',\n",
       "  'radiate',\n",
       "  'matuszyński',\n",
       "  'fontana',\n",
       "  'austen',\n",
       "  'egg',\n",
       "  'rouge',\n",
       "  'tiridates',\n",
       "  'commutator',\n",
       "  'chāṇakya',\n",
       "  'kellermann',\n",
       "  'wornum',\n",
       "  'beheading',\n",
       "  'mujāhid',\n",
       "  'wanamaker',\n",
       "  'velbazhd',\n",
       "  'sco',\n",
       "  'dunn',\n",
       "  'traceable',\n",
       "  'phage',\n",
       "  'refillable',\n",
       "  'jug',\n",
       "  'destroyer',\n",
       "  'puppetry',\n",
       "  'tongzhi',\n",
       "  'mnemonic',\n",
       "  'gilmore',\n",
       "  'bard',\n",
       "  'söderqvist',\n",
       "  'padrón',\n",
       "  'grapevine',\n",
       "  'lampyridae',\n",
       "  'maturing',\n",
       "  'aksumites',\n",
       "  'amílcar',\n",
       "  'whalley',\n",
       "  'colder',\n",
       "  'providence',\n",
       "  'rhode',\n",
       "  'anglofrench',\n",
       "  'squadron',\n",
       "  'wolong',\n",
       "  'wade',\n",
       "  'hampton',\n",
       "  'androgen',\n",
       "  'protandry',\n",
       "  'passover',\n",
       "  'roncourt',\n",
       "  'voyage',\n",
       "  'hefner',\n",
       "  'parkway',\n",
       "  'perez',\n",
       "  'jingwei',\n",
       "  'fix',\n",
       "  'stragglers',\n",
       "  'dilys',\n",
       "  'reproduce',\n",
       "  '553950',\n",
       "  'athenian',\n",
       "  'frog',\n",
       "  'dozens',\n",
       "  'hyder',\n",
       "  'theodora',\n",
       "  'ashkenaz',\n",
       "  'riphath',\n",
       "  'togarmah',\n",
       "  'gerow',\n",
       "  'sonnet',\n",
       "  'ulrich',\n",
       "  'methodologies',\n",
       "  'mormon',\n",
       "  'obrien',\n",
       "  'soundboard',\n",
       "  'prostomium',\n",
       "  'amborellales',\n",
       "  'nymphaeales',\n",
       "  'austrobaileyales',\n",
       "  'texans',\n",
       "  'catoira',\n",
       "  'chiffchaff',\n",
       "  'phylloscopus',\n",
       "  'collybita',\n",
       "  'everyone',\n",
       "  'perhaps',\n",
       "  'servants',\n",
       "  'prominent',\n",
       "  'organisations',\n",
       "  '1552',\n",
       "  'aleutian',\n",
       "  'reporter',\n",
       "  'ulisse',\n",
       "  'aldrovandi',\n",
       "  'emphasize',\n",
       "  'tofuga',\n",
       "  'dhambalin',\n",
       "  'vivaldi',\n",
       "  'anthropomorphic',\n",
       "  'superspeed',\n",
       "  'dropping',\n",
       "  'nonessential',\n",
       "  'olaf',\n",
       "  'choir',\n",
       "  'matsapha',\n",
       "  'doctrinal',\n",
       "  'mini',\n",
       "  'hivassociated',\n",
       "  'intrasexual',\n",
       "  'fifteenth',\n",
       "  '202',\n",
       "  'sassanian',\n",
       "  'hephthalite',\n",
       "  'samanid',\n",
       "  'timurid',\n",
       "  'tenthbusiest',\n",
       "  'm27',\n",
       "  'nullsoft',\n",
       "  'commitment',\n",
       "  'countering',\n",
       "  'revenue',\n",
       "  'regalado',\n",
       "  'interpreted',\n",
       "  'sonia',\n",
       "  'sotomayor',\n",
       "  'mortise',\n",
       "  'tenon',\n",
       "  'cgcg',\n",
       "  'offering',\n",
       "  'concessions',\n",
       "  'sick',\n",
       "  'lovejoy',\n",
       "  'mitzvot',\n",
       "  'fortepiano',\n",
       "  'krikor',\n",
       "  'moussapegiants',\n",
       "  'alki',\n",
       "  'spies',\n",
       "  'painkillers',\n",
       "  'arise',\n",
       "  'videos',\n",
       "  '1128',\n",
       "  '1133',\n",
       "  'enslaved',\n",
       "  'countship',\n",
       "  'meacham',\n",
       "  'gruyère',\n",
       "  'prism',\n",
       "  'joaquín',\n",
       "  'torres',\n",
       "  'garcía',\n",
       "  'nonenglish',\n",
       "  'softwares',\n",
       "  'skirmishes',\n",
       "  '728',\n",
       "  'pelham',\n",
       "  'animalis',\n",
       "  '24764',\n",
       "  'predate',\n",
       "  'vazquez',\n",
       "  'crlf',\n",
       "  'sister',\n",
       "  'humanist',\n",
       "  'pulsed',\n",
       "  '1742',\n",
       "  'marshlands',\n",
       "  'pittite',\n",
       "  'tories',\n",
       "  '343',\n",
       "  'thailands',\n",
       "  'migrant',\n",
       "  'touched',\n",
       "  'cries',\n",
       "  'lite',\n",
       "  'imbalance',\n",
       "  'anabaptist',\n",
       "  'chasseur',\n",
       "  'à',\n",
       "  'cheval',\n",
       "  'ablow',\n",
       "  'nordstrom',\n",
       "  'saks',\n",
       "  'napalm',\n",
       "  'parkwood',\n",
       "  'yohane',\n",
       "  'denture',\n",
       "  'cream',\n",
       "  'synthesizer',\n",
       "  'pikes',\n",
       "  'deepwater',\n",
       "  'tharapita',\n",
       "  'defendants',\n",
       "  'guilt',\n",
       "  'masurians',\n",
       "  'kursenieki',\n",
       "  'lithuanians',\n",
       "  'sensors',\n",
       "  'wildcats',\n",
       "  'hillside',\n",
       "  'benevolent',\n",
       "  'accumulation',\n",
       "  'taraborrelli',\n",
       "  'jokichi',\n",
       "  'takamine',\n",
       "  'pisum',\n",
       "  'sativum',\n",
       "  'ensembles',\n",
       "  'marshallese',\n",
       "  'manually',\n",
       "  'amended',\n",
       "  'arthropod',\n",
       "  'invertedu',\n",
       "  'plantation',\n",
       "  'sharply',\n",
       "  'lps',\n",
       "  'mast',\n",
       "  'mummy',\n",
       "  'superficial',\n",
       "  'covariance',\n",
       "  'provision',\n",
       "  'shelters',\n",
       "  'refugees',\n",
       "  'portable',\n",
       "  'shellac',\n",
       "  'slightest',\n",
       "  'pollak',\n",
       "  'sure',\n",
       "  'donors',\n",
       "  'mccrory',\n",
       "  'twentyfive',\n",
       "  'refectory',\n",
       "  'mohammed',\n",
       "  'magariaf',\n",
       "  'baptisms',\n",
       "  'abdülmecid',\n",
       "  'administrators',\n",
       "  'ambitions',\n",
       "  'caged',\n",
       "  'cub',\n",
       "  'organism',\n",
       "  'humors',\n",
       "  'nagasaki',\n",
       "  'mclynn',\n",
       "  'handler',\n",
       "  'gherman',\n",
       "  'titov',\n",
       "  '3083',\n",
       "  'bluestar',\n",
       "  'discussed',\n",
       "  'try',\n",
       "  'wore',\n",
       "  'shirts',\n",
       "  'demanding',\n",
       "  'resolutions',\n",
       "  'novelty',\n",
       "  'responds',\n",
       "  'determined',\n",
       "  'mechanistic',\n",
       "  'surrey',\n",
       "  'marvin',\n",
       "  'braude',\n",
       "  'syncretist',\n",
       "  '68732',\n",
       "  '42708',\n",
       "  'speechmaking',\n",
       "  'inconsistent',\n",
       "  '262',\n",
       "  'cue',\n",
       "  'djs',\n",
       "  'mixing',\n",
       "  'photosensitive',\n",
       "  'approvals',\n",
       "  'supercapacitors',\n",
       "  'insectum',\n",
       "  'nonformal',\n",
       "  'fermented',\n",
       "  'dîledefrance',\n",
       "  'seventy',\n",
       "  'autotrophs',\n",
       "  '166',\n",
       "  'heterotrophic',\n",
       "  'rockhopper',\n",
       "  'penguins',\n",
       "  'wellesley',\n",
       "  'abel',\n",
       "  'drake',\n",
       "  'us208',\n",
       "  'patrol',\n",
       "  'wishing',\n",
       "  '647',\n",
       "  'itchen',\n",
       "  'wendt',\n",
       "  'evangelisch',\n",
       "  'utv',\n",
       "  'polymyxins',\n",
       "  'bigger',\n",
       "  'researching',\n",
       "  'paternal',\n",
       "  'endocrine',\n",
       "  'latitudes',\n",
       "  'forests',\n",
       "  'gse',\n",
       "  'investiture',\n",
       "  'm3a3',\n",
       "  'hoover',\n",
       "  'link',\n",
       "  'guerrillas',\n",
       "  'subordinate',\n",
       "  'myers',\n",
       "  'branches',\n",
       "  'e9',\n",
       "  'mundo',\n",
       "  'gallaeci',\n",
       "  'lusitanians',\n",
       "  'celtici',\n",
       "  'cynetes',\n",
       "  'angloceltic',\n",
       "  'goodman',\n",
       "  'swanky',\n",
       "  'shutters',\n",
       "  'inventors',\n",
       "  'omega6',\n",
       "  'linoleic',\n",
       "  '867',\n",
       "  'wotje',\n",
       "  'undercover',\n",
       "  'patrols',\n",
       "  'cne',\n",
       "  'comité',\n",
       "  'eleições',\n",
       "  'playground',\n",
       "  'alter',\n",
       "  'microbiota',\n",
       "  'hardly',\n",
       "  'snorkeling',\n",
       "  'scuba',\n",
       "  'diving',\n",
       "  'encompasseth',\n",
       "  'insurance',\n",
       "  'europeanamerican',\n",
       "  'homing',\n",
       "  'anchoring',\n",
       "  'tags',\n",
       "  'juscelino',\n",
       "  'kubitschek',\n",
       "  'academics',\n",
       "  'kyoto',\n",
       "  'conscience',\n",
       "  '780000',\n",
       "  'plaintiff',\n",
       "  'schaal',\n",
       "  'ainsworth',\n",
       "  'x8664',\n",
       "  'g5',\n",
       "  'école',\n",
       "  'polytechnique',\n",
       "  'myspace',\n",
       "  'audiences',\n",
       "  'repurchase',\n",
       "  'collateralised',\n",
       "  'eiffel',\n",
       "  'tertiary',\n",
       "  'anschutz',\n",
       "  'movies',\n",
       "  'barcelona',\n",
       "  'heiress',\n",
       "  'dehomag',\n",
       "  'proponents',\n",
       "  'encouraging',\n",
       "  'marquess',\n",
       "  'us9999',\n",
       "  'priority',\n",
       "  'monotheism',\n",
       "  'mid20th',\n",
       "  'udba',\n",
       "  'overloads',\n",
       "  'sorghum',\n",
       "  'mcgee',\n",
       "  'lithium',\n",
       "  'aluminosilicates',\n",
       "  'dichotomy',\n",
       "  'audial',\n",
       "  'sutta',\n",
       "  'mixedrace',\n",
       "  'salonnières',\n",
       "  'shorter',\n",
       "  'souvenir',\n",
       "  'microphonic',\n",
       "  'eastnorth',\n",
       "  'dartmoor',\n",
       "  'études',\n",
       "  'qiu',\n",
       "  'thierstein',\n",
       "  'simões',\n",
       "  'ferreira',\n",
       "  'aleksandar',\n",
       "  'matunović',\n",
       "  'kgb',\n",
       "  'petrus',\n",
       "  'pitatus',\n",
       "  'selfidentity',\n",
       "  'mauritania',\n",
       "  'depositors',\n",
       "  'yuri',\n",
       "  'gagarin',\n",
       "  'knesset',\n",
       "  'dodgers',\n",
       "  'familys',\n",
       "  'erased',\n",
       "  'samurais',\n",
       "  'austriahungary',\n",
       "  'midnovember',\n",
       "  'derivative',\n",
       "  'vibhushan',\n",
       "  'bhushan',\n",
       "  'shri',\n",
       "  'hijazi',\n",
       "  'regenerative',\n",
       "  'braking',\n",
       "  'endpoint',\n",
       "  'rory',\n",
       "  'gallagher',\n",
       "  '1840s',\n",
       "  'mahabharata',\n",
       "  'emulsion',\n",
       "  'speeds',\n",
       "  'permian',\n",
       "  'inaction',\n",
       "  'kutako',\n",
       "  'frequencies',\n",
       "  'ingur',\n",
       "  'payne',\n",
       "  'resulted',\n",
       "  'wagons',\n",
       "  'kids',\n",
       "  'cant',\n",
       "  'alliances',\n",
       "  'chinas',\n",
       "  'waged',\n",
       "  'dnieper',\n",
       "  'falsifiers',\n",
       "  'solla',\n",
       "  'teodor',\n",
       "  'llorente',\n",
       "  'searchlights',\n",
       "  'flares',\n",
       "  'eastward',\n",
       "  'landings',\n",
       "  'intend',\n",
       "  'adulthood',\n",
       "  'escaped',\n",
       "  '670',\n",
       "  'forcefield',\n",
       "  '68th',\n",
       "  'guadeloupe',\n",
       "  'martinique',\n",
       "  'chose',\n",
       "  'plympton',\n",
       "  'ale',\n",
       "  'microbrewers',\n",
       "  'replicate',\n",
       "  'glove',\n",
       "  'ganglion',\n",
       "  '68000',\n",
       "  'prettiest',\n",
       "  'swabian',\n",
       "  'kolkata',\n",
       "  'unblocked',\n",
       "  '900000',\n",
       "  'shoddy',\n",
       "  'twotone',\n",
       "  'sorrow',\n",
       "  'affliction',\n",
       "  'dissatisfaction',\n",
       "  'discomfort',\n",
       "  'anguish',\n",
       "  'misery',\n",
       "  'frustration',\n",
       "  'playlist',\n",
       "  'zionism',\n",
       "  'cadet',\n",
       "  'gallatin',\n",
       "  'maxim',\n",
       "  'litvinov',\n",
       "  'timetables',\n",
       "  'imperium',\n",
       "  'noncaucasian',\n",
       "  'blackpool',\n",
       "  'm9',\n",
       "  'expo',\n",
       "  'assumptions',\n",
       "  'racebased',\n",
       "  'obstacles',\n",
       "  'dissolved',\n",
       "  'completion',\n",
       "  'hierax',\n",
       "  'derbies',\n",
       "  'octave',\n",
       "  'niccolò',\n",
       "  'machiavelli',\n",
       "  'airborne',\n",
       "  'suspension',\n",
       "  'discussions',\n",
       "  'networkscommunications',\n",
       "  'links',\n",
       "  'akechi',\n",
       "  'mitsuhide',\n",
       "  'lugano',\n",
       "  'finger',\n",
       "  'croatian',\n",
       "  'alleles',\n",
       "  'stopped',\n",
       "  'warring',\n",
       "  'gaining',\n",
       "  'punic',\n",
       "  'guarantees',\n",
       "  'vic',\n",
       "  'silwood',\n",
       "  'seerdoctors',\n",
       "  'jax',\n",
       "  'disable',\n",
       "  'connectivity',\n",
       "  'metaphysic',\n",
       "  'forbids',\n",
       "  'sanjiang',\n",
       "  'forlanini',\n",
       "  'frontal',\n",
       "  'dorsolateral',\n",
       "  'prefrontal',\n",
       "  'parietal',\n",
       "  'scandinavia',\n",
       "  'brutal',\n",
       "  'dictatorships',\n",
       "  'sandro',\n",
       "  'pertini',\n",
       "  'constructionist',\n",
       "  'advancement',\n",
       "  'deceive',\n",
       "  'archdioceses',\n",
       "  'curia',\n",
       "  'eye',\n",
       "  'barts',\n",
       "  'dormant',\n",
       "  'documentoriented',\n",
       "  'dusenberry',\n",
       "  'protesters',\n",
       "  'yacht',\n",
       "  'crosshaven',\n",
       "  'bublé',\n",
       "  '630',\n",
       "  'orthoptera',\n",
       "  'triacastela',\n",
       "  'ratings',\n",
       "  'proving',\n",
       "  'equals',\n",
       "  'remarkable',\n",
       "  'sackbut',\n",
       "  'colts',\n",
       "  'augustines',\n",
       "  'trinitate',\n",
       "  'codec',\n",
       "  'coderdecoder',\n",
       "  'ream',\n",
       "  'rectal',\n",
       "  '70600',\n",
       "  'suicides',\n",
       "  'drunkenness',\n",
       "  'catastrophism',\n",
       "  'vírgen',\n",
       "  'socavon',\n",
       "  'fluently',\n",
       "  'hirudinomorphs',\n",
       "  'pericles',\n",
       "  'fleas',\n",
       "  'yersinia',\n",
       "  'observers',\n",
       "  'rossoneri',\n",
       "  'kv',\n",
       "  'woodbury',\n",
       "  'pleistocene',\n",
       "  'megafauna',\n",
       "  'twentyfour',\n",
       "  'bolshevist',\n",
       "  'alternations',\n",
       "  'mimo',\n",
       "  'ms',\n",
       "  'friary',\n",
       "  'gibraltar',\n",
       "  'ideology',\n",
       "  'demonstrated',\n",
       "  'continuum',\n",
       "  'tripureshwor',\n",
       "  'redbridge',\n",
       "  'fredericksburg',\n",
       "  'fearless',\n",
       "  'magyar',\n",
       "  'romanian',\n",
       "  'genitive',\n",
       "  'patronymic',\n",
       "  'unwrapped',\n",
       "  'resigned',\n",
       "  'pong',\n",
       "  'upside',\n",
       "  'lettering',\n",
       "  'coins',\n",
       "  'falaknuma',\n",
       "  'hydrolysis',\n",
       "  'preparing',\n",
       "  'publish',\n",
       "  'benetiz',\n",
       "  'testicles',\n",
       "  'combine',\n",
       "  'airfields',\n",
       "  'waterlogged',\n",
       "  'b52h',\n",
       "  'typographic',\n",
       "  'punctuation',\n",
       "  'heightfuse',\n",
       "  'hfi',\n",
       "  'midterm',\n",
       "  'donatists',\n",
       "  '1748',\n",
       "  'magnoliids',\n",
       "  'morison',\n",
       "  'mivart',\n",
       "  'jaling',\n",
       "  'tuo',\n",
       "  'yalong',\n",
       "  'jinsha',\n",
       "  'braves',\n",
       "  'videocalls',\n",
       "  'inmates',\n",
       "  'extensions',\n",
       "  'schopenhauer',\n",
       "  'allison',\n",
       "  'discussing',\n",
       "  'ailments',\n",
       "  'vaccinations',\n",
       "  'donkeys',\n",
       "  'familiar',\n",
       "  'dictionaries',\n",
       "  'excellence',\n",
       "  'calafat',\n",
       "  'democratically',\n",
       "  'smallunimportant',\n",
       "  'emphasizing',\n",
       "  'muhammadu',\n",
       "  'buhari',\n",
       "  'southsea',\n",
       "  'gosport',\n",
       "  '787',\n",
       "  'brest',\n",
       "  'monoculture',\n",
       "  'howe',\n",
       "  'atharvaveda',\n",
       "  'abbas',\n",
       "  'kiarostami',\n",
       "  'ribosomal',\n",
       "  '7375',\n",
       "  'counterinsurgency',\n",
       "  'pyotr',\n",
       "  'ilyich',\n",
       "  'tchaikovsky',\n",
       "  'turnout',\n",
       "  '16539',\n",
       "  'tazzmission',\n",
       "  'ozark',\n",
       "  'ouachita',\n",
       "  'genetics',\n",
       "  'rip',\n",
       "  'degrades',\n",
       "  'participants',\n",
       "  'items',\n",
       "  'moscardi',\n",
       "  'nd',\n",
       "  'donna',\n",
       "  'haraway',\n",
       "  'uar',\n",
       "  'zdzisław',\n",
       "  'jachimecki',\n",
       "  '249175',\n",
       "  'wash',\n",
       "  'advocacy',\n",
       "  'hussite',\n",
       "  'protestants',\n",
       "  'kalahari',\n",
       "  'chiefly',\n",
       "  'homer',\n",
       "  '40point',\n",
       "  'emotionally',\n",
       "  'invested',\n",
       "  '5262',\n",
       "  '526',\n",
       "  'daun',\n",
       "  '13000',\n",
       "  'datax',\n",
       "  'psychiatry',\n",
       "  'flogged',\n",
       "  'superstar',\n",
       "  'counterair',\n",
       "  'brahms',\n",
       "  'faced',\n",
       "  'adapt',\n",
       "  'glagolitic',\n",
       "  'missale',\n",
       "  'romanum',\n",
       "  'glagolitice',\n",
       "  '1483',\n",
       "  'skyscraper',\n",
       "  'dolby',\n",
       "  'ex',\n",
       "  'stadtstaaten',\n",
       "  'citystates',\n",
       "  'latvians',\n",
       "  'wholesale',\n",
       "  'khilji',\n",
       "  'assumes',\n",
       "  'defers',\n",
       "  'allergens',\n",
       "  'constable',\n",
       "  'ambassador',\n",
       "  'porte',\n",
       "  'vladislav',\n",
       "  'volkov',\n",
       "  'georgi',\n",
       "  'dobrovolski',\n",
       "  'viktor',\n",
       "  'patsayev',\n",
       "  'bolgia',\n",
       "  'eschatology',\n",
       "  'exclusivists',\n",
       "  'hébert',\n",
       "  'candice',\n",
       "  'glover',\n",
       "  'angelo',\n",
       "  'roncalli',\n",
       "  'wedding',\n",
       "  'precedence',\n",
       "  'achean',\n",
       "  'odyssey',\n",
       "  'nonconformist',\n",
       "  'bluishwhite',\n",
       "  'entente',\n",
       "  'algren',\n",
       "  'donation',\n",
       "  'trappers',\n",
       "  'oaks',\n",
       "  'losev',\n",
       "  'regicide',\n",
       "  'lithology',\n",
       "  'protoindoeuropean',\n",
       "  'ceasefire',\n",
       "  'machilipatnam',\n",
       "  'opus',\n",
       "  'vermiculatum',\n",
       "  'rains',\n",
       "  'denis',\n",
       "  'tuohy',\n",
       "  'mainland',\n",
       "  '7436',\n",
       "  'smartcamp',\n",
       "  'refineries',\n",
       "  'hiking',\n",
       "  'camping',\n",
       "  'birding',\n",
       "  'wintertime',\n",
       "  'snowboarding',\n",
       "  'skiing',\n",
       "  'incubation',\n",
       "  'nozick',\n",
       "  'cds',\n",
       "  'profitable',\n",
       "  'ty',\n",
       "  'detmer',\n",
       "  'enemies',\n",
       "  'sebastião',\n",
       "  'melo',\n",
       "  'prosecuted',\n",
       "  'nearultraviolet',\n",
       "  'nuv',\n",
       "  'ernesto',\n",
       "  'zedillo',\n",
       "  'cobras',\n",
       "  'halfcentury',\n",
       "  'subsaharan',\n",
       "  'vive',\n",
       "  'lempereur',\n",
       "  'orphism',\n",
       "  'purism',\n",
       "  'crosscountry',\n",
       "  'romanesque',\n",
       "  'léon',\n",
       "  'escudier',\n",
       "  'leninist',\n",
       "  'wynn',\n",
       "  'ix',\n",
       "  'wartime',\n",
       "  'ismail',\n",
       "  'ardabil',\n",
       "  'outlaw',\n",
       "  '36836',\n",
       "  '180506',\n",
       "  'sykes',\n",
       "  'picot',\n",
       "  'calorific',\n",
       "  'rays',\n",
       "  'chaillot',\n",
       "  'uncompleted',\n",
       "  'interrupted',\n",
       "  'zan',\n",
       "  'wai',\n",
       "  'pe',\n",
       "  'khin',\n",
       "  'bo',\n",
       "  'hmu',\n",
       "  'gyi',\n",
       "  'sein',\n",
       "  'mya',\n",
       "  'myoma',\n",
       "  'kywe',\n",
       "  'resolved',\n",
       "  'yù',\n",
       "  'melissa',\n",
       "  'mathison',\n",
       "  '2644',\n",
       "  'tort',\n",
       "  'mediumdensity',\n",
       "  'highdensity',\n",
       "  'preferenceeligible',\n",
       "  'archaea',\n",
       "  'pottery',\n",
       "  '542',\n",
       "  'gwyneth',\n",
       "  'paltrow',\n",
       "  '10925',\n",
       "  '1208',\n",
       "  'offlimits',\n",
       "  'lucretia',\n",
       "  'cratonisation',\n",
       "  'cantabrian',\n",
       "  'refuge',\n",
       "  'ternary',\n",
       "  'alloy',\n",
       "  'nafta',\n",
       "  'indoaustralian',\n",
       "  'eurasian',\n",
       "  'pastoralist',\n",
       "  'sheriff',\n",
       "  'singer',\n",
       "  ...])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_outliers(Q_vocab, outlier_threshold+1), get_outliers(A_vocab, outlier_threshold+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e988636e-1d1c-4b82-b62c-8e31a7f3c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_outliers, a_outliers = get_outliers(Q_vocab,outlier_threshold+1), get_outliers(A_vocab,outlier_threshold+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c4425b0-1e02-4111-9585-46a2bcbd18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = remove_least_common(train_df, cols_tokens, [q_outliers, a_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e56fe3a5-5df6-4bdf-9dc9-29f4150d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = remove_least_common(test_df, cols_tokens, [q_outliers, a_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b6aa251-97ee-4ca6-ae09-70e06de4fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.04\n",
      "\t         median: 6.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 18)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 1.90\n",
      "\t         median: 1.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 17)\n"
     ]
    }
   ],
   "source": [
    "# tokenized & least common removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958f63b-66c0-4232-859e-b35c55d32dea",
   "metadata": {},
   "source": [
    "# remove questions that have less than three words and answers that have less than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd923454-7371-4b87-9c69-aff075b52dbe",
   "metadata": {},
   "source": [
    "\n",
    "## Remove long outliers: long sentences that occure rarely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64668e14-78d8-488c-8741-f9c1068568f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = filter_sentences(train_df_final, cols_tokens, [2,0], condition='longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "996649db-3b9e-4a0c-98b6-d12cf6cc745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question_tokens 3\n",
      "Answer_tokens 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_final_thresholds = histograms(train_df_final, cols_tokens, name = 'tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbbcbdfc-4417-411b-b17a-1e3a4f6937bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14477, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ca6daee-6325-4e48-bc3d-7e1858ce8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.16\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 18)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.23\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 17)\n"
     ]
    }
   ],
   "source": [
    "# shortest sentences removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5d9d4b5-78f5-4417-bb1c-e837992ae875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the 95% of the data\n",
    "\n",
    "cutoff = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cde7c06f-cf1e-47c2-aa56-65809a53ecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question_tokens': 10, 'Answer_tokens': 6}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keeping only the 95% of the data\n",
    "\n",
    "get_thresholds(train_df_final_thresholds, cutoff = cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3dec7d1-3cdf-481e-a53a-8c334bc3fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MAX, A_MAX = get_thresholds(train_df_final_thresholds, cutoff = cutoff).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39553408-5871-4f2f-9778-f2f5bd0b0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = filter_sentences(train_df_final, cols_tokens, [Q_MAX+1,A_MAX+1], condition='shorter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3585bff9-ae72-4536-9d18-1eb7f507be5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 5.98\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 10)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 1.96\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 6)\n"
     ]
    }
   ],
   "source": [
    "# long outliers removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dbbf6d5-1c20-4ac9-8910-986fe457123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13465, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee608e-e8b8-49b6-85fb-6c2e370135da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "269601d3-8ef4-423f-9dd1-45ad01bcb8a1",
   "metadata": {},
   "source": [
    "# Must make pairs from the dataset with removed short and long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53174fa0-b463-43b5-829e-f147b7f5a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs_final = get_pairs_from_df(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f23a364e-b19c-4453-a493-c6464391bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs_final = get_pairs_from_df(test_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "faf05038-054f-482c-ac82-9c764ee6e5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13465, 2114)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs_final), len(test_pairs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e4513-494a-43ec-983f-8165c388336a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2444ab25-2074-489c-991e-a57cea7e0fbc",
   "metadata": {},
   "source": [
    "# building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61581914-4772-4a0f-8010-b2c75126dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cc8a6-632f-4c82-a8f9-ec619f451162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f32432a-42cd-4a28-9d69-2d405401b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(vocab, tokens, seq_len, device):\n",
    "    '''Converts a tokenized sentence into a tensor of indices of a given length.\n",
    "    If too short, it uses padding at the beginning of the sentence as suggested by the mentor.'''\n",
    "    \n",
    "    tokens = [t for t in tokens if t in vocab.word2count.keys()]\n",
    "    \n",
    "    padded = [vocab.word2index['PAD']] * (seq_len-len(tokens)) + [vocab.word2index['SOS']] + [vocab.word2index[t] for t in tokens] + [vocab.word2index['EOS']]\n",
    "\n",
    "    #print(len(padded))\n",
    "    \n",
    "    tensor = torch.Tensor(padded).long().to(device).view(-1,1)\n",
    "    \n",
    "    #print(tensor.shape)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7285fa-ec3e-4f66-817b-c27d18cecf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffa4ab61-3ed1-4001-a627-189806fcbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    # We initialize the Encoder object with appropriate layers\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, embedding_size):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        #self.hidden = torch.zeros(1, 1, hidden_size)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size).to(device)\n",
    "        \n",
    "        # The LSTM is our last cell because it produces the hidden state        \n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, 1).to(device)\n",
    "    \n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x.view(1, 1, -1)\n",
    "        \n",
    "        #x = x.view(x.shape[0], 1, -1)\n",
    "        \n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        return x, hidden, cell_state\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # The Decoder is initialized in the same manner.\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, embedding_size):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size)\n",
    "        \n",
    "        # The LSTM produces an output by passing the hidden state to the   Linear layer\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim= 1)     \n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        x = self.softmax(self.fc(x[0]))\n",
    "        return x, hidden, cell_state\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    #def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, output_size, device):    \n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = Encoder(self.input_size, self.hidden_size, self.embedding_size).to(device)\n",
    "        self.decoder = Decoder(self.hidden_size, self.output_size, self.embedding_size).to(device)\n",
    "        #self.device = device\n",
    "        \n",
    "    def forward(self, src_batch: torch.LongTensor, trg_batch: torch.LongTensor, src_len, trg_len, teacher_forcing_ratio: float = 0.5):\n",
    "        \n",
    "        max_len, batch_size = trg_batch.shape\n",
    "                \n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(device) #.to(self.device) \n",
    "\n",
    "         # initialize hidden and cell state\n",
    "        encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) \n",
    "        cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)\n",
    "\n",
    "        for i in range(src_len):\n",
    "        \n",
    "            # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "            _, hidden, cell = self.encoder(src_batch[i], encoder_hidden, cell_state)\n",
    "        \n",
    "        \n",
    "        \n",
    "        trg = trg_batch[0]\n",
    "        \n",
    "        for i in range(trg_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "            \n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8151e-ab72-4b6a-b3ce-074ecd48302e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "034cea43-8428-458c-b354-c939d85dbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fa05580-3539-45d8-82c8-f2db40e4eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87823425-7091-493f-a4a1-9f292aa56af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(input_size=Q_vocab.n_words, hidden_size=hidden_size, embedding_size=embedding_dim, output_size=A_vocab.n_words, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24a0d67c-200c-4349-a172-d35dd9d6a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = seq2seq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6216d45-7339-4bca-be35-7903b348b12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2710aacf-cfa1-4193-a300-2efa21b8989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25f62c5e-1c44-44b6-a7df-b33dd67e43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bf76d06-3d6c-4311-86c6-36d3307bbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(seq2seq.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(ignore_index=0).to(device) # 0 is padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9584cf05-26eb-4ebb-9aa2-3f9cc6349248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, pairs, optimizer, criterion, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for pair in pairs:\n",
    "        \n",
    "        src = pair.question\n",
    "        tgt = pair.answer\n",
    "        \n",
    "        src_tensor = to_tensor(vocab=Q_vocab, tokens=src, seq_len=Q_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "        tgt_tensor = to_tensor(vocab=A_vocab, tokens=tgt, seq_len=A_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "\n",
    "        # print(src_tensor.shape, tgt_tensor.shape)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src_tensor, tgt_tensor, src_len=src_tensor.size(0), trg_len=tgt_tensor.size(0), teacher_forcing_ratio=1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_tensor.view(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        count += 1 \n",
    "    \n",
    "        if count % 100 == 0:\n",
    "            print(f'Loss {total_loss/count}')\n",
    "    \n",
    "    return total_loss / len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806cb39-bb7d-493a-afda-234c650b4812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f4714c4-3f60-4a8f-8e25-466c8c6a9bbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "test after each epoch\n",
    "\n",
    "use minibatches (e.g. 16)\n",
    "\n",
    "either count pairs and only update loss/optimizer after n pairs\n",
    " or\n",
    "use bucket iterator\n",
    "\n",
    "https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb\n",
    "\n",
    "https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\n",
    "\n",
    "learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bc591-bb75-42f4-872b-49eade518bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fea572-6091-4b62-bf25-84394954b044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d349d25f-d960-4506-a205-5ec1ea1f40ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 7.203090801239013\n",
      "Loss 6.943091149330139\n",
      "Loss 6.769580410321553\n",
      "Loss 6.718248398303985\n",
      "Loss 6.613827770233154\n",
      "Loss 6.569031422138214\n",
      "Loss 6.50876715864454\n",
      "Loss 6.454655666351318\n",
      "Loss 6.415002989768982\n",
      "Loss 6.339275882720948\n",
      "Loss 6.262043362097307\n",
      "Loss 6.178652839064598\n",
      "Loss 6.143029320240021\n",
      "Loss 6.100663472584316\n",
      "Loss 6.0254803296724955\n",
      "Loss 5.969105757325888\n",
      "Loss 5.926152554399827\n",
      "Loss 5.874285455147425\n",
      "Loss 5.840606117750469\n",
      "Loss 5.796812346577644\n",
      "Loss 5.765627592858814\n",
      "Loss 5.72754963929003\n",
      "Loss 5.6907799887657164\n",
      "Loss 5.661697512567043\n",
      "Loss 5.633557128715515\n",
      "Loss 5.607118760072268\n",
      "Loss 5.594328987863329\n",
      "Loss 5.569085063678878\n",
      "Loss 5.547084771189196\n",
      "Loss 5.533639315923055\n",
      "Loss 5.513751115260586\n",
      "Loss 5.489338161796331\n",
      "Loss 5.476822957775809\n",
      "Loss 5.455531465025509\n",
      "Loss 5.43871051134382\n",
      "Loss 5.427478431132105\n",
      "Loss 5.4153141976047205\n",
      "Loss 5.401198417136544\n",
      "Loss 5.393487818302252\n",
      "Loss 5.380656868994236\n",
      "Loss 5.371372203245396\n",
      "Loss 5.361291206280391\n",
      "Loss 5.347977968482084\n",
      "Loss 5.336959432959556\n",
      "Loss 5.327843325720893\n",
      "Loss 5.321450016602226\n",
      "Loss 5.311567766970777\n",
      "Loss 5.300650257269542\n",
      "Loss 5.287341982296535\n",
      "Loss 5.2764066125869755\n",
      "Loss 5.272677179832084\n",
      "Loss 5.268574821719756\n",
      "Loss 5.2637375895932035\n",
      "Loss 5.25250273987099\n",
      "Loss 5.244952771403573\n",
      "Loss 5.236313554261412\n",
      "Loss 5.22992054094348\n",
      "Loss 5.221517123189466\n",
      "Loss 5.216065157793336\n",
      "Loss 5.20910798629125\n",
      "Loss 5.200402079371155\n",
      "Loss 5.189957057968263\n",
      "Loss 5.186835288055359\n",
      "Loss 5.179950701184571\n",
      "Loss 5.175303802233476\n",
      "Loss 5.169861618172039\n",
      "Loss 5.16394802050804\n",
      "Loss 5.1616768645539\n",
      "Loss 5.156401268433833\n",
      "Loss 5.152578397035599\n",
      "Loss 5.145995377621181\n",
      "Loss 5.137605216966735\n",
      "Loss 5.129683282212035\n",
      "Loss 5.12571613427755\n",
      "Loss 5.119459586366018\n",
      "Loss 5.118483772497428\n",
      "Loss 5.112775443622044\n",
      "Loss 5.106166783907475\n",
      "Loss 5.10359196934519\n",
      "Loss 5.097631946861744\n",
      "Loss 5.093825529180927\n",
      "Loss 5.087952288563659\n",
      "Loss 5.083518892483539\n",
      "Loss 5.078420693647294\n",
      "Loss 5.073430995015537\n",
      "Loss 5.069894820424014\n",
      "Loss 5.0673868770708985\n",
      "Loss 5.067923643128438\n",
      "Loss 5.059206799576791\n",
      "Loss 5.056731151554319\n",
      "Loss 5.051306519560762\n",
      "Loss 5.048400094094483\n",
      "Loss 5.046768074599646\n",
      "Loss 5.044831033133446\n",
      "Loss 5.041230844472584\n",
      "Loss 5.038442934552829\n",
      "Loss 5.03512280734544\n",
      "Loss 5.031492932815941\n",
      "Loss 5.028328955655146\n",
      "Loss 5.026495350694656\n",
      "Loss 5.023141983192746\n",
      "Loss 5.019923553420048\n",
      "Loss 5.015974580940691\n",
      "Loss 5.01246625737502\n",
      "Loss 5.012814921061198\n",
      "Loss 5.007584703148536\n",
      "Loss 5.004487370820803\n",
      "Loss 5.002195659434354\n",
      "Loss 5.000653517421233\n",
      "Loss 4.998662683855404\n",
      "Loss 4.997491058444117\n",
      "Loss 4.996317714686905\n",
      "Loss 4.994564666072879\n",
      "Loss 4.993574019628658\n",
      "Loss 4.989240449511486\n",
      "Loss 4.987902421375801\n",
      "Loss 4.9871994105974835\n",
      "Loss 4.987327230320139\n",
      "Loss 4.98618798610543\n",
      "Loss 4.985316444595655\n",
      "Loss 4.982376818361361\n",
      "Loss 4.981663753575966\n",
      "Loss 4.9810699045561195\n",
      "Loss 4.980016362801675\n",
      "Loss 4.979283196697235\n",
      "Loss 4.977509028987279\n",
      "Loss 4.9741036872600946\n",
      "Loss 4.972991942036897\n",
      "Loss 4.97165006761403\n",
      "Loss 4.969917530371593\n",
      "Loss 4.9694160769367945\n",
      "Loss 4.96745304403883\n",
      "Loss 4.968284846750417\n",
      "Loss 4.965609255655488\n",
      "Epoch 1/5, Loss: 4.9643\n",
      "Loss 4.787129259109497\n",
      "Loss 4.63358139038086\n",
      "Loss 4.566562352180481\n",
      "Loss 4.640264127254486\n",
      "Loss 4.620109889507294\n",
      "Loss 4.66968234539032\n",
      "Loss 4.691191563606262\n",
      "Loss 4.720721735656261\n",
      "Loss 4.759203073713515\n",
      "Loss 4.756472015142441\n",
      "Loss 4.749061553911729\n",
      "Loss 4.728948023120562\n",
      "Loss 4.753630271324744\n",
      "Loss 4.7661251321860725\n",
      "Loss 4.744622901280721\n",
      "Loss 4.736886626332998\n",
      "Loss 4.7392656512821425\n",
      "Loss 4.730437000592549\n",
      "Loss 4.736267578978287\n",
      "Loss 4.729733679771424\n",
      "Loss 4.734058667705172\n",
      "Loss 4.729081785678863\n",
      "Loss 4.724005268034728\n",
      "Loss 4.723476239442825\n",
      "Loss 4.7232925686836245\n",
      "Loss 4.721811604316418\n",
      "Loss 4.7322886816660565\n",
      "Loss 4.730571241804531\n",
      "Loss 4.729022840878059\n",
      "Loss 4.734707157293956\n",
      "Loss 4.734134950945454\n",
      "Loss 4.728519757315516\n",
      "Loss 4.732994622100484\n",
      "Loss 4.728404533302083\n",
      "Loss 4.726493980816432\n",
      "Loss 4.730010946856605\n",
      "Loss 4.731720019095653\n",
      "Loss 4.730923534255279\n",
      "Loss 4.735654489627251\n",
      "Loss 4.73509130525589\n",
      "Loss 4.737163968086243\n",
      "Loss 4.737764360620862\n",
      "Loss 4.734942645860273\n",
      "Loss 4.7338499738953335\n",
      "Loss 4.734553982999589\n",
      "Loss 4.737544353267421\n",
      "Loss 4.736582371326203\n",
      "Loss 4.734476061364015\n",
      "Loss 4.729522038673868\n",
      "Loss 4.72666961236\n",
      "Loss 4.730162863965128\n",
      "Loss 4.733015704200818\n",
      "Loss 4.735145031821053\n",
      "Loss 4.730988287749114\n",
      "Loss 4.730116224115545\n",
      "Loss 4.7279469312514575\n",
      "Loss 4.72749886441649\n",
      "Loss 4.725237755035532\n",
      "Loss 4.725544542660147\n",
      "Loss 4.724241720636686\n",
      "Loss 4.7210874726733225\n",
      "Loss 4.716087636409267\n",
      "Loss 4.717760930629003\n",
      "Loss 4.71575716663152\n",
      "Loss 4.7157067455878625\n",
      "Loss 4.714763130166314\n",
      "Loss 4.713077250843617\n",
      "Loss 4.714838298489066\n",
      "Loss 4.713596805662348\n",
      "Loss 4.713745705774852\n",
      "Loss 4.7109220649155095\n",
      "Loss 4.706392599476708\n",
      "Loss 4.702268582533484\n",
      "Loss 4.701785376361898\n",
      "Loss 4.698985543314616\n",
      "Loss 4.70110051688395\n",
      "Loss 4.698737796096059\n",
      "Loss 4.695150014865093\n",
      "Loss 4.695516461873356\n",
      "Loss 4.692334935069084\n",
      "Loss 4.691416492521027\n",
      "Loss 4.688261637396929\n",
      "Loss 4.6866552711394895\n",
      "Loss 4.684157220295497\n",
      "Loss 4.6818113721118255\n",
      "Loss 4.680814902366594\n",
      "Loss 4.680621379929027\n",
      "Loss 4.683162367939949\n",
      "Loss 4.677021979374832\n",
      "Loss 4.676786966721217\n",
      "Loss 4.6737208195833055\n",
      "Loss 4.6730851873107575\n",
      "Loss 4.6732716706234925\n",
      "Loss 4.673318937103799\n",
      "Loss 4.671687326682242\n",
      "Loss 4.670774019981424\n",
      "Loss 4.669218589473016\n",
      "Loss 4.667328688344177\n",
      "Loss 4.665905729496118\n",
      "Loss 4.665691225242615\n",
      "Loss 4.663850705529203\n",
      "Loss 4.6622086585503\n",
      "Loss 4.659910604351933\n",
      "Loss 4.657847942297275\n",
      "Loss 4.659422230152857\n",
      "Loss 4.65568988404184\n",
      "Loss 4.653976524968013\n",
      "Loss 4.652982946148625\n",
      "Loss 4.652796263366664\n",
      "Loss 4.651957714189183\n",
      "Loss 4.652029525975923\n",
      "Loss 4.652037138364145\n",
      "Loss 4.6514648265543235\n",
      "Loss 4.651466887540985\n",
      "Loss 4.648337286555249\n",
      "Loss 4.647988923520877\n",
      "Loss 4.648248606482123\n",
      "Loss 4.649399280709735\n",
      "Loss 4.649258526152924\n",
      "Loss 4.649273445328077\n",
      "Loss 4.647383519815019\n",
      "Loss 4.647580126778024\n",
      "Loss 4.647801598746602\n",
      "Loss 4.647585224682285\n",
      "Loss 4.647698279361725\n",
      "Loss 4.646755674074567\n",
      "Loss 4.644235753919196\n",
      "Loss 4.644021157026291\n",
      "Loss 4.6434460788364555\n",
      "Loss 4.642457429372348\n",
      "Loss 4.642635345094987\n",
      "Loss 4.641392865795078\n",
      "Loss 4.6428895573867\n",
      "Loss 4.64109272494245\n",
      "Epoch 2/5, Loss: 4.6403\n",
      "Loss 4.548562548160553\n",
      "Loss 4.40436319231987\n",
      "Loss 4.340492543379466\n",
      "Loss 4.40738534450531\n",
      "Loss 4.387987983226776\n",
      "Loss 4.4357989076773325\n",
      "Loss 4.455038527761187\n",
      "Loss 4.482573232650757\n",
      "Loss 4.5179265567991465\n",
      "Loss 4.515358924865723\n",
      "Loss 4.5086395116285845\n",
      "Loss 4.488290606935819\n",
      "Loss 4.511551844523503\n",
      "Loss 4.523705698081425\n",
      "Loss 4.504544496218363\n",
      "Loss 4.497250374257565\n",
      "Loss 4.499863759910359\n",
      "Loss 4.491407650974062\n",
      "Loss 4.496784955576847\n",
      "Loss 4.490590114235878\n",
      "Loss 4.494644361904689\n",
      "Loss 4.489957965720784\n",
      "Loss 4.485539333820343\n",
      "Loss 4.484837203919888\n",
      "Loss 4.484544839763641\n",
      "Loss 4.482944395358746\n",
      "Loss 4.492589607680285\n",
      "Loss 4.491620659487588\n",
      "Loss 4.489470791734498\n",
      "Loss 4.49428422276179\n",
      "Loss 4.4934786964231925\n",
      "Loss 4.488484969213605\n",
      "Loss 4.493009932908145\n",
      "Loss 4.488501051524106\n",
      "Loss 4.485954626900809\n",
      "Loss 4.489634097350968\n",
      "Loss 4.491268479115254\n",
      "Loss 4.490536599096499\n",
      "Loss 4.4952908851550175\n",
      "Loss 4.494858775734901\n",
      "Loss 4.496799563605611\n",
      "Loss 4.497582944177446\n",
      "Loss 4.494624200809834\n",
      "Loss 4.493669627742334\n",
      "Loss 4.494888279967838\n",
      "Loss 4.498309791865556\n",
      "Loss 4.497559089609918\n",
      "Loss 4.496088089644909\n",
      "Loss 4.491104319630837\n",
      "Loss 4.488469963407517\n",
      "Loss 4.491974124627955\n",
      "Loss 4.4947351654447045\n",
      "Loss 4.496873412424663\n",
      "Loss 4.493153531617589\n",
      "Loss 4.492729365890677\n",
      "Loss 4.491024485932929\n",
      "Loss 4.490593388289736\n",
      "Loss 4.488797342345633\n",
      "Loss 4.4894110896021635\n",
      "Loss 4.488510393122832\n",
      "Loss 4.48589085029774\n",
      "Loss 4.481355517122053\n",
      "Loss 4.483060175975163\n",
      "Loss 4.481441173087806\n",
      "Loss 4.481715569991332\n",
      "Loss 4.481053162795124\n",
      "Loss 4.479365956302899\n",
      "Loss 4.481393383723848\n",
      "Loss 4.480313944989357\n",
      "Loss 4.480751356874194\n",
      "Loss 4.477969919527081\n",
      "Loss 4.473677412503296\n",
      "Loss 4.469933435361679\n",
      "Loss 4.469864093000824\n",
      "Loss 4.4673538356781\n",
      "Loss 4.469646358521361\n",
      "Loss 4.467777031304\n",
      "Loss 4.464447926466281\n",
      "Loss 4.465233943703808\n",
      "Loss 4.462038105458022\n",
      "Loss 4.461659725948616\n",
      "Loss 4.458715587970687\n",
      "Loss 4.457685032752623\n",
      "Loss 4.455479199772789\n",
      "Loss 4.453517061065225\n",
      "Loss 4.453038770792096\n",
      "Loss 4.453172667876057\n",
      "Loss 4.4558382448283105\n",
      "Loss 4.45030233318886\n",
      "Loss 4.450539673911201\n",
      "Loss 4.448045548632905\n",
      "Loss 4.448139820928159\n",
      "Loss 4.448493890429056\n",
      "Loss 4.448971019399927\n",
      "Loss 4.447754137942666\n",
      "Loss 4.447193346371253\n",
      "Loss 4.445936289054831\n",
      "Loss 4.444295263022792\n",
      "Loss 4.4432819307452505\n",
      "Loss 4.4435283168554305\n",
      "Loss 4.441916819799064\n",
      "Loss 4.440786861648746\n",
      "Loss 4.439008645467387\n",
      "Loss 4.437336929451961\n",
      "Loss 4.439312685501008\n",
      "Loss 4.43602520026126\n",
      "Loss 4.434723494888466\n",
      "Loss 4.43414270185762\n",
      "Loss 4.434560119613595\n",
      "Loss 4.4340410322817885\n",
      "Loss 4.434761818217802\n",
      "Loss 4.435265678241849\n",
      "Loss 4.435308214995714\n",
      "Loss 4.43566131787342\n",
      "Loss 4.432978742734246\n",
      "Loss 4.433082594265198\n",
      "Loss 4.433749958225804\n",
      "Loss 4.4354318330045475\n",
      "Loss 4.435778359645555\n",
      "Loss 4.4361623594164845\n",
      "Loss 4.4348112788870315\n",
      "Loss 4.435452459972413\n",
      "Loss 4.436101249524248\n",
      "Loss 4.436341520317139\n",
      "Loss 4.436901819133759\n",
      "Loss 4.4364340550748125\n",
      "Loss 4.434434461190006\n",
      "Loss 4.434891396695748\n",
      "Loss 4.434718368034954\n",
      "Loss 4.434191143237627\n",
      "Loss 4.43478073329416\n",
      "Loss 4.434045921311234\n",
      "Loss 4.435979102392842\n",
      "Loss 4.4348116712072\n",
      "Epoch 3/5, Loss: 4.4345\n",
      "Loss 4.398695991039276\n",
      "Loss 4.256742086410522\n",
      "Loss 4.192444924513499\n",
      "Loss 4.256567067205906\n",
      "Loss 4.237413341760635\n",
      "Loss 4.286339412132899\n",
      "Loss 4.30402276294572\n",
      "Loss 4.330957649201155\n",
      "Loss 4.365402957465913\n",
      "Loss 4.3632884761095045\n",
      "Loss 4.358288301446221\n",
      "Loss 4.337630593876044\n",
      "Loss 4.361894121261743\n",
      "Loss 4.374842445680073\n",
      "Loss 4.358260784626007\n",
      "Loss 4.351711912751198\n",
      "Loss 4.355620617305531\n",
      "Loss 4.347245300081041\n",
      "Loss 4.35275413419071\n",
      "Loss 4.346989331483841\n",
      "Loss 4.35171441095216\n",
      "Loss 4.347804218855771\n",
      "Loss 4.344695802719697\n",
      "Loss 4.344131916860739\n",
      "Loss 4.344337008857727\n",
      "Loss 4.342845244866151\n",
      "Loss 4.352479637287281\n",
      "Loss 4.352813778349331\n",
      "Loss 4.349781301967029\n",
      "Loss 4.353688622315724\n",
      "Loss 4.353013947779132\n",
      "Loss 4.348781291283667\n",
      "Loss 4.353962118589517\n",
      "Loss 4.349691991630722\n",
      "Loss 4.346633853776114\n",
      "Loss 4.351171382996771\n",
      "Loss 4.35285629549542\n",
      "Loss 4.352477207434805\n",
      "Loss 4.357577897921587\n",
      "Loss 4.3577263339459895\n",
      "Loss 4.359964100791187\n",
      "Loss 4.360971679034687\n",
      "Loss 4.357763398663942\n",
      "Loss 4.356983095190742\n",
      "Loss 4.358965785053042\n",
      "Loss 4.363186302444209\n",
      "Loss 4.362660457403102\n",
      "Loss 4.36168636550506\n",
      "Loss 4.356711858802912\n",
      "Loss 4.35426092467308\n",
      "Loss 4.3579330837025365\n",
      "Loss 4.3605974356257\n",
      "Loss 4.363053325976965\n",
      "Loss 4.359731920361519\n",
      "Loss 4.359744192578576\n",
      "Loss 4.358383339962789\n",
      "Loss 4.357914927507702\n",
      "Loss 4.356478244025132\n",
      "Loss 4.357564382027771\n",
      "Loss 4.356981903374195\n",
      "Loss 4.354901941252536\n",
      "Loss 4.35074664535061\n",
      "Loss 4.352518931778651\n",
      "Loss 4.350996389631182\n",
      "Loss 4.351608415053441\n",
      "Loss 4.35113724079999\n",
      "Loss 4.349222232388026\n",
      "Loss 4.351483361440547\n",
      "Loss 4.350473600038583\n",
      "Loss 4.351205118945667\n",
      "Loss 4.348340851958369\n",
      "Loss 4.344027217610015\n",
      "Loss 4.340373458715335\n",
      "Loss 4.340498803112958\n",
      "Loss 4.338091515525182\n",
      "Loss 4.340440546195758\n",
      "Loss 4.338846237365302\n",
      "Loss 4.335455279380847\n",
      "Loss 4.336481857179087\n",
      "Loss 4.333020500406623\n",
      "Loss 4.332976346001213\n",
      "Loss 4.329943358316654\n",
      "Loss 4.329211474039468\n",
      "Loss 4.327089126734506\n",
      "Loss 4.325335733820411\n",
      "Loss 4.325146901704544\n",
      "Loss 4.325325496717431\n",
      "Loss 4.327887177927927\n",
      "Loss 4.3225981903611945\n",
      "Loss 4.323046590447426\n",
      "Loss 4.320732904973921\n",
      "Loss 4.321268074667972\n",
      "Loss 4.321450886572561\n",
      "Loss 4.322000443478848\n",
      "Loss 4.32082310188444\n",
      "Loss 4.320261026298007\n",
      "Loss 4.319099900992875\n",
      "Loss 4.31748043496998\n",
      "Loss 4.316576714359148\n",
      "Loss 4.317010890233517\n",
      "Loss 4.31532195703818\n",
      "Loss 4.314283863200861\n",
      "Loss 4.31265809398253\n",
      "Loss 4.311095447643445\n",
      "Loss 4.313086190042042\n",
      "Loss 4.30986538028942\n",
      "Loss 4.308626996880379\n",
      "Loss 4.308099688148057\n",
      "Loss 4.308714876426469\n",
      "Loss 4.308137225205248\n",
      "Loss 4.309114893889642\n",
      "Loss 4.309788970148989\n",
      "Loss 4.310057605726529\n",
      "Loss 4.310426752389523\n",
      "Loss 4.307865341186523\n",
      "Loss 4.307982377379105\n",
      "Loss 4.308704313702053\n",
      "Loss 4.310566149788388\n",
      "Loss 4.311011174847098\n",
      "Loss 4.311343043208122\n",
      "Loss 4.310165491153386\n",
      "Loss 4.31082305789971\n",
      "Loss 4.311578180528269\n",
      "Loss 4.311963384468709\n",
      "Loss 4.312561342658997\n",
      "Loss 4.312141909078946\n",
      "Loss 4.3102639590567495\n",
      "Loss 4.310974760437384\n",
      "Loss 4.3108951969386995\n",
      "Loss 4.310428795805344\n",
      "Loss 4.311174814300682\n",
      "Loss 4.310619264949452\n",
      "Loss 4.312684912098978\n",
      "Loss 4.311759153008461\n",
      "Epoch 4/5, Loss: 4.3116\n",
      "Loss 4.283079478740692\n",
      "Loss 4.147363605499268\n",
      "Loss 4.079474489688874\n",
      "Loss 4.141217949986458\n",
      "Loss 4.120645160198212\n",
      "Loss 4.171293995976448\n",
      "Loss 4.187332641397203\n",
      "Loss 4.2143914166092875\n",
      "Loss 4.248138731453154\n",
      "Loss 4.246199938416481\n",
      "Loss 4.242619434811852\n",
      "Loss 4.2224834010005\n",
      "Loss 4.247486752179952\n",
      "Loss 4.261037828751973\n",
      "Loss 4.246217686096827\n",
      "Loss 4.239869805723429\n",
      "Loss 4.244631484536564\n",
      "Loss 4.2363558659950895\n",
      "Loss 4.24174122164124\n",
      "Loss 4.235849560201168\n",
      "Loss 4.241044801473618\n",
      "Loss 4.237991200577129\n",
      "Loss 4.236042974720831\n",
      "Loss 4.2354813047250115\n",
      "Loss 4.235853663730621\n",
      "Loss 4.234502809231098\n",
      "Loss 4.243551138860208\n",
      "Loss 4.244617095887661\n",
      "Loss 4.2407111676397\n",
      "Loss 4.243923873106638\n",
      "Loss 4.243389583479973\n",
      "Loss 4.239709336608648\n",
      "Loss 4.245356797016028\n",
      "Loss 4.241310724090128\n",
      "Loss 4.2377021021502355\n",
      "Loss 4.242983683447043\n",
      "Loss 4.244362997686541\n",
      "Loss 4.244119459578865\n",
      "Loss 4.249183339583568\n",
      "Loss 4.249792609989643\n",
      "Loss 4.252122838642539\n",
      "Loss 4.253165513049988\n",
      "Loss 4.249671494434046\n",
      "Loss 4.248807764215903\n",
      "Loss 4.25133621319135\n",
      "Loss 4.256090542388999\n",
      "Loss 4.255583553035208\n",
      "Loss 4.254731321682533\n",
      "Loss 4.249562114671785\n",
      "Loss 4.247116174030304\n",
      "Loss 4.250755984923419\n",
      "Loss 4.253248944374231\n",
      "Loss 4.255866075461766\n",
      "Loss 4.25275844041948\n",
      "Loss 4.25284496066787\n",
      "Loss 4.25152980491519\n",
      "Loss 4.251000991599602\n",
      "Loss 4.249741006226375\n",
      "Loss 4.251197916814837\n",
      "Loss 4.250704243282477\n",
      "Loss 4.248968054505645\n",
      "Loss 4.24524024334646\n",
      "Loss 4.24699618719873\n",
      "Loss 4.245421785600484\n",
      "Loss 4.246189621503537\n",
      "Loss 4.24584263687784\n",
      "Loss 4.243757206450647\n",
      "Loss 4.246195543075309\n",
      "Loss 4.245205697961476\n",
      "Loss 4.246037456410272\n",
      "Loss 4.243167725499247\n",
      "Loss 4.238674643552965\n",
      "Loss 4.2350407483969645\n",
      "Loss 4.235168595797306\n",
      "Loss 4.232761342366537\n",
      "Loss 4.2350483516799775\n",
      "Loss 4.233545613892667\n",
      "Loss 4.230028947851597\n",
      "Loss 4.2310984199711035\n",
      "Loss 4.227518716529012\n",
      "Loss 4.227709898139223\n",
      "Loss 4.224671194931356\n",
      "Loss 4.224045165274517\n",
      "Loss 4.2218596180563885\n",
      "Loss 4.220171351376702\n",
      "Loss 4.22005720912024\n",
      "Loss 4.220222309471547\n",
      "Loss 4.2225862033258785\n",
      "Loss 4.217572213277388\n",
      "Loss 4.218056204901801\n",
      "Loss 4.215802211407777\n",
      "Loss 4.2165965324640275\n",
      "Loss 4.21661137984645\n",
      "Loss 4.217032920743557\n",
      "Loss 4.2157767124426995\n",
      "Loss 4.215117911932369\n",
      "Loss 4.214074016772595\n",
      "Loss 4.212592652537385\n",
      "Loss 4.211836231344878\n",
      "Loss 4.212467184877395\n",
      "Loss 4.210733398470548\n",
      "Loss 4.209647835002226\n",
      "Loss 4.208054899648555\n",
      "Loss 4.206655263522497\n",
      "Loss 4.2085557918321514\n",
      "Loss 4.205356887747657\n",
      "Loss 4.204181634187698\n",
      "Loss 4.203640016328405\n",
      "Loss 4.204277777595258\n",
      "Loss 4.203549181515521\n",
      "Loss 4.204659808680818\n",
      "Loss 4.2054607303759886\n",
      "Loss 4.2058340309257005\n",
      "Loss 4.206214620387345\n",
      "Loss 4.203795022021169\n",
      "Loss 4.203854652191031\n",
      "Loss 4.204650855064392\n",
      "Loss 4.206573393243854\n",
      "Loss 4.207053678506563\n",
      "Loss 4.207288420130809\n",
      "Loss 4.206240559097164\n",
      "Loss 4.2068245651682865\n",
      "Loss 4.207675201059357\n",
      "Loss 4.208133491700695\n",
      "Loss 4.208715148706436\n",
      "Loss 4.208310213202522\n",
      "Loss 4.206552062757372\n",
      "Loss 4.207383752455935\n",
      "Loss 4.207366337785425\n",
      "Loss 4.206918525888369\n",
      "Loss 4.207821743242613\n",
      "Loss 4.207398938518582\n",
      "Loss 4.209546230377112\n",
      "Loss 4.2087575138326905\n",
      "Epoch 5/5, Loss: 4.2087\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(seq2seq, train_pairs_final, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ea147-c71c-49b6-be37-8f6022db0b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce4904c8-87c3-4391-9d36-4090ec460ce6",
   "metadata": {},
   "source": [
    "it can also be caused if you have a mismatch between the dimension of your input tensor and the dimensions of your nn.Linear module. (ex. x.shape = (a, b) and nn.Linear(c, c, bias=False) with c not matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fc674-a203-43e9-bf8f-bf7c8fda9ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstmtorch",
   "language": "python",
   "name": "lstmtorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
