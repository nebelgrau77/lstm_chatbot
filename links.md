## Various articles and tutorials:

* https://www.guru99.com/seq2seq-model.html - Seq2Seq with PyTorch (EN-DE translation, GRU not LSTM, no dataloader, no batch)
* https://saturncloud.io/blog/how-to-use-multiple-gpus-in-pytorch/ - parallel training
* https://www.marktechpost.com/2020/04/12/implementing-batching-for-seq2seq-models-in-pytorch/ - implementing batch for Seq2Seq
* https://medium.com/exemplifyml-ai/multi-gpu-training-in-pytorch-ab1a9500377e - MultiGPU training with DDP
* https://glassboxmedicine.com/2020/03/04/multi-gpu-training-in-pytorch-data-and-model-parallelism/ - parallel training
* https://towardsdatascience.com/how-to-scale-training-on-multiple-gpus-dae1041f49d2 - training on multiple GPUs