{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a3b362-3b2c-4dd5-90db-e438d861c5b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SIMPLE WORKING VERSION\n",
    "\n",
    "Karan suggests to use KFold:\n",
    "\n",
    "*The best way to improve the test loss is to combine first both train and dev dataset. Then use kfold random sampling while training. Note: LSTM is not capable enough too perform best on unseen data. If you evaluate the train and test set there will be no similarity in que and answer. So its best, if you use kfold method, which randomly select test set at each iteration.* \n",
    "- *Try reducing sentence length (both que and answer)*\n",
    "- *Try using learning-rate as 0.01*\n",
    "- *Try reducing the batch size (keep 16 as batch size)*\n",
    "- *Try adding n-layer paramter in LSTM to at least 2*\n",
    "- *Try to train for at least 30 epochs.*\n",
    "\n",
    "There is an example that uses KFold: https://github.com/iJoud/Seq2Seq-Chatbot/tree/main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c2679-9204-4273-a4a1-64f41ef9d11b",
   "metadata": {},
   "source": [
    "# RNN LSTM Chatbot project\n",
    "\n",
    "In this project I'm creating a chatbot that is supposed to answer questions from the Stanford Questions & Answers dataset SQuAD1, using a sequence-to-sequence Encoder-Decoder recurrent neural network architecture in PyTorch.\n",
    "\n",
    "To make the notebook more readable and the code more modular, all helper functions (data ingestion and preparation, data analysis, vocabulary creation) were moved to `modules`. \n",
    "\n",
    "The model for easier debugging is kept in the main notebook for now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79ff163-ef6c-4dbd-b8b8-9a0b6f31122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c980c5-3cff-4e3d-a06b-7513721ab2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e1d6c1-da35-4ac8-9bf9-65b786d259f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9442349d-4e46-4ba2-b9f8-79b6ce598c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a6456-5007-46ed-97d0-7477cd9cc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import SQuAD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ef63a7-6d02-4c19-9abc-fedccbc1a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = SQuAD1(\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f44af6a-6144-4443-b309-c6514bf0c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /shared/home/u076079/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /shared/home/u076079/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /shared/home/u076079/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from modules.data import *\n",
    "\n",
    "#get_dataframe,  get_pairs_from_df, cols, sample_df_perc, get_thresholds, get_outliers, tokenize_sentence, remove_least_common, to_tensor,  filter_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0ef1e-be7c-4e95-ae5c-1e3707b5d22a",
   "metadata": {},
   "source": [
    "## Data ingestion\n",
    "\n",
    "* Data is loaded from the dataset into pandas dataframes: one for training, one for testing, \n",
    "* To keep the dataset size reasonable, only a sample of the questions/answers is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6845c6-5997-457d-8e50-e07d0108e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test dataframes of sentences\n",
    "train_df, test_df = get_dataframe(train), get_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b4268c-6744-4949-85c8-b865360e008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87599, 2), (10570, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07ccb1c-19e0-40a3-9991-92c23c037a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 40000\n",
    "test_len = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744b72aa-38b0-4542-ac96-906a818b96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sample_df_num(train_df, train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54a9b1e-ffaf-4f51-93ce-b31b9b7f1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sample_df_num(test_df, test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49d6bc9-266c-447c-9be6-1794c5053b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 2), (4000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ccaa7e-fa23-4eb2-bbe7-f9e8e5dfac4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the name of second best basketball clu...</td>\n",
       "      <td>Tartu Ülikool/Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Israel developed what?</td>\n",
       "      <td>various water-saving technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Few AA guns are able to fire which way?</td>\n",
       "      <td>vertically</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  What is the name of second best basketball clu...   \n",
       "1                             Israel developed what?   \n",
       "2            Few AA guns are able to fire which way?   \n",
       "\n",
       "                              Answer  \n",
       "0                 Tartu Ülikool/Rock  \n",
       "1  various water-saving technologies  \n",
       "2                         vertically  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc78290-1a58-45c9-ba2e-ec4b3d1511bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6344a0f9-cc0b-4b6e-9238-c54a5da7197b",
   "metadata": {},
   "source": [
    "## Vocabulary creation / Data preparation\n",
    "\n",
    "Sentences (questions and answers) are converted into lists of tokens:\n",
    "* all characters are made into lower case\n",
    "* punctuation is removed\n",
    "* stopwords (most common words that don't carry much additional meaning) are removed, but keeping question words (when, how, who, etc.)\n",
    "* For questions stemming is applied to reduce number of words to just their \"roots\". For answers this step is skipped, to have full unstemmed words in the answers vocabulary\n",
    "* Pairs question:answer are created from both train and test dataset, and words are added to two vocabularies: Q_vocab and A_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea6bbdcf-6263-4531-b5d5-1447576708d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do the Armenians see the events of 1915-1917 as?\n",
      "['what', 'armenians', 'see', 'events', '19151917']\n",
      "['what', 'armenian', 'see', 'event', '19151917']\n"
     ]
    }
   ],
   "source": [
    "# Example of the sequence processing\n",
    "\n",
    "import random\n",
    "\n",
    "rand_question = train_df.at[random.randint(0,train_df.shape[0]), 'Question']\n",
    "print(rand_question)\n",
    "\n",
    "print(tokenize_sentence(rand_question))\n",
    "print(tokenize_sentence(rand_question, normalization='stem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f5a18-cd38-49eb-8e1a-6f18f64f39a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5546a5c6-eec6-4816-85c2-ec3b652b5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c28a91-cbe2-445e-98cf-0b3e67e4a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, norm in zip(cols, ['stem', None]): # only questions get stemmed\n",
    "    train_df[f'{col}_tokens'] = train_df[col].apply(lambda s: tokenize_sentence(s, normalization=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc7a90d6-dd8b-4425-81f8-9c447201783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, norm in zip(cols, ['stem', None]):\n",
    "    test_df[f'{col}_tokens'] = test_df[col].apply(lambda s: tokenize_sentence(s, normalization=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc6971c-872e-4b3a-a0d9-585ab3d44739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_tokens</th>\n",
       "      <th>Answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>Reduced insulin function can also go by what o...</td>\n",
       "      <td>insulin resistance</td>\n",
       "      <td>[reduc, insulin, function, also, go, what, term]</td>\n",
       "      <td>[insulin, resistance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>What is the name of the naval base the US leas...</td>\n",
       "      <td>Guantánamo Bay Naval Base</td>\n",
       "      <td>[what, name, naval, base, us, leas, newli, ind...</td>\n",
       "      <td>[guantánamo, bay, naval, base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27426</th>\n",
       "      <td>What Nigerian community has the worst unsustai...</td>\n",
       "      <td>Kubwa Community</td>\n",
       "      <td>[what, nigerian, communiti, worst, unsustain, ...</td>\n",
       "      <td>[kubwa, community]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "13344  Reduced insulin function can also go by what o...   \n",
       "437    What is the name of the naval base the US leas...   \n",
       "27426  What Nigerian community has the worst unsustai...   \n",
       "\n",
       "                          Answer  \\\n",
       "13344         insulin resistance   \n",
       "437    Guantánamo Bay Naval Base   \n",
       "27426            Kubwa Community   \n",
       "\n",
       "                                         Question_tokens  \\\n",
       "13344   [reduc, insulin, function, also, go, what, term]   \n",
       "437    [what, name, naval, base, us, leas, newli, ind...   \n",
       "27426  [what, nigerian, communiti, worst, unsustain, ...   \n",
       "\n",
       "                        Answer_tokens  \n",
       "13344           [insulin, resistance]  \n",
       "437    [guantánamo, bay, naval, base]  \n",
       "27426              [kubwa, community]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5a711d-2d46-4255-9091-959b91a07b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed sequences columns names have '_tokens' suffix\n",
    "cols_tokens = [f'{col}_tokens' for col in cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4520dfcf-9530-4268-b9a7-4d01bc98c6be",
   "metadata": {},
   "source": [
    "### Create pairs and add to the vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c241b5-3e32-47ba-9fab-9bad67404d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = get_pairs_from_df(train_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9eebcb5-30c2-4bf0-bbe8-e6a4015205f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = get_pairs_from_df(test_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d3fed41-b6df-495e-966b-73d8275bc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_vocab, A_vocab = Vocab(), Vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4791a92-39ea-4709-bceb-316b1f7cf61d",
   "metadata": {},
   "source": [
    "### Words from both training and test datasets are added to the two vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766b2b7c-8452-4f41-91c1-a1933899af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in train_pairs:\n",
    "    Q_vocab.add_sentence(pair.question)\n",
    "    A_vocab.add_sentence(pair.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bf020f0-9fa9-4d35-b5a1-c72e2190e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19724, 26728)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.n_words, A_vocab.n_words, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3dcfe2-d353-4d2e-915f-03e0923dc785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in test_pairs:\n",
    "    Q_vocab.add_sentence(pair.question)\n",
    "    A_vocab.add_sentence(pair.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b57afc2-4b59-481a-8d15-ee267b0d8e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20907, 28324)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answers vocabulary contains more words due to lack of stemming\n",
    "\n",
    "Q_vocab.n_words, A_vocab.n_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7878b-ad57-4ad4-9cd4-b4509c6f660d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6d39d65-1c60-4b17-8913-100b2fe00cde",
   "metadata": {},
   "source": [
    "## Data analysis and further cleanup\n",
    "\n",
    "To improve and reduce the dataset, some analysis is done to find and remove outliers:\n",
    "* least common words (those that occur only once)\n",
    "* answers that have less than one token (empty sequences)\n",
    "* questions that have less than three tokens, as they're not really meaningful\n",
    "* histograms are used to find the \"long tail\" of the dataset: longer sequences are rare, so I establish a threshold above which the dataframe row with either very long question or answer is dropped. This way most of the data is kept, and the sequences can be of reasonable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da86f92-bddd-41f3-b0f6-5b4d2eb5d873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7450e792-925e-4a07-8236-38f1045e69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.stats import sentences_stats, histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1982157e-f27d-40b3-98fb-f001012d68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.43\n",
      "\t         median: 6.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 22)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.44\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 22)\n"
     ]
    }
   ],
   "source": [
    "# statistics for tokenized sentences\n",
    "sentences_stats(train_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed546c61-46c6-4198-8b2d-658e6ea83727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.49\n",
      "\t         median: 6.00\n",
      "\t         minimum: 2\n",
      "\t         maximum: 17)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.36\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 18)\n"
     ]
    }
   ],
   "source": [
    "# statistics for tokenized sentences\n",
    "sentences_stats(test_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034d347-3b5c-4675-9040-c06f9d1be915",
   "metadata": {},
   "source": [
    "### Remove the least common words from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0127a26b-68b8-4456-8c70-c49ba08525ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times at most a word occurs to be considered an outlier\n",
    "outlier_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0335f482-7f3c-4265-81d9-93436d7f1090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions vocabulary has 10198 words that occur only once, answers vocabulary has 16601 such words\n"
     ]
    }
   ],
   "source": [
    "print(f'Questions vocabulary has {len(get_outliers(Q_vocab, outlier_threshold+1))} words that occur only once, answers vocabulary has {len(get_outliers(A_vocab, outlier_threshold+1))} such words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6146cc-8b68-4db8-b387-008c413e71ac",
   "metadata": {},
   "source": [
    "### Create lists of those words and remove them from the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2adafd8f-bae0-455c-ab37-363db03f2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_outliers, a_outliers = get_outliers(Q_vocab,outlier_threshold+1), get_outliers(A_vocab,outlier_threshold+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0464a5cf-fb82-4acc-ab6c-b3029a1e510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = remove_least_common(train_df, cols_tokens, [q_outliers, a_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52510523-62a9-4e42-ba96-bddbee4bf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = remove_least_common(test_df, cols_tokens, [q_outliers, a_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a019f58-39d0-4a4e-9b22-6a69e84a80ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.20\n",
      "\t         median: 6.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 22)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.06\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 18)\n"
     ]
    }
   ],
   "source": [
    "# tokenized & least common removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0b21a9a-243f-4dc6-a0a8-2e2c65caebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.26\n",
      "\t         median: 6.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 17)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.00\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 15)\n"
     ]
    }
   ],
   "source": [
    "# tokenized & least common removed\n",
    "sentences_stats(test_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25751515-a24f-4e0a-9b6c-e12f9dafd722",
   "metadata": {},
   "source": [
    "### Remove questions that have less than three words and answers that have less than one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47ca1d7a-f8b0-4d42-aa9e-a889c0dfbcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_final = filter_sentences(train_df_final, cols_tokens, [2,0], condition='longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3934a09f-4d33-4024-adcc-e4bccc55d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question_tokens 3\n",
      "Answer_tokens 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAHHCAYAAAB5gsZZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpYklEQVR4nO3deVxO6f8/8Nfdvhfa0TLRJvs2iUSRZYwsk21EtmGyZhsfJpmYRoZhJiP7MsNYZmiMGWu6GSQpKYbEREwbg1IqqfP7w7fzm1uh3N3u4vV8PO7HZ+7rnHOd9znu6vW5znWfIxEEQQARERERvTYVZRdAREREVNcxUBERERHJiYGKiIiISE4MVERERERyYqAiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOTFQEdFbJTg4GBKJRNllvJJUKoVEIsHPP/+stBpsbGzwwQcfKGW/o0ePfqP73LJlCyQSCW7evPlG90vvDgYqojcgOTkZgwcPhrW1NbS0tNCwYUP06NED3333nUL3m5GRgeDgYCQmJip0P/RiO3bswMqVK2u83zNnziA4OBgPHz6s8b6JqPoYqIgU7MyZM2jXrh0uXryI8ePHIzw8HOPGjYOKigpWrVql0H1nZGRg0aJFDFRKpMhAtWjRojoZqFJSUrB+/Xpll0FUo9SUXQDR227JkiUwNDREXFwcjIyMZJbl5OQopygiJdLU1FR2CUQ1jiNURAp248YNNGvWrEKYAgBTU9MKbT/++CPatm0LbW1t1K9fH0OHDsXt27dl1vHw8ICLiwv++usvdOvWDTo6OmjYsCHCwsLEdaRSKdq3bw8A8Pf3h0QigUQiwZYtW8R1YmNj0atXLxgaGkJHRwddu3bF6dOnZfZVPifp+vXrGD16NIyMjGBoaAh/f388fvy40vo7dOgAHR0d1KtXD+7u7jhy5IjMOgcPHkSXLl2gq6sLfX199O3bF5cvX5ZZJysrC/7+/mjUqBE0NTVhYWGB/v37v/YcmJo6r+Vu3bqFDz/8ELq6ujA1NcWMGTNw+PBhSCQSSKVSsb/ff/8dt27dEs+/jY2NTD9lZWVYsmQJGjVqBC0tLXh6euL69esvPZbg4GDMnj0bAGBrayv2XX5unj59ipCQENjZ2UFTUxM2Njb43//+h+Li4leep61bt0JNTU3sH6j5z8nzc6jK66/s9d9/76tXr2Lw4MGoX78+tLS00K5dO+zfv7/CMVy+fBndu3eHtrY2GjVqhMWLF6OsrOyVx04kD45QESmYtbU1YmJicOnSJbi4uLx03SVLluDzzz+Hr68vxo0bh7t37+K7776Du7s7Lly4IBPKHjx4gF69emHgwIHw9fXFzz//jLlz56J58+bo3bs3nJyc8MUXXyAoKAgTJkxAly5dAACdOnUCABw/fhy9e/dG27ZtsXDhQqioqGDz5s3o3r07/vzzT3To0EGmNl9fX9ja2iI0NBQJCQnYsGEDTE1NsXTpUnGdRYsWITg4GJ06dcIXX3wBDQ0NxMbG4vjx4+jZsycA4IcffsCoUaPg7e2NpUuX4vHjx1izZg06d+6MCxcuiIFj0KBBuHz5MqZMmQIbGxvk5OTg6NGjSE9PrxBKXqUmzysAFBQUoHv37sjMzMS0adNgbm6OHTt2IDo6Wma/8+fPR25uLu7cuYNvvvkGAKCnpyezzldffQUVFRXMmjULubm5CAsLw4gRIxAbG/vC4xk4cCCuXbuGn376Cd988w2MjY0BACYmJgCAcePGYevWrRg8eDBmzpyJ2NhYhIaG4sqVK9i3b98L+123bh0mTpyI//3vf1i8eDEAxXxOnvfDDz9UaFuwYAFycnLE83X58mW4ubmhYcOG+Oyzz6Crq4vdu3fDx8cHv/zyCwYMGADgWRDv1q0bnj59Kq63bt06aGtrv3D/RDVCICKFOnLkiKCqqiqoqqoKrq6uwpw5c4TDhw8LT548kVnv5s2bgqqqqrBkyRKZ9uTkZEFNTU2mvWvXrgIAYdu2bWJbcXGxYG5uLgwaNEhsi4uLEwAImzdvlumzrKxMaNq0qeDt7S2UlZWJ7Y8fPxZsbW2FHj16iG0LFy4UAAhjxoyR6WPAgAFCgwYNxPepqamCioqKMGDAAKG0tLTC/gRBEB49eiQYGRkJ48ePl1melZUlGBoaiu0PHjwQAAjLli0Tqqu83nKKOK/Lly8XAAiRkZFiW2FhoeDo6CgAEKKjo8X2vn37CtbW1hXqjI6OFgAITk5OQnFxsdi+atUqAYCQnJz80uNctmyZAEBIS0uTaU9MTBQACOPGjZNpnzVrlgBAOH78uNhmbW0t9O3bV9yvRCIRQkJCxOWK+JyU73fUqFEvPLawsLAK/w6enp5C8+bNhaKiIpn6OnXqJDRt2lRsmz59ugBAiI2NFdtycnIEQ0PDSs8XUU3hJT8iBevRowdiYmLw4Ycf4uLFiwgLC4O3tzcaNmwoc7li7969KCsrg6+vL+7duye+zM3N0bRp0wqjH3p6evj444/F9xoaGujQoQP+/vvvV9aUmJiI1NRUDB8+HP/++6+4r4KCAnh6euLkyZMVLpFMnDhR5n2XLl3w77//Ii8vDwAQGRmJsrIyBAUFQUVF9ldL+W0Mjh49iocPH2LYsGEyx6iqqoqOHTuKx6itrQ0NDQ1IpVI8ePDglcfzMoo4r4cOHULDhg3x4Ycfim1aWloYP358tevz9/eHhoaG+L58JLEq/46V+eOPPwAAgYGBMu0zZ84EAPz+++8VtgkLC8O0adOwdOlSLFiwQGxXxOfkVaKjozFv3jxMmTIFI0eOBADcv38fx48fh6+vLx49eiTW8e+//8Lb2xupqan4559/xON///33ZUbOTExMMGLEiCrtn+h18ZIf0RvQvn177N27F0+ePMHFixexb98+fPPNNxg8eDASExPh7OyM1NRUCIKApk2bVtqHurq6zPtGjRpVuN9SvXr1kJSU9Mp6UlNTAQCjRo164Tq5ubmoV6+e+N7KyqrCvoBnl8gMDAxw48YNqKiowNnZ+ZX77d69e6XLDQwMADybtLx06VLMnDkTZmZmeP/99/HBBx/Az88P5ubmrzy+5/dZ0+f11q1bsLOzq7BekyZNqlUb8PLz+jpu3boFFRWVCrWYm5vDyMgIt27dkmk/ceIEfv/9d8ydO1dm3hSgmM/Jy9y5cwdDhgyBm5sbVqxYIbZfv34dgiDg888/x+eff17ptjk5OWjYsCFu3bqFjh07Vlju4ODw0n0TyYuBiugN0tDQQPv27dG+fXvY29vD398fe/bswcKFC1FWVgaJRIKDBw9CVVW1wrbPz72pbB0AEAThlXWUjyosW7YMrVq1qnSdmtzf8/v94YcfKg1Gamr//1fS9OnT0a9fP0RGRuLw4cP4/PPPERoaiuPHj6N169bV2uebOq+vQ1H7q+rNTZs1a4aHDx/ihx9+wCeffAJbW1tx2Zv8nDx58gSDBw+GpqYmdu/eLfNZKK9j1qxZ8Pb2rnT71wmzRDWJgYpISdq1awcAyMzMBADY2dlBEATY2trC3t6+Rvbxoj+qdnZ2AJ6NCHl5edXIvuzs7FBWVoa//vrrhX98y/drampapf3a2dlh5syZmDlzJlJTU9GqVSssX74cP/74Y7Xqqunzam1tjb/++guCIMic48q+naeou7a/qF9ra2uUlZUhNTUVTk5OYnt2djYePnwIa2trmfWNjY3x888/o3PnzvD09MSpU6dgaWkJQDGfkxeZOnUqEhMTcfLkSZiZmckse++99wA8G018VR3W1tbiyNp/paSk1FyxRJXgHCoiBYuOjq70/52Xz3UpvxQxcOBAqKqqYtGiRRXWFwQB//77b7X3raurCwAVbv7Ytm1b2NnZ4euvv0Z+fn6F7e7evVvtffn4+EBFRQVffPFFhXk15cfj7e0NAwMDfPnllygpKXnhfh8/foyioiKZZXZ2dtDX16/SV///SxHn1dvbG//884/MHLiioqJKb1apq6uL3Nzcau/jVV70b9unTx8AqHAz0fJLaH379q3QV6NGjXDs2DEUFhaiR48e4jlRxOekMps3b8batWuxevXqCt8aBJ4FcA8PD6xdu1b8PyAvqqNPnz44e/Yszp07J7N8+/btNVIr0YtwhIpIwaZMmYLHjx9jwIABcHR0xJMnT3DmzBns2rULNjY28Pf3B/AsMCxevBjz5s3DzZs34ePjA319faSlpWHfvn2YMGECZs2aVa1929nZwcjICBEREdDX14euri46duwIW1tbbNiwAb1790azZs3g7++Phg0b4p9//kF0dDQMDAzw22+/VWtfTZo0wfz58xESEoIuXbpg4MCB0NTURFxcHCwtLREaGgoDAwOsWbMGI0eORJs2bTB06FCYmJggPT0dv//+O9zc3BAeHo5r167B09MTvr6+cHZ2hpqaGvbt24fs7GwMHTq02uegps/rJ598gvDwcAwbNgzTpk2DhYUFtm/fDi0tLQCyo0dt27bFrl27EBgYiPbt20NPTw/9+vWr1v4q07ZtWwDPbs0wdOhQqKuro1+/fmjZsiVGjRqFdevW4eHDh+jatSvOnTuHrVu3wsfHB926dau0vyZNmuDIkSPw8PCAt7c3jh8/DgMDgxr/nDzv3r17+PTTT+Hs7AxNTc0Ko48DBgyArq4uVq9ejc6dO6N58+YYP3483nvvPWRnZyMmJgZ37tzBxYsXAQBz5szBDz/8gF69emHatGnibROsra2rNL+Q6LW98e8VEr1jDh48KIwZM0ZwdHQU9PT0BA0NDaFJkybClClThOzs7Arr//LLL0Lnzp0FXV1dQVdXV3B0dBQCAgKElJQUcZ2uXbsKzZo1q7DtqFGjKnxF/9dffxWcnZ0FNTW1CrdQuHDhgjBw4EChQYMGgqampmBtbS34+voKUVFR4jrlX4e/e/euTL+bN2+u9GvomzZtElq3bi1oamoK9erVE7p27SocPXpUZp3o6GjB29tbMDQ0FLS0tAQ7Ozth9OjRwvnz5wVBEIR79+4JAQEBgqOjo6CrqysYGhoKHTt2FHbv3v3Sc/3fep9X0+f177//Fvr27Stoa2sLJiYmwsyZM4VffvlFACCcPXtWXC8/P18YPny4YGRkJAAQ+ym/bcKePXtk+k1LS6v0VheVCQkJERo2bCioqKjI/FuUlJQIixYtEmxtbQV1dXWhcePGwrx582RuOSAIsrdNKBcbGyvo6+sL7u7uwuPHjwVBqPnPyX9vm1B+vC96/Xe7GzduCH5+foK5ubmgrq4uNGzYUPjggw+En3/+WWafSUlJQteuXQUtLS2hYcOGQkhIiLBx40beNoEUSiIICpppSUT0jlm5ciVmzJiBO3fuoGHDhsouh4jeIAYqIqLXUFhYKHP37aKiIrRu3RqlpaW4du2aEisjImXgHCoiotcwcOBAWFlZoVWrVsjNzcWPP/6Iq1evcvIz0TuKgYqI6DV4e3tjw4YN2L59O0pLS+Hs7IydO3diyJAhyi6NiJSAl/yIiIiI5MT7UBERERHJiYGKiIiISE6cQ1VDysrKkJGRAX19fYU9aoKIiIhqliAIePToESwtLaGi8vrjTAxUNSQjIwONGzdWdhlERET0Gm7fvo1GjRq99vYMVDVEX18fwLN/EAMDAyVXQ0RERFWRl5eHxo0bi3/HXxcDVQ0pv8xnYGDAQEVERFTHyDtdh5PSiYiIiOTEQEVEREQkJwYqIiIiIjlxDhURESlMaWkpSkpKlF0GvcPU1dWhqqqq8P0wUBERUY0TBAFZWVl4+PChskshgpGREczNzRV6n0gGKiIiqnHlYcrU1BQ6Ojq84TEphSAIePz4MXJycgAAFhYWCtsXAxUREdWo0tJSMUw1aNBA2eXQO05bWxsAkJOTA1NTU4Vd/uOkdCIiqlHlc6Z0dHSUXAnRM+WfRUXO52OgIiIiheBlPqot3sRnkYGKiIiISE4MVERERHWIRCJBZGSksst4JRsbG6xcuVLZZbwxnJRORERvTLBU+mb35+HxWtvdvn0bCxcuxKFDh3Dv3j1YWFjAx8cHQUFBb2yifXBwMCIjI5GYmCjTnpmZiXr16r2RGoBnwWj69OmYPn36G9tnXcQRKiIiov/4+++/0a5dO6SmpuKnn37C9evXERERgaioKLi6uuL+/ftKrc/c3ByamppKrYEqYqAiIiL6j4CAAGhoaODIkSPo2rUrrKys0Lt3bxw7dgz//PMP5s+fD6DyS29GRkbYsmWL+P727dvw9fWFkZER6tevj/79++PmzZvicqlUig4dOkBXVxdGRkZwc3PDrVu3sGXLFixatAgXL16ERCKBRCIR+31+v8nJyejevTu0tbXRoEEDTJgwAfn5+eLy0aNHw8fHB19//TUsLCzQoEEDBAQEVOkbbx4eHrh16xZmzJgh1lHul19+QbNmzaCpqQkbGxssX778pX1t2LABRkZGiIqKAgBcunQJvXv3hp6eHszMzDBy5Ejcu3dPZt9Tp07FnDlzUL9+fZibmyM4OFhcLggCgoODYWVlBU1NTVhaWmLq1KmvPCZFYaAiIiL6P/fv38fhw4fx6aefivcvKmdubo4RI0Zg165dEAThlX2VlJTA29sb+vr6+PPPP3H69Gno6emhV69eePLkCZ4+fQofHx907doVSUlJiImJwYQJEyCRSDBkyBDMnDkTzZo1Q2ZmJjIzMzFkyJAK+ygoKIC3tzfq1auHuLg47NmzB8eOHcPkyZNl1ouOjsaNGzcQHR2NrVu3YsuWLTLB70X27t2LRo0a4YsvvhDrAID4+Hj4+vpi6NChSE5ORnBwMD7//PMX9hkWFobPPvsMR44cgaenJx4+fIju3bujdevWOH/+PA4dOoTs7Gz4+vrKbLd161bo6uoiNjYWYWFh+OKLL3D06FEAzwLdN998g7Vr1yI1NRWRkZFo3rz5K49JUTiH6h0mDZYqpF+PYA+F9EtEpGipqakQBAFOTk6VLndycsKDBw9w9+7dV/a1a9culJWVYcOGDeLIzubNm2FkZASpVIp27dohNzcXH3zwAezs7MT+y+np6UFNTQ3m5uYv3MeOHTtQVFSEbdu2QVdXFwAQHh6Ofv36YenSpTAzMwMA1KtXD+Hh4VBVVYWjoyP69u2LqKgojB8//qXHUL9+faiqqkJfX1+mjhUrVsDT0xOff/45AMDe3h5//fUXli1bhtGjR8v0MXfuXPzwww84ceIEmjVrJtbYunVrfPnll+J6mzZtQuPGjXHt2jXY29sDAFq0aIGFCxcCAJo2bYrw8HBERUWhR48eSE9Ph7m5Oby8vKCurg4rKyt06NDhpcejSByhIiIies6rRqA0NDRe2cfFixdx/fp16OvrQ09PD3p6eqhfvz6Kiopw48YN1K9fH6NHj4a3tzf69euHVatWiSNAVXXlyhW0bNlSDFMA4ObmhrKyMqSkpIhtzZo1k7lDuIWFhfg4ltdx5coVuLm5ybS5ubkhNTUVpaWlYtvy5cuxfv16nDp1SgxTwLNzEx0dLZ4XPT09ODo6AgBu3LghrteiRQuZffy37o8++giFhYV47733MH78eOzbtw9Pnz597WOSFwMVERHR/2nSpAkkEgmuXLlS6fIrV67AxMQERkZGkEgkFYLXf+cl5efno23btkhMTJR5Xbt2DcOHDwfwbMQqJiYGnTp1wq5du2Bvb4+zZ8/W+HGpq6vLvJdIJCgrK6vx/TyvS5cuKC0txe7du2Xa8/Pz0a9fvwrnJjU1Fe7u7lWqu3HjxkhJScH3338PbW1tfPrpp3B3d1fo3dBfhoGKiIjo/zRo0AA9evTA999/j8LCQpllWVlZ2L59u3hJy8TERGZEKTU1FY8fPxbft2nTBqmpqTA1NUWTJk1kXoaGhuJ6rVu3xrx583DmzBm4uLhgx44dAJ6Ngv13tKcyTk5OuHjxIgoKCsS206dPQ0VFBQ4ODq99Hv6rsjqcnJxw+vRpmbbTp0/D3t5eZiSsQ4cOOHjwIL788kt8/fXXYnubNm1w+fJl2NjYVDg3/x1texVtbW3069cP3377LaRSKWJiYpCcnPyaRyofBioiIqL/CA8PR3FxMby9vXHy5Encvn0bhw4dQo8ePWBvb4+goCAAQPfu3REeHo4LFy7g/PnzmDhxosyIyogRI2BsbIz+/fvjzz//RFpaGqRSKaZOnYo7d+4gLS0N8+bNQ0xMDG7duoUjR44gNTVVnEdlY2ODtLQ0JCYm4t69eyguLq5Q64gRI6ClpYVRo0bh0qVLiI6OxpQpUzBy5Ehx/pS8bGxscPLkSfzzzz/it/BmzpyJqKgohISE4Nq1a9i6dSvCw8Mxa9asCtt36tQJf/zxBxYtWiTe6DMgIAD379/HsGHDEBcXhxs3buDw4cPw9/d/ZYgst2XLFmzcuBGXLl3C33//jR9//BHa2tqwtraukeOuLgYqIiKi/2jatCni4uLw3nvvwdfXF9bW1ujduzfs7e3Fb+oBz+YHNW7cGF26dMHw4cMxa9YsmQdC6+jo4OTJk7CyssLAgQPh5OSEsWPHoqioCAYGBtDR0cHVq1cxaNAg2NvbY8KECQgICMAnn3wCABg0aBB69eqFbt26wcTEBD/99FOFWnV0dHD48GHcv38f7du3x+DBg+Hp6Ynw8PAaOx9ffPEFbt68CTs7O5iYmAB4NsK0e/du7Ny5Ey4uLggKCsIXX3xRYUJ6uc6dO+P333/HggUL8N1338HS0hKnT59GaWkpevbsiebNm2P69OkwMjKCikrVoomRkRHWr18PNzc3tGjRAseOHcNvv/32xm68+jyJUJXvftIr5eXlwdDQELm5uTAwMFB2OVXCb/kRkSIUFRUhLS0Ntra20NLSUnY5NWLhwoVYsWIFjh49ivfff1/Z5VA1vewzWVN/v3nbBCIioldYtGgRbGxscPbsWXTo0KHKoyj07mCgIiIiqgJ/f39ll1Dj/vzzT/Tu3fuFy/97x3V6OQYqIiKid1S7du0qPHyZXg8DFRER0TtKW1sbTZo0UXYZb4VacxH4q6++gkQiwfTp08W2oqIiBAQEoEGDBtDT08OgQYOQnZ390n4EQUBQUBAsLCygra0NLy8vpKamisuLi4sxcuRIGBgYwN7eHseOHZPZftmyZZgyZUqNHhsRERG93WpFoIqLi8PatWsr3GJ+xowZ+O2337Bnzx6cOHECGRkZGDhw4Ev7CgsLw7fffouIiAjExsZCV1cX3t7eKCoqAgCsW7cO8fHx4kMohw8fLt7pNi0tDevXr8eSJUsUc6BERET0VlJ6oMrPz8eIESOwfv161KtXT2zPzc3Fxo0bsWLFCnTv3h1t27bF5s2bcebMmRfell8QBKxcuRILFixA//790aJFC2zbtg0ZGRmIjIwE8OyxAR9++CGaNWuGgIAA3L17V7xR2aRJk7B06dI6c9sDIiIiqh2UHqgCAgLQt29feHl5ybTHx8ejpKREpt3R0RFWVlaIiYmptK+0tDRkZWXJbGNoaIiOHTuK27Rs2RKnTp1CYWEhDh8+DAsLCxgbG2P79u3Q0tLCgAEDqlR3cXEx8vLyZF5ERET0blLqpPSdO3ciISEBcXFxFZZlZWVBQ0MDRkZGMu1mZmbIysqqtL/y9udvt//fbcaMGYOkpCQ4OzvD2NgYu3fvxoMHDxAUFASpVIoFCxZg586dsLOzw6ZNm9CwYcNK9xUaGopFixZV95CJiIjoLaS0Earbt29j2rRp4sjQm6Kuro7Vq1cjLS0NcXFx6Ny5M2bOnImpU6fiwoULiIyMxMWLF/H+++9j6tSpL+xn3rx5yM3NFV+3b99+Y8dARET0pnl4eMh8cYxkKW2EKj4+Hjk5OWjTpo3YVlpaipMnTyI8PByHDx/GkydP8PDhQ5lRquzsbJibm1faZ3l7dnY2LCwsZLZp1apVpdtER0fj8uXL2LBhA2bPno0+ffpAV1cXvr6+L30WkqamJjQ1NatxxEREpKhHXr3I6z4KKyYmBp07d0avXr3w+++/12xRSubh4YFWrVqJDyqmmqG0ESpPT08kJycjMTFRfLVr1w4jRowQ/1tdXR1RUVHiNikpKUhPT4erq2ulfdra2sLc3Fxmm7y8PMTGxla6TfltGdauXQtVVVWUlpaipKQEAFBSUlLlJ14TEdHbZePGjZgyZQpOnjyJjIwMZZdTZU+ePFF2Ce8spQUqfX19uLi4yLx0dXXRoEEDuLi4wNDQEGPHjkVgYCCio6MRHx8Pf39/uLq6yjyY0tHREfv27QMA8T5Wixcvxv79+5GcnAw/Pz9YWlrCx8enQg0hISHo06cPWrduDQBwc3PD3r17kZSUhPDwcLi5ub2Rc0FERLVHfn4+du3ahUmTJqFv377YsmWLuEwqlUIikSAqKgrt2rWDjo4OOnXqhJSUFHGdixcvolu3btDX14eBgQHatm2L8+fPQxAEmJiY4OeffxbXbdWqlcwVlVOnTkFTUxOPHz8GADx8+BDjxo2DiYkJDAwM0L17d1y8eFFcPzg4GK1atcKGDRuq9DDq0aNH48SJE1i1ahUkEgkkEglu3rwJADhx4gQ6dOgATU1NWFhY4LPPPsPTp09f2Nfvv/8OQ0NDbN++HcCzqTy+vr4wMjJC/fr10b9/f7Hv8n37+Pjg66+/hoWFBRo0aICAgABxIAMAvv/+ezRt2hRaWlowMzPD4MGDX3o8tYnSv+X3Mt988w0++OADDBo0CO7u7jA3N8fevXtl1klJSUFubq74fs6cOZgyZQomTJiA9u3bIz8/H4cOHarwIbt06RJ2794tM7F88ODB6Nu3L7p06YKkpCSsWrVKsQdIRES1zu7du+Ho6AgHBwd8/PHH2LRpk3i/wnLz58/H8uXLcf78eaipqWHMmDHishEjRqBRo0aIi4tDfHw8PvvsM6irq0MikcDd3R1SqRQA8ODBA1y5cgWFhYW4evUqgGehpn379tDR0QEAfPTRR8jJycHBgwcRHx+PNm3awNPTE/fv3xf3d/36dfzyyy/Yu3fvKx8js2rVKri6umL8+PHIzMxEZmYmGjdujH/++Qd9+vRB+/btcfHiRaxZswYbN27E4sWLK+1nx44dGDZsGLZv344RI0agpKQE3t7e0NfXx59//onTp09DT08PvXr1khk1i46Oxo0bNxAdHY2tW7diy5YtYmA9f/48pk6dii+++AIpKSk4dOgQ3N3dq/RvVhvUqkfPlH/IymlpaWH16tVYvXr1C7d5/kMukUjwxRdf4IsvvnjpvlxcXGTuoA4AKioq+P777/H9999Xr3AiInprbNy4ER9//DEAoFevXsjNzcWJEyfg4eEhrrNkyRJ07doVAPDZZ5+hb9++KCoqgpaWFtLT0zF79mw4OjoCAJo2bSpu5+HhgbVr1wIATp48idatW8Pc3BxSqRSOjo6QSqViv6dOncK5c+eQk5Mjztn9+uuvERkZiZ9//hkTJkwA8Owy37Zt22BiYvLKYzM0NISGhgZ0dHRk5iN///33aNy4McLDwyGRSODo6IiMjAzMnTsXQUFBUFH5/+Mvq1evxvz58/Hbb7+Jte7atQtlZWXYsGEDJBIJAGDz5s0wMjKCVCpFz549AQD16tVDeHg4VFVV4ejoiL59+yIqKgrjx49Heno6dHV18cEHH0BfXx/W1tbiFaS6oFaPUBEREb1JKSkpOHfuHIYNGwYAUFNTw5AhQ7Bx40aZ9f77ZI/yS3Y5OTkAgMDAQIwbNw5eXl746quvcOPGDXHdrl274q+//sLdu3fFkObh4QGpVIqSkhKcOXNGDG4XL15Efn6++Pi18ldaWppMn9bW1lUKUy9z5coVuLq6imEIeDYNJj8/H3fu3BHbfv75Z8yYMQNHjx4Vw1R5rdevX4e+vr5YZ/369VFUVCRTa7NmzaCqqipz7srPW48ePWBtbY333nsPI0eOxPbt28VLn3VBrRqhIiIiUqaNGzfi6dOnsLS0FNsEQYCmpqbMN7/V1dXF/y4PIWVlZQCezWsaPnw4fv/9dxw8eBALFy7Ezp07MWDAADRv3hz169fHiRMncOLECSxZsgTm5uZYunQp4uLiUFJSgk6dOgF4NpfLwsKiwtUbADLfftfV1a3JU/BSrVu3RkJCAjZt2oR27dqJx56fn4+2bduK86n+679h77/nDXh27srPm76+PhISEiCVSnHkyBEEBQUhODgYcXFxFe5JWRsxUBEREQF4+vQptm3bhuXLl4uXqMr5+Pjgp59+Ei/jvYq9vT3s7e0xY8YMDBs2DJs3b8aAAQMgkUjQpUsX/Prrr7h8+TI6d+4MHR0dFBcXY+3atWjXrp0YkNq0aYOsrCyoqanBxsamxo5TQ0OjwrfYnZyc8Msvv0AQBDEknT59Gvr6+mjUqJG4np2dHZYvXw4PDw+oqqqKIbNNmzbYtWsXTE1N5Xp8m5qaGry8vODl5YWFCxfCyMgIx48ff+VzfGsDXvIjIiICcODAATx48ABjx46t8C30QYMGVbjsV5nCwkJMnjwZUqkUt27dwunTpxEXFwcnJydxHQ8PD/z0009o1aoV9PT0oKKiAnd3d2zfvl3mMpqXlxdcXV3h4+ODI0eO4ObNmzhz5gzmz5+P8+fPv/Zx2tjYIDY2Fjdv3sS9e/dQVlaGTz/9FLdv38aUKVNw9epV/Prrr1i4cCECAwNl5k8Bz8JidHQ0fvnlF/FGnyNGjICxsTH69++PP//8E2lpaZBKpZg6darMJcOXOXDgAL799lskJibi1q1b2LZtG8rKyuDg4PDax/omMVARERHh2eU+Ly8vGBoaVlg2aNAgnD9/HklJSS/tQ1VVFf/++y/8/Pxgb28PX19f9O7dW+Yb5V27dkVpaanMJHcPD48KbRKJBH/88Qfc3d3h7+8Pe3t7DB06FLdu3arwiLXqmDVrFlRVVeHs7AwTExOkp6ejYcOG+OOPP3Du3Dm0bNkSEydOxNixY7FgwYJK+3BwcMDx48fx008/YebMmdDR0cHJkydhZWWFgQMHwsnJCWPHjkVRUVGVR6yMjIywd+9edO/eHU5OToiIiMBPP/2EZs2avfaxvkkS4fmvydFrycvLg6GhIXJzc+Ua7nyTFHXH4te9MzERvR2KioqQlpZWpfsiEb0JL/tM1tTfb45QEREREcmJgYqIiOgtkZ6eLnOLhedf6enpyi7xrcVv+REREb0lLC0tX3q39P/eDoJqFgMVERHRW0JNTQ1NmjRRdhnvJF7yIyIiIpITAxURESlE+R2wiZTtTXwWecmPiIhqlIaGBlRUVJCRkQETExNoaGjIPCOO6E0RBAFPnjzB3bt3oaKiAg0NDYXti4GKiIhqlIqKCmxtbZGZmYmMjAxll0MEHR0dWFlZVbjre01ioCIiohqnoaEBKysrPH36tMJz44jeJFVVVaipqSl8lJSBioiIFEIikUBdXR3q6urKLoVI4TgpnYiIiEhODFREREREcmKgIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJwYqIiIiIjkxUBERERHJiYGKiIiISE4MVERERERyYqAiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOSk1UK1ZswYtWrSAgYEBDAwM4OrqioMHD4rLPTw8IJFIZF4TJ058aZ+CICAoKAgWFhbQ1taGl5cXUlNTxeXFxcUYOXIkDAwMYG9vj2PHjslsv2zZMkyZMqVmD5SIiIjeakoNVI0aNcJXX32F+Ph4nD9/Ht27d0f//v1x+fJlcZ3x48cjMzNTfIWFhb20z7CwMHz77beIiIhAbGwsdHV14e3tjaKiIgDAunXrEB8fj5iYGEyYMAHDhw+HIAgAgLS0NKxfvx5LlixR3EETERHRW0epgapfv37o06cPmjZtCnt7eyxZsgR6eno4e/asuI6Ojg7Mzc3Fl4GBwQv7EwQBK1euxIIFC9C/f3+0aNEC27ZtQ0ZGBiIjIwEAV65cwYcffohmzZohICAAd+/exb179wAAkyZNwtKlS1+6DyIiIqLn1Zo5VKWlpdi5cycKCgrg6uoqtm/fvh3GxsZwcXHBvHnz8Pjx4xf2kZaWhqysLHh5eYlthoaG6NixI2JiYgAALVu2xKlTp1BYWIjDhw/DwsICxsbG2L59O7S0tDBgwIAq1VtcXIy8vDyZFxEREb2b1JRdQHJyMlxdXVFUVAQ9PT3s27cPzs7OAIDhw4fD2toalpaWSEpKwty5c5GSkoK9e/dW2ldWVhYAwMzMTKbdzMxMXDZmzBgkJSXB2dkZxsbG2L17Nx48eICgoCBIpVIsWLAAO3fuhJ2dHTZt2oSGDRtWuq/Q0FAsWrSopk4DERER1WFKD1QODg5ITExEbm4ufv75Z4waNQonTpyAs7MzJkyYIK7XvHlzWFhYwNPTEzdu3ICdnd1r7U9dXR2rV6+WafP398fUqVNx4cIFREZG4uLFiwgLC8PUqVPxyy+/VNrPvHnzEBgYKL7Py8tD48aNX6smIiIiqtuUfslPQ0MDTZo0Qdu2bREaGoqWLVti1apVla7bsWNHAMD169crXW5ubg4AyM7OlmnPzs4Wlz0vOjoaly9fxuTJkyGVStGnTx/o6urC19cXUqn0hXVramqK304sfxEREdG7SemB6nllZWUoLi6udFliYiIAwMLCotLltra2MDc3R1RUlNiWl5eH2NhYmXlZ5YqKihAQEIC1a9dCVVUVpaWlKCkpAQCUlJSgtLRUzqMhIiKid4FSA9W8efNw8uRJ3Lx5E8nJyZg3bx6kUilGjBiBGzduICQkBPHx8bh58yb2798PPz8/uLu7o0WLFmIfjo6O2LdvHwBAIpFg+vTpWLx4Mfbv34/k5GT4+fnB0tISPj4+FfYfEhKCPn36oHXr1gAANzc37N27F0lJSQgPD4ebm9sbOQ9ERERUtyl1DlVOTg78/PyQmZkJQ0NDtGjRAocPH0aPHj1w+/ZtHDt2DCtXrkRBQQEaN26MQYMGYcGCBTJ9pKSkIDc3V3w/Z84cFBQUYMKECXj48CE6d+6MQ4cOQUtLS2a7S5cuYffu3eKoFwAMHjwYUqkUXbp0gYODA3bs2KHQ4yciIqK3g0Qov6slySUvLw+GhobIzc2tM/OppMFShfTrEeyhkH6JiIhqWk39/a51c6iIiIiI6hoGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcmKgIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJwYqIiIiIjkxUBERERHJiYGKiIiISE4MVERERERyYqAiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOTFQEREREcmJgYqIiIhITgxURERERHJioCIiIiKSEwMVERERkZwYqIiIiIjkxEBFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcmKgIiIiIpITAxURERGRnJQaqNasWYMWLVrAwMAABgYGcHV1xcGDB8XlRUVFCAgIQIMGDaCnp4dBgwYhOzv7pX0KgoCgoCBYWFhAW1sbXl5eSE1NFZcXFxdj5MiRMDAwgL29PY4dOyaz/bJlyzBlypSaPVAiIiJ6qyk1UDVq1AhfffUV4uPjcf78eXTv3h39+/fH5cuXAQAzZszAb7/9hj179uDEiRPIyMjAwIEDX9pnWFgYvv32W0RERCA2Nha6urrw9vZGUVERAGDdunWIj49HTEwMJkyYgOHDh0MQBABAWloa1q9fjyVLlij2wImIiOitIhHK00QtUb9+fSxbtgyDBw+GiYkJduzYgcGDBwMArl69CicnJ8TExOD999+vsK0gCLC0tMTMmTMxa9YsAEBubi7MzMywZcsWDB06FJ9++ikMDAzw1VdfobCwEDo6OsjJyYGJiQl69eqFTz75BAMGDKh23Xl5eTA0NERubi4MDAzkOwlviDRYqpB+PYI9FNIvERFRTaupv9+1Zg5VaWkpdu7ciYKCAri6uiI+Ph4lJSXw8vIS13F0dISVlRViYmIq7SMtLQ1ZWVky2xgaGqJjx47iNi1btsSpU6dQWFiIw4cPw8LCAsbGxti+fTu0tLSqHKaKi4uRl5cn8yIiIqJ3k5qyC0hOToarqyuKioqgp6eHffv2wdnZGYmJidDQ0ICRkZHM+mZmZsjKyqq0r/J2MzOzF24zZswYJCUlwdnZGcbGxti9ezcePHiAoKAgSKVSLFiwADt37oSdnR02bdqEhg0bVrqv0NBQLFq0SM6jJyIioreB0keoHBwckJiYiNjYWEyaNAmjRo3CX3/9pbD9qaurY/Xq1UhLS0NcXBw6d+6MmTNnYurUqbhw4QIiIyNx8eJFvP/++5g6deoL+5k3bx5yc3PF1+3btxVWMxEREdVuSh+h0tDQQJMmTQAAbdu2RVxcHFatWoUhQ4bgyZMnePjwocwoVXZ2NszNzSvtq7w9OzsbFhYWMtu0atWq0m2io6Nx+fJlbNiwAbNnz0afPn2gq6sLX19fhIeHv7BuTU1NaGpqVvNo3w2KmJvFeVlERFSbKX2E6nllZWUoLi5G27Ztoa6ujqioKHFZSkoK0tPT4erqWum2tra2MDc3l9kmLy8PsbGxlW5TfluGtWvXQlVVFaWlpSgpKQEAlJSUoLS0tIaPjoiIiN5GSg1U8+bNw8mTJ3Hz5k0kJydj3rx5kEqlGDFiBAwNDTF27FgEBgYiOjoa8fHx8Pf3h6urq8w3/BwdHbFv3z4AgEQiwfTp07F48WLs378fycnJ8PPzg6WlJXx8fCrsPyQkBH369EHr1q0BAG5ubti7dy+SkpIQHh4ONze3N3IeiIiIqG5T6iW/nJwc+Pn5ITMzE4aGhmjRogUOHz6MHj16AAC++eYbqKioYNCgQSguLoa3tze+//57mT5SUlKQm5srvp8zZw4KCgowYcIEPHz4EJ07d8ahQ4egpaUls92lS5ewe/duJCYmim2DBw+GVCpFly5d4ODggB07diju4ImIiOitUevuQ1VX8T5UisU5VEREpAhv3X2oiIiIiOoqBioiIiIiOTFQEREREcmJgYqIiIhITgxURERERHJioCIiIiKSEwMVERERkZwYqIiIiIjkxEBFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcmKgIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJwYqIiIiIjkxUBERERHJiYGKiIiISE4MVERERERyYqAiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOTFQEREREcmJgYqIiIhITtUOVH///bci6iAiIiKqs6odqJo0aYJu3brhxx9/RFFRkSJqIiIiIqpTqh2oEhIS0KJFCwQGBsLc3ByffPIJzp07p4jaiIiIiOqEageqVq1aYdWqVcjIyMCmTZuQmZmJzp07w8XFBStWrMDdu3er3FdoaCjat28PfX19mJqawsfHBykpKTLreHh4QCKRyLwmTpz40n4FQUBQUBAsLCygra0NLy8vpKamisuLi4sxcuRIGBgYwN7eHseOHZPZftmyZZgyZUqVj4OIiIjeba89KV1NTQ0DBw7Enj17sHTpUly/fh2zZs1C48aN4efnh8zMzFf2ceLECQQEBODs2bM4evQoSkpK0LNnTxQUFMisN378eGRmZoqvsLCwl/YbFhaGb7/9FhEREYiNjYWuri68vb3FS5Tr1q1DfHw8YmJiMGHCBAwfPhyCIAAA0tLSsH79eixZsuQ1zwwRERG9a147UJ0/fx6ffvopLCwssGLFCsyaNQs3btzA0aNHkZGRgf79+7+yj0OHDmH06NFo1qwZWrZsiS1btiA9PR3x8fEy6+no6MDc3Fx8GRgYvLBPQRCwcuVKLFiwAP3790eLFi2wbds2ZGRkIDIyEgBw5coVfPjhh2jWrBkCAgJw9+5d3Lt3DwAwadIkLF269KX7ICIiIvqvageqFStWoHnz5ujUqRMyMjKwbds23Lp1C4sXL4atrS26dOmCLVu2ICEhodrF5ObmAgDq168v0759+3YYGxvDxcUF8+bNw+PHj1/YR1paGrKysuDl5SW2GRoaomPHjoiJiQEAtGzZEqdOnUJhYSEOHz4MCwsLGBsbY/v27dDS0sKAAQNeWWtxcTHy8vJkXkRERPRuUqvuBmvWrMGYMWMwevRoWFhYVLqOqakpNm7cWK1+y8rKMH36dLi5ucHFxUVsHz58OKytrWFpaYmkpCTMnTsXKSkp2Lt3b6X9ZGVlAQDMzMxk2s3MzMRlY8aMQVJSEpydnWFsbIzdu3fjwYMHCAoKglQqxYIFC7Bz507Y2dlh06ZNaNiwYYX9hIaGYtGiRdU6RiIiIno7SYTyyUNKNmnSJBw8eBCnTp1Co0aNXrje8ePH4enpievXr8POzq7C8jNnzsDNzQ0ZGRkygc/X1xcSiQS7du2qtF9/f3+0atUKtra2+N///ofY2FiEhYXh0qVL+OWXXyqsX1xcjOLiYvF9Xl4eGjdujNzc3DpzuVAaLFV2CVXmEeyh7BKIiOgtlJeXB0NDQ7n/flf7kt/mzZuxZ8+eCu179uzB1q1bX6uIyZMn48CBA4iOjn5pmAKAjh07AgCuX79e6XJzc3MAQHZ2tkx7dna2uOx50dHRuHz5MiZPngypVIo+ffpAV1cXvr6+kEqllW6jqakJAwMDmRcRERG9m6odqEJDQ2FsbFyh3dTUFF9++WW1+hIEAZMnT8a+fftw/Phx2NravnKbxMREAHjh5UZbW1uYm5sjKipKbMvLy0NsbCxcXV0rrF9UVISAgACsXbsWqqqqKC0tRUlJCQCgpKQEpaWl1TomIiIievdUO1Clp6dXGnysra2Rnp5erb4CAgLw448/YseOHdDX10dWVhaysrJQWFgIALhx4wZCQkIQHx+PmzdvYv/+/fDz84O7uztatGgh9uPo6Ih9+/YBACQSCaZPn47Fixdj//79SE5Ohp+fHywtLeHj41OhhpCQEPTp0wetW7cGALi5uWHv3r1ISkpCeHg43NzcqnVMRERE9O6p9qR0U1NTJCUlwcbGRqb94sWLaNCgQbX6WrNmDYBnN+/8r82bN2P06NHQ0NDAsWPHsHLlShQUFKBx48YYNGgQFixYILN+SkqK+A1BAJgzZw4KCgowYcIEPHz4EJ07d8ahQ4egpaUls92lS5ewe/ducdQLAAYPHgypVIouXbrAwcEBO3bsqNYxERER0bun2pPS586di127dmHz5s1wd3cH8OwGnWPGjMHgwYPx9ddfK6TQ2q6mJrW9SZyUTkRE77qa+vtd7RGqkJAQ3Lx5E56enlBTe7Z5WVkZ/Pz8qj2HioiIiOhtUO1ApaGhgV27diEkJAQXL16EtrY2mjdvDmtra0XUR0RERFTrVTtQlbO3t4e9vX1N1kJERERUJ1U7UJWWlmLLli2IiopCTk4OysrKZJYfP368xoojIiIiqguqHaimTZuGLVu2oG/fvnBxcYFEIlFEXURERER1RrUD1c6dO7F792706dNHEfUQERER1TnVvrGnhoYGmjRpoohaiIiIiOqkageqmTNnYtWqVaglz1QmIiIiUrpqX/I7deoUoqOjcfDgQTRr1gzq6uoyy/fu3VtjxRERERHVBdUOVEZGRhgwYIAiaiEiIiKqk6odqDZv3qyIOoiIiIjqrGrPoQKAp0+f4tixY1i7di0ePXoEAMjIyEB+fn6NFkdERERUF1R7hOrWrVvo1asX0tPTUVxcjB49ekBfXx9Lly5FcXExIiIiFFEnERERUa1V7RGqadOmoV27dnjw4AG0tbXF9gEDBiAqKqpGiyMiIiKqC6o9QvXnn3/izJkz0NDQkGm3sbHBP//8U2OFEREREdUV1R6hKisrQ2lpaYX2O3fuQF9fv0aKIiIiIqpLqh2oevbsiZUrV4rvJRIJ8vPzsXDhQj6OhoiIiN5J1b7kt3z5cnh7e8PZ2RlFRUUYPnw4UlNTYWxsjJ9++kkRNRIRERHVatUOVI0aNcLFixexc+dOJCUlIT8/H2PHjsWIESNkJqkTERERvSuqHagAQE1NDR9//HFN10JERERUJ1U7UG3btu2ly/38/F67GCIiIqK6qNqBatq0aTLvS0pK8PjxY2hoaEBHR4eBioiIiN451f6W34MHD2Re+fn5SElJQefOnTkpnYiIiN5Jr/Usv+c1bdoUX331VYXRKyIiIqJ3QY0EKuDZRPWMjIya6o6IiIiozqj2HKr9+/fLvBcEAZmZmQgPD4ebm1uNFUZERERUV1Q7UPn4+Mi8l0gkMDExQffu3bF8+fKaqouIiIiozqh2oCorK1NEHURERER1Vo3NoSIiIiJ6V1V7hCowMLDK665YsaK63RMRERHVOdUOVBcuXMCFCxdQUlICBwcHAMC1a9egqqqKNm3aiOtJJJKaq5KIiIioFqv2Jb9+/frB3d0dd+7cQUJCAhISEnD79m1069YNH3zwAaKjoxEdHY3jx4+/sq/Q0FC0b98e+vr6MDU1hY+PD1JSUmTWKSoqQkBAABo0aAA9PT0MGjQI2dnZL+1XEAQEBQXBwsIC2tra8PLyQmpqqri8uLgYI0eOhIGBAezt7XHs2DGZ7ZctW4YpU6ZU46wQERHRu6zagWr58uUIDQ1FvXr1xLZ69eph8eLF1f6W34kTJxAQEICzZ8/i6NGjKCkpQc+ePVFQUCCuM2PGDPz222/Ys2cPTpw4gYyMDAwcOPCl/YaFheHbb79FREQEYmNjoaurC29vbxQVFQEA1q1bh/j4eMTExGDChAkYPnw4BEEAAKSlpWH9+vVYsmRJtY6FiIiI3l3VvuSXl5eHu3fvVmi/e/cuHj16VK2+Dh06JPN+y5YtMDU1RXx8PNzd3ZGbm4uNGzdix44d6N69OwBg8+bNcHJywtmzZ/H+++9X6FMQBKxcuRILFixA//79ATx7oLOZmRkiIyMxdOhQXLlyBR9++CGaNWuG9957D7Nnz8a9e/dgYmKCSZMmYenSpTAwMKjWsRApWrBUWvN9enjUeJ9ERO+iao9QDRgwAP7+/ti7dy/u3LmDO3fu4JdffsHYsWNfOXL0Krm5uQCA+vXrAwDi4+NRUlICLy8vcR1HR0dYWVkhJiam0j7S0tKQlZUls42hoSE6duwobtOyZUucOnUKhYWFOHz4MCwsLGBsbIzt27dDS0sLAwYMeGWtxcXFyMvLk3kRERHRu6naI1QRERGYNWsWhg8fjpKSkmedqKlh7NixWLZs2WsXUlZWhunTp8PNzQ0uLi4AgKysLGhoaMDIyEhmXTMzM2RlZVXaT3m7mZnZC7cZM2YMkpKS4OzsDGNjY+zevRsPHjxAUFAQpFIpFixYgJ07d8LOzg6bNm1Cw4YNK+wnNDQUixYteu3jJSIiordHtQOVjo4Ovv/+eyxbtgw3btwAANjZ2UFXV1euQgICAnDp0iWcOnVKrn6qQl1dHatXr5Zp8/f3x9SpU3HhwgVERkbi4sWLCAsLw9SpU/HLL79U6GPevHkyt5DIy8tD48aNFV47ERER1T7VDlTlMjMzkZmZCXd3d2hra0MQhNe+VcLkyZNx4MABnDx5Eo0aNRLbzc3N8eTJEzx8+FBmlCo7Oxvm5uaV9lXenp2dDQsLC5ltWrVqVek20dHRuHz5MjZs2IDZs2ejT58+0NXVha+vL8LDwyvdRlNTE5qamtU8UnoXKGKuExER1W7VnkP177//wtPTE/b29ujTpw8yMzMBAGPHjsXMmTOr1ZcgCJg8eTL27duH48ePw9bWVmZ527Ztoa6ujqioKLEtJSUF6enpcHV1rbRPW1tbmJuby2yTl5eH2NjYSrcpvy3D2rVroaqqitLSUvFSZklJCUpLS6t1TERERPTuqXagmjFjBtTV1ZGeng4dHR2xfciQIRW+tfcqAQEB+PHHH7Fjxw7o6+sjKysLWVlZKCwsBPBsMvnYsWMRGBiI6OhoxMfHw9/fH66urjLf8HN0dMS+ffsAPLuh6PTp07F48WLs378fycnJ8PPzg6WlZYUHOwNASEgI+vTpg9atWwMA3NzcsHfvXiQlJSE8PBxubm7VPUVERET0jqn2Jb8jR47g8OHDMpfmAKBp06a4detWtfpas2YNAMDjua9ub968GaNHjwYAfPPNN1BRUcGgQYNQXFwMb29vfP/99zLrp6SkiN8QBIA5c+agoKAAEyZMwMOHD9G5c2ccOnQIWlpaMttdunQJu3fvRmJiotg2ePBgSKVSdOnSBQ4ODtixY0e1jomIiIjePRKh/I6WVaSvr4+EhAQ0bdoU+vr6uHjxIt577z2cP38e3t7e+PfffxVVa62Wl5cHQ0ND5Obm1pl7WEmDpcouoco8gj2UXUKV1aU5VLwPFRG962rq73e1L/l16dIF27ZtE99LJBKUlZUhLCwM3bp1e+1CiIiIiOqqal/yCwsLg6enJ86fP48nT55gzpw5uHz5Mu7fv4/Tp08rokYiIiKiWq3aI1QuLi64du0aOnfujP79+6OgoAADBw7EhQsXYGdnp4gaiYiIiGq1ao1QlZSUoFevXoiIiMD8+fMVVRMRERFRnVKtESp1dXUkJSUpqhYiIiKiOqnal/w+/vhjbNy4URG1EBEREdVJ1Z6U/vTpU2zatAnHjh1D27ZtKzzDb8WKFTVWHBEREVFdUKVAlZSUBBcXF6ioqODSpUto06YNAODatWsy673us/yIiIiI6rIqBarWrVsjMzMTpqamuHXrFuLi4tCgQQNF10ZERERUJ1RpDpWRkRHS0tIAADdv3kRZWZlCiyIiIiKqS6o0QjVo0CB07doVFhYWkEgkaNeuHVRVVStd9++//67RAomIiIhquyoFqnXr1mHgwIG4fv06pk6divHjx0NfX1/RtRERERHVCVX+ll+vXr0AAPHx8Zg2bRoDFREREdH/qfZtEzZv3qyIOoiIiIjqrGrf2JOIiIiIZDFQEREREcmJgYqIiIhITgxURERERHJioCIiIiKSEwMVERERkZwYqIiIiIjkxEBFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcqr2w5GJ6O0RLJXWfJ8eHjXeJxFRbccRKiIiIiI5MVARERERyYmBioiIiEhODFREREREclJqoDp58iT69esHS0tLSCQSREZGyiwfPXo0JBKJzKtXr16v7Hf16tWwsbGBlpYWOnbsiHPnzsksDwwMRP369dG4cWNs375dZtmePXvQr18/uY+NiIiI3h1KDVQFBQVo2bIlVq9e/cJ1evXqhczMTPH1008/vbTPXbt2ITAwEAsXLkRCQgJatmwJb29v5OTkAAB+++037NixA0eOHEFYWBjGjRuHe/fuAQByc3Mxf/78l9ZDRERE9DylBqrevXtj8eLFGDBgwAvX0dTUhLm5ufiqV6/eS/tcsWIFxo8fD39/fzg7OyMiIgI6OjrYtGkTAODKlSvw8PBAu3btMGzYMBgYGCAtLQ0AMGfOHEyaNAlWVlY1d5BERET01qv1c6ikUilMTU3h4OCASZMm4d9//33huk+ePEF8fDy8vLzENhUVFXh5eSEmJgYA0LJlS5w/fx4PHjxAfHw8CgsL0aRJE5w6dQoJCQmYOnWqwo+JiIiI3i61OlD16tUL27ZtQ1RUFJYuXYoTJ06gd+/eKC0trXT9e/fuobS0FGZmZjLtZmZmyMrKAgB4e3vj448/Rvv27TF69Ghs3boVurq6mDRpEiIiIrBmzRo4ODjAzc0Nly9ffmFtxcXFyMvLk3kRERHRu6lW3yl96NCh4n83b94cLVq0gJ2dHaRSKTw9PV+73+DgYAQHB4vvFy1aBC8vL6irq2Px4sVITk7GgQMH4Ofnh/j4+Er7CA0NxaJFi167BiIiInp71OoRque99957MDY2xvXr1ytdbmxsDFVVVWRnZ8u0Z2dnw9zcvNJtrl69ih9//BEhISGQSqVwd3eHiYkJfH19kZCQgEePHlW63bx585Cbmyu+bt++Ld/BERERUZ1VpwLVnTt38O+//8LCwqLS5RoaGmjbti2ioqLEtrKyMkRFRcHV1bXC+oIg4JNPPsGKFSugp6eH0tJSlJSUAID4vy+6vKipqQkDAwOZFxEREb2blBqo8vPzkZiYiMTERABAWloaEhMTkZ6ejvz8fMyePRtnz57FzZs3ERUVhf79+6NJkybw9vYW+/D09ER4eLj4PjAwEOvXr8fWrVtx5coVTJo0CQUFBfD396+w/w0bNsDExES875SbmxuOHz+Os2fP4ptvvoGzszOMjIwUeg6IiIio7lPqHKrz58+jW7du4vvAwEAAwKhRo7BmzRokJSVh69atePjwISwtLdGzZ0+EhIRAU1NT3ObGjRvifaQAYMiQIbh79y6CgoKQlZWFVq1a4dChQxUmqmdnZ2PJkiU4c+aM2NahQwfMnDkTffv2hampKbZu3aqoQyciIqK3iEQQBEHZRbwN8vLyYGhoiNzc3Dpz+U8aLFV2CVXmEeyh7BKqLFgqVXYJShXs4aHsEoiIqqym/n7XqTlURERERLURAxURERGRnBioiIiIiOTEQEVEREQkJwYqIiIiIjnV6kfPEJVT1DcSpR4K6ZaIiN4xHKEiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOTFQEREREcmJgYqIiIhITgxURERERHJioCIiIiKSEwMVERERkZwYqIiIiIjkxEBFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcmKgIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJwYqIiIiIjkxUBERERHJSU3ZBRDR2yVYKlVMvx4eCumXiKgmcISKiIiISE4MVERERERyUmqgOnnyJPr16wdLS0tIJBJERkbKLBcEAUFBQbCwsIC2tja8vLyQmpr6yn5Xr14NGxsbaGlpoWPHjjh37pzM8sDAQNSvXx+NGzfG9u3bZZbt2bMH/fr1k/vYiIiI6N2h1EBVUFCAli1bYvXq1ZUuDwsLw7fffouIiAjExsZCV1cX3t7eKCoqemGfu3btQmBgIBYuXIiEhAS0bNkS3t7eyMnJAQD89ttv2LFjB44cOYKwsDCMGzcO9+7dAwDk5uZi/vz5L6yHiIiIqDJKDVS9e/fG4sWLMWDAgArLBEHAypUrsWDBAvTv3x8tWrTAtm3bkJGRUWEk679WrFiB8ePHw9/fH87OzoiIiICOjg42bdoEALhy5Qo8PDzQrl07DBs2DAYGBkhLSwMAzJkzB5MmTYKVlZVCjpeIiIjeTrV2DlVaWhqysrLg5eUlthkaGqJjx46IiYmpdJsnT54gPj5eZhsVFRV4eXmJ27Rs2RLnz5/HgwcPEB8fj8LCQjRp0gSnTp1CQkICpk6dqtgDIyIiordOrQ1UWVlZAAAzMzOZdjMzM3HZ8+7du4fS0tKXbuPt7Y2PP/4Y7du3x+jRo7F161bo6upi0qRJiIiIwJo1a+Dg4AA3Nzdcvnz5hfUVFxcjLy9P5kVERETvplobqBQpODgY169fR3JyMgYMGIDQ0FB4eXlBXV0dixcvxqlTpzBu3Dj4+fm9sI/Q0FAYGhqKr8aNG7/BIyAiIqLapNYGKnNzcwBAdna2THt2dra47HnGxsZQVVWt1jZXr17Fjz/+iJCQEEilUri7u8PExAS+vr5ISEjAo0ePKt1u3rx5yM3NFV+3b9+u7iESERHRW6LWBipbW1uYm5sjKipKbMvLy0NsbCxcXV0r3UZDQwNt27aV2aasrAxRUVGVbiMIAj755BOsWLECenp6KC0tRUlJCQCI/1taWlrpvjQ1NWFgYCDzIiIioneTUgNVfn4+EhMTkZiYCODZRPTExESkp6dDIpFg+vTpWLx4Mfbv34/k5GT4+fnB0tISPj4+Yh+enp4IDw8X3wcGBmL9+vXYunUrrly5gkmTJqGgoAD+/v4V9r9hwwaYmJiI951yc3PD8ePHcfbsWXzzzTdwdnaGkZGRIk8BERERvQWU+iy/8+fPo1u3buL7wMBAAMCoUaOwZcsWzJkzBwUFBZgwYQIePnyIzp0749ChQ9DS0hK3uXHjhngfKQAYMmQI7t69i6CgIGRlZaFVq1Y4dOhQhYnq2dnZWLJkCc6cOSO2dejQATNnzkTfvn1hamqKrVu3KurQiYiI6C0iEQRBUHYRb4O8vDwYGhoiNze3zlz+kwZLlV2C0kk9lF0BVRUfjkxEilBTf79r7RwqIiIiorqCgYqIiIhITgxURERERHJioCIiIiKSEwMVERERkZwYqIiIiIjkxEBFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcmKgIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJwYqIiIiIjkxUBERERHJiYGKiIiISE4MVERERERyYqAiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOakpuwAioqoIlkprvk8Pjxrvk4jeTRyhIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJ05KpzpBevOmYjreooA+R9sooFMiIqrNOEJFREREJKdaHaiCg4MhkUhkXo6Oji/dZs+ePXB0dISWlhaaN2+OP/74Q2b5119/DVNTU5iammL58uUyy2JjY9G2bVs8ffq0xo+FiIiI3l61/pJfs2bNcOzYMfG9mtqLSz5z5gyGDRuG0NBQfPDBB9ixYwd8fHyQkJAAFxcXJCUlISgoCAcOHIAgCPjggw/Qs2dPNG/eHE+fPsXEiROxbt26l+6DiIiI6Hm1PjmoqanB3Ny8SuuuWrUKvXr1wuzZswEAISEhOHr0KMLDwxEREYGrV6+iRYsW6N69OwCgRYsWuHr1Kpo3b45ly5bB3d0d7du3V9ixEBER0dupVl/yA4DU1FRYWlrivffew4gRI5Cenv7CdWNiYuDl5SXT5u3tjZiYGABA8+bNce3aNaSnp+PWrVu4du0aXFxccOPGDWzevBmLFy9W6LEQERHR26lWB6qOHTtiy5YtOHToENasWYO0tDR06dIFjx49qnT9rKwsmJmZybSZmZkhKysLAODk5IQvv/wSPXr0QM+ePREaGgonJyd88sknCAsLw+HDh+Hi4oLWrVvj5MmTL62tuLgYeXl5Mi8iIiJ6N9XqS369e/cW/7tFixbo2LEjrK2tsXv3bowdO/a1+pw4cSImTpwovt+6dSv09fXh6uoKBwcHxMXF4c6dOxg6dCjS0tKgqalZaT+hoaFYtGjRa9VAREREb5daPUL1PCMjI9jb2+P69euVLjc3N0d2drZMW3Z29gvnYN27dw+LFi3Cd999h9jYWNjb26Np06bo1q0bSkpKcO3atRfWMm/ePOTm5oqv27dvv/6BERERUZ1WpwJVfn4+bty4AQsLi0qXu7q6IioqSqbt6NGjcHV1rXT9GTNmYMaMGWjUqBFKS0tRUlIiLnv69ClKS0tfWIumpiYMDAxkXkRERPRuqtWX/GbNmoV+/frB2toaGRkZWLhwIVRVVTFs2DAAgJ+fHxo2bIjQ0FAAwLRp09C1a1csX74cffv2xc6dO3H+/HmsW7euQt9Hjx7FtWvXsHXrVgBA+/btcfXqVRw8eBC3b9+GqqoqHBwc3tzBEhERUZ1VqwPVnTt3MGzYMPz7778wMTFB586dcfbsWZiYmAAA0tPToaLy/wfZOnXqhB07dmDBggX43//+h6ZNmyIyMhIuLi4y/RYWFmLy5MnYtWuXuH2jRo3w3Xffwd/fH5qamti6dSu0tbXf3MESERFRnSURBEFQdhFvg7y8PBgaGiI3N7fOXP6TBkuVXUKVKexZforAZ/nVGcEeHsougYiUrKb+ftepOVREREREtREDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOTFQEREREcmpVt+HiohIkYKlUsX0y9sxEL1zOEJFREREJCcGKiIiIiI5MVARERERyYlzqIhq2pabiumXj7QhIqq1OEJFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREREREcmKgIiIiIpITAxURERGRnBioiIiIiOTEQEVEREQkJ94pnaiuUMQd2Hn3dSKiGsFARURUw4Kl0prv08OjxvskoprDS35EREREcmKgIiIiIpITAxURERGRnBioiIiIiOTESelE7zJ+c5CIqEZwhIqIiIhIThyhIqKapYhRL+CdH/lSxK0YAN6OgaimcISKiIiISE4coSKiuoHzvYioFqsTI1SrV6+GjY0NtLS00LFjR5w7d+6l6+/ZsweOjo7Q0tJC8+bN8ccff8gs//rrr2FqagpTU1MsX75cZllsbCzatm2Lp0+f1vhxEBER0dup1o9Q7dq1C4GBgYiIiEDHjh2xcuVKeHt7IyUlBaamphXWP3PmDIYNG4bQ0FB88MEH2LFjB3x8fJCQkAAXFxckJSUhKCgIBw4cgCAI+OCDD9CzZ080b94cT58+xcSJE7Fu3TqoqdX6U0NE8lLUfC9FUNBoGh+TQ1Qzav0I1YoVKzB+/Hj4+/vD2dkZERER0NHRwaZNmypdf9WqVejVqxdmz54NJycnhISEoE2bNggPDwcAXL16FS1atED37t3h6emJFi1a4OrVqwCAZcuWwd3dHe3bt39jx0dERER1X60ehnny5Ani4+Mxb948sU1FRQVeXl6IiYmpdJuYmBgEBgbKtHl7eyMyMhIA0Lx5c1y7dg3p6ekQBAHXrl2Di4sLbty4gc2bNyM+Pl5hx0NE9Nrq0GhaMKSK6ZcjX1SL1epAde/ePZSWlsLMzEym3czMTBxVel5WVlal62dlZQEAnJyc8OWXX6JHjx4AgNDQUDg5OcHLywthYWE4fPgwgoODoa6ujlWrVsHd3b3S/RQXF6O4uFh8n5ubCwDIy8t7vYNVgoLiAmWXUGXFTwqVXQIRVdW6Kwrpdp6C+lWEeREjlF0CVVH5321BEOTqp1YHKkWZOHEiJk6cKL7funUr9PX14erqCgcHB8TFxeHOnTsYOnQo0tLSoKmpWaGP0NBQLFq0qEJ748aNFVo7ERHVfl/99KmyS6BqevToEQwNDV97+1odqIyNjaGqqors7GyZ9uzsbJibm1e6jbm5ebXWv3fvHhYtWoSTJ08iNjYW9vb2aNq0KZo2bYqSkhJcu3YNzZs3r7DdvHnzZC4tlpWV4f79+2jQoAEkEkl1D/Wl8vLy0LhxY9y+fRsGBgY12ndNY62KUVdqrSt1AqxVUVirYrBWxSiv9a+//oKlpaVcfdXqQKWhoYG2bdsiKioKPj4+AJ4Fl6ioKEyePLnSbVxdXREVFYXp06eLbUePHoWrq2ul68+YMQMzZsxAo0aNEBcXh5KSEnHZ06dPUVpaWul2mpqaFUaujIyMqn5wr8HAwKDWfzjLsVbFqCu11pU6AdaqKKxVMVirYjRs2BAqKvJ9T69WByoACAwMxKhRo9CuXTt06NABK1euREFBAfz9/QEAfn5+aNiwIUJDQwEA06ZNQ9euXbF8+XL07dsXO3fuxPnz57Fu3boKfR89ehTXrl3D1q1bAQDt27fH1atXcfDgQdy+fRuqqqpwcHB4cwdLREREdVKtD1RDhgzB3bt3ERQUhKysLLRq1QqHDh0SJ56np6fLpMpOnTphx44dWLBgAf73v/+hadOmiIyMhIuLi0y/hYWFmDx5Mnbt2iVu36hRI3z33Xfw9/eHpqYmtm7dCm1t7Td3sERERFQn1fpABQCTJ09+4SU+aSU3pfvoo4/w0UcfvbRPbW1tpKSkVGgfN24cxo0b91p1KoqmpiYWLlxY6eT42oa1KkZdqbWu1AmwVkVhrYrBWhWjJmuVCPJ+T5CIiIjoHVfr75ROREREVNsxUBERERHJiYGKiIiISE4MVERERERyYqCq5VavXg0bGxtoaWmhY8eOOHfunLJLqiA0NBTt27eHvr4+TE1N4ePjU+k3KGujr776ChKJROZGsLXJP//8g48//hgNGjSAtrY2mjdvjvPnzyu7rApKS0vx+eefw9bWFtra2rCzs0NISIjcz8aqCSdPnkS/fv1gaWkJiUQiPii9nCAICAoKgoWFBbS1teHl5YXU1NRaV2tJSQnmzp2L5s2bQ1dXF5aWlvDz80NGRkatq/V5EydOhEQiwcqVK99Yff9VlVqvXLmCDz/8EIaGhtDV1UX79u2Rnp5e62rNz8/H5MmT0ahRI2hra8PZ2RkRERFvvM6q/N4vKipCQEAAGjRoAD09PQwaNKjCk0xqQ63379/HlClT4ODgAG1tbVhZWWHq1KniM3qrioGqFtu1axcCAwOxcOFCJCQkoGXLlvD29kZOTo6yS5Nx4sQJBAQE4OzZszh69ChKSkrQs2dPFBTU7ocvx8XFYe3atWjRooWyS6nUgwcP4ObmBnV1dRw8eBB//fUXli9fjnr16im7tAqWLl2KNWvWIDw8HFeuXMHSpUsRFhaG7777TtmloaCgAC1btsTq1asrXR4WFoZvv/0WERERiI2Nha6uLry9vVFUVPSGK315rY8fP0ZCQgI+//xzJCQkYO/evUhJScGHH374xusEXn1ey+3btw9nz56V+7Ee8nhVrTdu3EDnzp3h6OgIqVSKpKQkfP7559DS0nrDlb661sDAQBw6dAg//vgjrly5gunTp2Py5MnYv3//G62zKr/3Z8yYgd9++w179uzBiRMnkJGRgYEDB77ROqtSa0ZGBjIyMvD111/j0qVL2LJlCw4dOoSxY8dWb0cC1VodOnQQAgICxPelpaWCpaWlEBoaqsSqXi0nJ0cAIJw4cULZpbzQo0ePhKZNmwpHjx4VunbtKkybNk3ZJVUwd+5coXPnzsouo0r69u0rjBkzRqZt4MCBwogRI5RUUeUACPv27RPfl5WVCebm5sKyZcvEtocPHwqamprCTz/9pIQK/7/na63MuXPnBADCrVu33kxRL/CiWu/cuSM0bNhQuHTpkmBtbS188803b7y251VW65AhQ4SPP/5YOQW9RGW1NmvWTPjiiy9k2tq0aSPMnz//DVZW0fO/9x8+fCioq6sLe/bsEde5cuWKAECIiYlRVpmCIFTtb9Tu3bsFDQ0NoaSkpMr9coSqlnry5Ani4+Ph5eUltqmoqMDLywsxMTFKrOzVyodJ69evr+RKXiwgIAB9+/aVOb+1zf79+9GuXTt89NFHMDU1RevWrbF+/Xpll1WpTp06ISoqCteuXQMAXLx4EadOnULv3r2VXNnLpaWlISsrS+ZzYGhoiI4dO9b6nzPg2c+aRCJR+HNEX0dZWRlGjhyJ2bNno1mzZsou54XKysrw+++/w97eHt7e3jA1NUXHjh1feglTmTp16oT9+/fjn3/+gSAIiI6OxrVr19CzZ0+l1vX87/34+HiUlJTI/Gw5OjrCyspK6T9bVfkblZubCwMDA6ipVf3+5wxUtdS9e/dQWloqPmKnnJmZGbKyspRU1auVlZVh+vTpcHNzq/C4n9pi586dSEhIEJ//WFv9/fffWLNmDZo2bYrDhw9j0qRJmDp1qvjsydrks88+w9ChQ+Ho6Ah1dXW0bt0a06dPx4gRI5Rd2kuV/yzVtZ8z4Nn8lLlz52LYsGG18gG0S5cuhZqaGqZOnarsUl4qJycH+fn5+Oqrr9CrVy8cOXIEAwYMwMCBA3HixAlll1fBd999B2dnZzRq1AgaGhro1asXVq9eDXd3d6XVVNnv/aysLGhoaFQI+8r+2arK36h79+4hJCQEEyZMqFbfdeLRM1R3BAQE4NKlSzh16pSyS6nU7du3MW3aNBw9elQp8yOqo6ysDO3atcOXX34JAGjdujUuXbqEiIgIjBo1SsnVydq9eze2b9+OHTt2oFmzZkhMTMT06dNhaWlZ62p9G5SUlMDX1xeCIGDNmjXKLqeC+Ph4rFq1CgkJCZBIJMou56XKysoAAP3798eMGTMAAK1atcKZM2cQERGBrl27KrO8Cr777jucPXsW+/fvh7W1NU6ePImAgABYWloqbcS9tv/e/69X1ZqXl4e+ffvC2dkZwcHB1eqbI1S1lLGxMVRVVSt8IyI7Oxvm5uZKqurlJk+ejAMHDiA6OhqNGjVSdjmVio+PR05ODtq0aQM1NTWoqanhxIkT+Pbbb6GmpobS0lJllyiysLCAs7OzTJuTk5NSvnn0KrNnzxZHqZo3b46RI0dixowZtX4UsPxnqS79nJWHqVu3buHo0aO1cnTqzz//RE5ODqysrMSfs1u3bmHmzJmwsbFRdnkyjI2NoaamVid+1goLC/G///0PK1asQL9+/dCiRQtMnjwZQ4YMwddff62Uml70e9/c3BxPnjzBw4cPZdZX5s/Wq/5GPXr0CL169YK+vj727dsHdXX1avXPQFVLaWhooG3btoiKihLbysrKEBUVBVdXVyVWVpEgCJg8eTL27duH48ePw9bWVtklvZCnpyeSk5ORmJgovtq1a4cRI0YgMTERqqqqyi5R5ObmVuFryNeuXYO1tbWSKnqxx48fQ0VF9teJqqqq+P/+aytbW1uYm5vL/Jzl5eUhNja21v2cAf8/TKWmpuLYsWNo0KCBskuq1MiRI5GUlCTzc2ZpaYnZs2fj8OHDyi5PhoaGBtq3b18nftZKSkpQUlJSK37WXvV7v23btlBXV5f52UpJSUF6evob/9mqyt+ovLw89OzZExoaGti/f/9rXcHgJb9aLDAwEKNGjUK7du3QoUMHrFy5EgUFBfD391d2aTICAgKwY8cO/Prrr9DX1xevjxsaGkJbW1vJ1cnS19evcN1cV1cXDRo0qHVzvmbMmIFOnTrhyy+/hK+vL86dO4d169Zh3bp1yi6tgn79+mHJkiWwsrJCs2bNcOHCBaxYsQJjxoxRdmnIz8/H9evXxfdpaWlITExE/fr1YWVlhenTp2Px4sVo2rQpbG1t8fnnn8PS0hI+Pj61qlYLCwsMHjwYCQkJOHDgAEpLS8Wftfr160NDQ6PW1GplZVUh7Kmrq8Pc3BwODg5vtE7g1bXOnj0bQ4YMgbu7O7p164ZDhw7ht99+g1QqrXW1du3aFbNnz4a2tjasra1x4sQJbNu2DStWrHijdb7q976hoSHGjh2LwMBA1K9fHwYGBpgyZQpcXV3x/vvv16pay8PU48eP8eOPPyIvLw95eXkAABMTk6r/H205v31ICvbdd98JVlZWgoaGhtChQwfh7Nmzyi6pAgCVvjZv3qzs0qqktt42QRAE4bfffhNcXFwETU1NwdHRUVi3bp2yS6pUXl6eMG3aNMHKykrQ0tIS3nvvPWH+/PlCcXGxsksToqOjK/18jho1ShCEZ7dO+PzzzwUzMzNBU1NT8PT0FFJSUmpdrWlpaS/8WYuOjq5VtVZGmbdNqEqtGzduFJo0aSJoaWkJLVu2FCIjI2tlrZmZmcLo0aMFS0tLQUtLS3BwcBCWL18ulJWVvdE6q/J7v7CwUPj000+FevXqCTo6OsKAAQOEzMzMN1pnVWp90TkHIKSlpVV5P5L/2xkRERERvSbOoSIiIiKSEwMVERERkZwYqIiIiIjkxEBFREREJCcGKiIiIiI5MVARERERyYmBioiIiEhODFREpBAeHh6YPn26sssAAEilUkgkkgrPFXuZmzdvQiKRQCKRoFWrVnLXMHr0aKXcfb1ccHCweDwrV65UWh1EbysGKiJ6q9R0kDt27JjM88iUHYxe16xZs5CZmVlrH1xOVNfxWX5ERC/RoEGDWvsQ4urQ09ODnp5erXoAONHbhCNURPRGFBcXY9asWWjYsCF0dXXRsWNHmYfPbtmyBUZGRjh8+DCcnJygp6eHXr16ITMzU1zn6dOnmDp1KoyMjNCgQQPMnTsXo0aNEkeMRo8ejRMnTmDVqlXi5a2bN2+K28fHx6Ndu3bQ0dFBp06dkJKSUq1jCA4OxtatW/Hrr7+K/ZcfQ3JyMrp37w5tbW00aNAAEyZMQH5+/gv7iouLg4mJCZYuXQoAePjwIcaNGwcTExMYGBige/fuuHjxosy+W7VqhR9++AE2NjYwNDTE0KFD8ejRI3Gdn3/+Gc2bNxdr8PLyQkFBQbWOkYheDwMVEb0RkydPRkxMDHbu3ImkpCR89NFH6NWrF1JTU8V1Hj9+jK+//ho//PADTp48ifT0dMyaNUtcvnTpUmzfvh2bN2/G6dOnkZeXh8jISHH5qlWr4OrqivHjxyMzMxOZmZlo3LixuHz+/PlYvnw5zp8/DzU1NYwZM6ZaxzBr1iz4+vqKQS8zMxOdOnVCQUEBvL29Ua9ePcTFxWHPnj04duwYJk+eXGk/x48fR48ePbBkyRLMnTsXAPDRRx8hJycHBw8eRHx8PNq0aQNPT0/cv39f3O7GjRuIjIzEgQMHcODAAZw4cQJfffUVACAzMxPDhg3DmDFjcOXKFUilUgwcOBB8XCvRG6KABzsTEQldu3YVpk2bJgiCINy6dUtQVVUV/vnnH5l1PD09hXnz5gmCIAibN28WAAjXr18Xl69evVowMzMT35uZmQnLli0T3z99+lSwsrIS+vfvX+l+y5U/Tf7YsWNi2++//y4AEAoLCyutPy0tTQAgXLhwQaZ91KhRMvsTBEFYt26dUK9ePSE/P1+mfxUVFSErK0tmu7179wp6enrCzp07xXX//PNPwcDAQCgqKpLp187OTli7dq0gCIKwcOFCQUdHR8jLyxOXz549W+jYsaMgCIIQHx8vABBu3rxZ6fGUs7a2Fr755puXrkNE1cc5VESkcMnJySgtLYW9vb1Me3Fxscz8JB0dHdjZ2YnvLSwskJOTAwDIzc1FdnY2OnToIC5XVVVF27ZtUVZWVqU6WrRoIdM3AOTk5MDKyqr6B/UfV65cQcuWLaGrqyu2ubm5oaysDCkpKTAzMwMAxMbG4sCBA/j5559lJrZfvHgR+fn5FeZqFRYW4saNG+J7Gxsb6OvryxxD+flp2bIlPD090bx5c3h7e6Nnz54YPHgw6tWrJ9exEVHVMFARkcLl5+dDVVUV8fHxFSZF6+npif+trq4us0wikdToJav/9i+RSACgymGsJtjZ2aFBgwbYtGkT+vbtK9aTn58PCwsLmTll5YyMjMT/ruz8lNevqqqKo0eP4syZMzhy5Ai+++47zJ8/H7GxsbC1tVXYMRHRM5xDRUQK17p1a5SWliInJwdNmjSReZmbm1epD0NDQ5iZmSEuLk5sKy0tRUJCgsx6GhoaKC0trdH6X9W/k5MTLl68KDMB/PTp01BRUYGDg4PYZmxsjOPHj+P69evw9fVFSUkJAKBNmzbIysqCmppahfNjbGxc5dokEgnc3NywaNEiXLhwARoaGti3b5+cR0xEVcFARUQKZ29vjxEjRsDPzw979+5FWloazp07h9DQUPz+++9V7mfKlCkIDQ3Fr7/+ipSUFEybNg0PHjwQR5uAZ5fFYmNjcfPmTdy7d6/GR6BsbGyQlJSElJQU3Lt3DyUlJRgxYgS0tLQwatQoXLp0CdHR0ZgyZQpGjhwpXu4rZ2pqiuPHj+Pq1asYNmwYnj59Ci8vL7i6usLHxwdHjhzBzZs3cebMGcyfPx/nz5+vUl2xsbH48ssvcf78eaSnp2Pv3r24e/cunJycavT4iahyDFRE9EZs3rwZfn5+mDlzJhwcHODj44O4uLhqzV+aO3cuhg0bBj8/P7i6ukJPTw/e3t7Q0tIS15k1axZUVVXh7OwMExMTpKen1+hxjB8/Hg4ODmjXrh1MTExw+vRp6Ojo4PDhw7h//z7at2+PwYMHw9PTE+Hh4ZX2YW5ujuPHjyM5ORkjRoxAWVkZ/vjjD7i7u8Pf3x/29vYYOnQobt26VSGQvYiBgQFOnjyJPn36wN7eHgsWLMDy5cvRu3fvmjx8InoBiVCTExSIiN6gsrIyODk5wdfXFyEhITXa982bN2Fra4sLFy7UyKNnagsbGxtMnz691jwWiOhtwREqIqozbt26hfXr1+PatWtITk7GpEmTkJaWhuHDhytsn506dUKnTp0U1v+b8uWXX0JPT6/GR+yI6BmOUBFRnXH79m0MHToUly5dgiAIcHFxwVdffQV3d/ca39fTp0/Fu6xramrK3CC0Lrp//754k1ATExMYGhoquSKitwsDFREREZGceMmPiIiISE4MVERERERyYqAiIiIikhMDFREREZGcGKiIiIiI5MRARURERCQnBioiIiIiOTFQEREREcmJgYqIiIhITv8PBDOhrj5gXUYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the histograms to see if that worked\n",
    "\n",
    "train_df_final_thresholds = histograms(train_df_final, cols_tokens, name = 'tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6789669f-3bbf-4a2d-942e-30dc0255930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35044, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fde25b3c-a9f0-4659-8198-63baefbe91a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.28\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 22)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.29\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 18)\n"
     ]
    }
   ],
   "source": [
    "# shortest sentences removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37889e-0499-44c7-a615-b68335952dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38915cef-2608-4ff0-b870-005f29ce64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = filter_sentences(test_df_final, cols_tokens, [2,0], condition='longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ed9ed2f-f665-4cf8-af0d-34ce49f48ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question_tokens 3\n",
      "Answer_tokens 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the histograms to see if that worked\n",
    "\n",
    "test_df_final_thresholds = histograms(test_df_final, cols_tokens, name = 'tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "193fa900-f512-46d9-b2ba-aa5cc64f9000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3530, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "606eac15-6aaa-4e53-85d3-529d935684a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.36\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 17)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.20\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 15)\n"
     ]
    }
   ],
   "source": [
    "# shortest sentences removed\n",
    "sentences_stats(test_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed5af0-e6ac-486f-9d77-3ba2615d25de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01a76972-303d-44ae-bf59-08c46a237488",
   "metadata": {},
   "source": [
    "### Remove long outliers: long sentences that occure rarely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69685485-1713-4017-8436-9a196e879cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the 95% of the data\n",
    "cutoff = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25b7ecff-2312-4e1c-9773-6028dad38e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question_tokens': 10, 'Answer_tokens': 6}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_thresholds(train_df_final_thresholds, cutoff = cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82a5369e-fcde-48c3-a0c4-110bb6c7e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MAX, A_MAX = get_thresholds(train_df_final_thresholds, cutoff = cutoff).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e88cbc7c-a428-43e6-a81e-7d71d2be3ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_MAX, A_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dbfd71c-8b8b-4b7d-a4fe-6f687da0b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MAX = 8\n",
    "A_MAX = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "648d0c08-a9e0-4278-8beb-3b5e35f8c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = filter_sentences(train_df_final, cols_tokens, [Q_MAX+1,A_MAX+1], condition='shorter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12cfc150-100f-460b-a252-d475c139fee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 5.72\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 8)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 1.83\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 4)\n"
     ]
    }
   ],
   "source": [
    "# long outliers removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36354e-a106-40bb-bccf-73737f654f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2be1ef8-3321-4c82-a6ff-e8ad9579c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to simplify I'm using the same thresholds for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41eb7230-16a9-407f-8747-2bd5f3db7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = filter_sentences(test_df_final, cols_tokens, [Q_MAX+1,A_MAX+1], condition='shorter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acbac5aa-a51b-4a37-9265-4657e7f7239d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 5.77\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 8)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 1.86\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 4)\n"
     ]
    }
   ],
   "source": [
    "# long outliers removed\n",
    "sentences_stats(test_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2750b9b-f01b-4ee9-be2b-69890cb4ca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27493, 4), (2776, 4))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.shape, test_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffdcad-8870-4376-b738-1b9282a07bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0be952bd-44cc-4f41-bed5-ea17231aa76e",
   "metadata": {},
   "source": [
    "### Pairs have to be redone from the cleaned up datasets, to be used in the model (after being turned into tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "309585c9-df9d-4f84-995c-544fab45b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs_final = get_pairs_from_df(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "088c6509-f966-480c-bc40-48fa5bd2fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs_final = get_pairs_from_df(test_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cb90adf-d401-48f0-8911-b31144276227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27493, 2776)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs_final), len(test_pairs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3ef56-8fa3-463a-b2d8-6b923aaf72e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e03bca-c654-4f1f-9dde-3ccf6c17376c",
   "metadata": {},
   "source": [
    "### Data preparation for the neural network model\n",
    "\n",
    "Sequences are converted into torch tokens made of their vocabulary indexes. Sequences shorter than the defined length are padded at the beginning. Also Start-Of-Sequence and End-Of-Sequence tokens are added to the tensor.\n",
    "\n",
    "The padding token will be ignored by the model.\n",
    "\n",
    "### Neural network model\n",
    "\n",
    "It uses Seq2Seq Encoder-Decoder architecture with a single LSTM layer. Right now the training is done pair after pair, without batch processing.\n",
    "The optimizer is Stochastic Gradient Descent, and the loss function is \n",
    "negative log likelihood (NLLLoss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d228937-b36c-4aef-a3e8-1031d690b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784657ae-aece-40b3-bc5f-1ce27d7f8b37",
   "metadata": {},
   "source": [
    "## ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6cfb4aee-4ed6-4021-bfde-806682b61123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    # We initialize the Encoder object with appropriate layers\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, embedding_size):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # embedding step\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size).to(device)\n",
    "        \n",
    "        # single LSTM layer\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, 1).to(device)\n",
    "    \n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)        \n",
    "        x = x.view(1, 1, -1)        \n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        return x, hidden, cell_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488893ba-1ea6-43db-88d8-24be60a3103a",
   "metadata": {},
   "source": [
    "## DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6fbc0579-85f1-4459-8f07-e596622498ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    # The Decoder is initialized in the same manner.\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, embedding_size):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # embedding\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        # single LSTM layer\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size)\n",
    "        \n",
    "        # fully connected linear layer\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "        # softmax\n",
    "        self.softmax = nn.LogSoftmax(dim=1)     \n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        x = self.softmax(self.fc(x[0]))\n",
    "        return x, hidden, cell_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592881ec-41a1-421b-ac62-de79f2a24bca",
   "metadata": {},
   "source": [
    "## SEQ2SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9a72ba5-792a-4557-ab14-9ce52f6607ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, output_size, device):    \n",
    "\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # make encoder and decoder \n",
    "        self.encoder = Encoder(self.input_size, self.hidden_size, self.embedding_size).to(device)\n",
    "        self.decoder = Decoder(self.hidden_size, self.output_size, self.embedding_size).to(device)\n",
    "                \n",
    "    def forward(self, src_batch: torch.LongTensor, trg_batch: torch.LongTensor, src_len, trg_len, teacher_forcing_ratio: float = 0.5):\n",
    "        \n",
    "        # target batch (answers) is unpacked to maximum length and batch size\n",
    "        max_len, batch_size = trg_batch.shape               \n",
    "\n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(device) #.to(self.device) \n",
    "              \n",
    "        # initialize hidden and cell state\n",
    "        encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) \n",
    "        cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)\n",
    "       \n",
    "        # iterate over the length of the source (question sequence) using the encoder\n",
    "        \n",
    "        for i in range(src_len):       \n",
    "            # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "            \n",
    "            # src_batch[i] is the ith token of the input (question)\n",
    "            _, hidden, cell = self.encoder(src_batch[i], encoder_hidden, cell_state)\n",
    "        \n",
    "        # trg_batch[0] that's just the first element of trg_batch        \n",
    "        trg = trg_batch[0]\n",
    "                \n",
    "        # now iterating over the target length, using the decoder\n",
    "        \n",
    "        for i in range(trg_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            \n",
    "            # here we use the teacher forcing: if the random value is less than the ratio, then the target is just an element of the target (token from the answer)\n",
    "            # otherwise it's the highest probability prediction\n",
    "            outputs[i] = prediction\n",
    "            \n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d94be0-39bd-431d-99d0-8134badaf0a6",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f31f26b7-7613-4074-896e-8776197e1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c3b2f-ceef-4260-b741-1e486c4fe324",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22ff1200-1c64-4280-869f-ee513745f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48e3a2-a408-4580-94f4-a4c26e9dd5fa",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9668665-18a6-461e-a79c-ce8c8fb621a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(input_size=Q_vocab.n_words, hidden_size=hidden_size, embedding_size=embedding_dim, output_size=A_vocab.n_words, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10c0f439-05ef-4fcf-8cdb-28574170775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = seq2seq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e88ae989-3a38-46a7-97fa-76b0a18ea3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(20907, 256)\n",
      "    (lstm): LSTM(256, 256)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(28324, 256)\n",
      "    (lstm): LSTM(256, 256)\n",
      "    (fc): Linear(in_features=256, out_features=28324, bias=True)\n",
      "    (softmax): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed741601-908d-42fe-8f6e-566c3bdf8317",
   "metadata": {},
   "source": [
    "### Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cad46fed-b21b-464f-aede-b3c55f854a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f861a598-d49f-413b-a49c-ed50ca454a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(seq2seq.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(ignore_index=0).to(device) # 0 is padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a04a7-bc10-4050-8834-603e068cfa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81adbd9-5655-4e35-b9af-426a74beb76a",
   "metadata": {},
   "source": [
    "### Model training \n",
    "\n",
    "For debugging purposes the training function is kept in the main notebook for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da4c1b7b-2da0-457f-9f48-7811a5a9479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_loss = []\n",
    "total_test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4a88f8c-8d1c-4b83-b8f2-1dcc318b8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor_new(vocab, tokens, seq_len, padding):\n",
    "    '''Converts a tokenized sentence into a tensor of indices of a given length.\n",
    "    Allows to choose to pad either at the beginning or at the end.\n",
    "    Padding at the beginning is the default option.'''\n",
    "    \n",
    "    tokens = [t for t in tokens if t in vocab.word2count.keys()]\n",
    "    \n",
    "    if padding == 'end':\n",
    "    \n",
    "        padded = [[vocab.word2index['SOS']] + [vocab.word2index[t] for t in tokens] + [vocab.word2index['EOS']] + [vocab.word2index['PAD']] * (seq_len-len(tokens))]\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        padded = [vocab.word2index['PAD']] * (seq_len-len(tokens)) + [vocab.word2index['SOS']] + [vocab.word2index[t] for t in tokens] + [vocab.word2index['EOS']]\n",
    "\n",
    "    tensor = torch.Tensor(padded).long().view(-1,1)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ffbf468-5a15-4153-8a16-6a15b6172203",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pair = namedtuple('Pair', ['question', 'answer'])\n",
    "def get_tensor_pairs_from_df(df, cols, q_vocab, q_max_len, a_vocab, a_max_len, padding):\n",
    "    '''returns a list of named tuples (question, answer)'''\n",
    "    dicts = []\n",
    "    for col in cols:\n",
    "        dicts.append(df[col].to_dict().values())\n",
    "    \n",
    "    return [Pair(to_tensor_new(q_vocab, q, q_max_len, padding), to_tensor_new(a_vocab, a, a_max_len, padding)) for q, a in zip(*dicts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85d1e4ea-9bbc-48ef-a27c-dc516a22255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_pairs_final = get_tensor_pairs_from_df(train_df_final, cols_tokens, Q_vocab, Q_MAX, A_vocab, A_MAX, 'end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "731dfadf-4357-41fb-abc5-69aa577ed7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor_pairs_final = get_tensor_pairs_from_df(test_df_final, cols_tokens, Q_vocab, Q_MAX, A_vocab, A_MAX, 'end')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85954e0c-0554-42ab-ab1d-a874ec1840ef",
   "metadata": {},
   "source": [
    "## KFold - notes\n",
    "source_data and target_data in the KFold example are lists of tensors:\n",
    "\n",
    "source_data = [toTensor(Q_vocab, pair[0]) for pair in pairs]\n",
    "target_data = [toTensor(A_vocab, pair[1]) for pair in pairs]\n",
    "Seq2Seq class' forward function uses this:\n",
    "\n",
    "  def forward(self):\n",
    "  \n",
    "      # omitted \n",
    "      \n",
    "      output = {\n",
    "                'decoder_output':[]\n",
    "            }\n",
    "\n",
    "      # omitted \n",
    "\n",
    "      for i in range(trg_len):\n",
    "          decoder_output, decoder_hidden, cell_state = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
    "          output['decoder_output'].append(decoder_output)\n",
    "\n",
    "            # omitted\n",
    "\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bebffca7-ecc0-4966-a1fb-85b4603b4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(source_data, target_data, model, epochs, batch_size, print_every, learning_rate):\n",
    "\n",
    "def train(model, pairs, optimizer, criterion, device, epochs, batch_size, teacher_forcing_ratio = 0.5, print_every = 1000): \n",
    "    \n",
    "    total_training_loss = 0\n",
    "    total_valid_loss = 0\n",
    "    loss = 0\n",
    "  \n",
    "    source_data = [pair.question.to(device) for pair in pairs]\n",
    "    target_data = [pair.answer.to(device) for pair in pairs]\n",
    "    \n",
    "\n",
    "    print(f'Started training. Source data size: {len(source_data)}, target data size: {len(target_data)}')\n",
    "    \n",
    "    # use cross validation\n",
    "    kf = KFold(n_splits=epochs, shuffle=True)\n",
    "\n",
    "    for e, (train_index, test_index) in enumerate(kf.split(source_data), 1):\n",
    "        model.train()\n",
    "        for i in range(0, len(train_index)):\n",
    "\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "            current_loss = 0\n",
    "            for (s, t) in zip(output, trg):                 \n",
    "                current_loss += criterion(s, t)\n",
    "                \n",
    "                # print(current_loss)\n",
    "\n",
    "            loss += current_loss\n",
    "            total_training_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "\n",
    "            if i % batch_size == 0 or i == (len(train_index)-1):\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss = 0\n",
    "        \n",
    "        print(e, total_training_loss)\n",
    "\n",
    "        # validation set \n",
    "        model.eval()\n",
    "        for i in range(0, len(test_index)):\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "            current_loss = 0\n",
    "            for (s, t) in zip(output, trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            total_valid_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "\n",
    "        print(e, total_test_loss)\n",
    "\n",
    "        if e % print_every == 0:\n",
    "            training_loss_average = total_training_loss / (len(train_index)*print_every)\n",
    "            validation_loss_average = total_valid_loss / (len(test_index)*print_every)\n",
    "            print(\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(e, epochs, training_loss_average, validation_loss_average))\n",
    "            total_training_loss = 0\n",
    "            total_valid_loss = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffce8eb-3a75-4176-b612-c77eb24c2080",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "def train(model, pairs, optimizer, criterion, device, teacher_forcing_ratio = 0.5, print_every = 1000): \n",
    "    \n",
    "    model.train() # Set the model to training mode\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for pair in pairs:\n",
    "\n",
    "        src = pair.question\n",
    "        tgt = pair.answer\n",
    "\n",
    "        src_tensor = to_tensor(vocab=Q_vocab, tokens=src, seq_len=Q_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "        tgt_tensor = to_tensor(vocab=A_vocab, tokens=tgt, seq_len=A_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "\n",
    "        # print(src_tensor.shape, tgt_tensor.shape)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(src_tensor, tgt_tensor, src_len=src_tensor.size(0), trg_len=tgt_tensor.size(0), teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_tensor.view(-1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        count += 1 \n",
    "\n",
    "        if count % print_every == 0:\n",
    "            print(f'Loss {total_loss/count}')\n",
    "\n",
    "    return total_loss / len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f085f7f-ad21-41e5-be28-053e421512b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "def evaluate(model, pairs, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for pair in pairs:\n",
    "            \n",
    "            src = pair.question\n",
    "            tgt = pair.answer\n",
    "            \n",
    "            src_tensor = to_tensor(vocab=Q_vocab, tokens=src, seq_len=Q_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "            tgt_tensor = to_tensor(vocab=A_vocab, tokens=tgt, seq_len=A_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "\n",
    "            output = model(src_tensor, tgt_tensor, src_len=src_tensor.size(0), trg_len=tgt_tensor.size(0), teacher_forcing_ratio=0) # turn off teacher forcing\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(output.view(-1, output.size(-1)), tgt_tensor.view(-1))\n",
    "\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5aabcb4-0bc9-4efa-9908-f1c07c5a2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "393c6254-d89f-41a7-8add-2312e060dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training. Source data size: 27493, target data size: 27493\n",
      "1 nan\n",
      "1 []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(seq2seq, train_tensor_pairs_final, optimizer, criterion, device, epochs\u001b[38;5;241m=\u001b[39mnum_epochs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, teacher_forcing_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, print_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn [78], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, pairs, optimizer, criterion, device, epochs, batch_size, teacher_forcing_ratio, print_every)\u001b[0m\n\u001b[1;32m     22\u001b[0m src \u001b[38;5;241m=\u001b[39m source_data[i]\n\u001b[1;32m     23\u001b[0m trg \u001b[38;5;241m=\u001b[39m target_data[i]\n\u001b[0;32m---> 25\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (s, t) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output, trg):                 \n",
      "File \u001b[0;32m~/envs/lstm_chatbot/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [63], line 44\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src_batch, trg_batch, src_len, trg_len, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# now iterating over the target length, using the decoder\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trg_len):\n\u001b[0;32m---> 44\u001b[0m     prediction, hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# here we use the teacher forcing: if the random value is less than the ratio, then the target is just an element of the target (token from the answer)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# otherwise it's the highest probability prediction\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     outputs[i] \u001b[38;5;241m=\u001b[39m prediction\n",
      "File \u001b[0;32m~/envs/lstm_chatbot/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [62], line 29\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, hidden, cell_state)\u001b[0m\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m x, (hidden, cell_state) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, hidden, cell_state\n",
      "File \u001b[0;32m~/envs/lstm_chatbot/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/envs/lstm_chatbot/lib/python3.8/site-packages/torch/nn/modules/rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/envs/lstm_chatbot/lib/python3.8/site-packages/torch/nn/modules/rnn.py:685\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    680\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    681\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    682\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    683\u001b[0m                        ):\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    686\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    688\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(seq2seq, train_tensor_pairs_final, optimizer, criterion, device, epochs=num_epochs, batch_size=4, teacher_forcing_ratio = 0.5, print_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90af759-ad86-4889-a496-868a896a6c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eca748-2446-4e2a-98de-fd7ff2bacf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73368444-4fcb-449c-8dbe-ee0ede80ac54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 6.138925907373428\n",
      "Loss 5.665556329607964\n",
      "Loss 5.422191146572431\n",
      "Loss 5.274101310282946\n",
      "Loss 5.1777826576948165\n",
      "Loss 5.060412658294042\n",
      "Loss 5.024915111592838\n",
      "Loss 4.988384833216667\n",
      "Loss 4.927239915808042\n",
      "Loss 4.883971033763886\n",
      "Loss 4.839784553755414\n",
      "Loss 4.798760089387496\n",
      "Loss 4.771627730800556\n",
      "Loss 4.745397167384625\n",
      "Loss 4.708552335500717\n",
      "Loss 4.699005514301359\n",
      "Loss 4.673108266136225\n",
      "Loss 4.649730131685734\n",
      "Loss 4.64802007442399\n",
      "Loss 4.638342442634702\n",
      "Loss 4.621480358756724\n",
      "Loss 4.619393641160293\n",
      "Loss 4.6055101600885395\n",
      "Loss 4.599667688459158\n",
      "Loss 4.592523946399688\n",
      "Loss 4.585663975261725\n",
      "Loss 4.582873447784671\n",
      "Loss 4.573222222017391\n",
      "Loss 4.5600896535145825\n",
      "Loss 4.553379962998629\n",
      "Loss 4.549003374466973\n",
      "Loss 4.548034676002339\n",
      "Loss 4.545192748364174\n",
      "Loss 4.535138930808095\n",
      "Loss 4.536200982551915\n",
      "Loss 4.53194768034584\n",
      "Loss 4.527945615844146\n",
      "Loss 4.522653424562592\n",
      "Loss 4.527179853190214\n",
      "Loss 4.523953871430456\n",
      "Loss 4.522294710326485\n",
      "Loss 4.5206683866282305\n",
      "Loss 4.516756220513998\n",
      "Loss 4.510547178600322\n",
      "Loss 4.510042063600487\n",
      "Loss 4.50989757021225\n",
      "Loss 4.50059090130253\n",
      "Loss 4.502184742294252\n",
      "Loss 4.501613989474822\n",
      "Loss 4.501331207869053\n",
      "Loss 4.498658563920096\n",
      "Loss 4.499318051175429\n",
      "Loss 4.498889123642219\n",
      "Loss 4.495973178693542\n",
      "Loss 4.495628578357263\n",
      "Loss 4.490553135384406\n",
      "Loss 4.489466709686999\n",
      "Loss 4.488809813922849\n",
      "Loss 4.486023361119173\n",
      "Loss 4.483231054848432\n",
      "Loss 4.480890987816404\n",
      "Loss 4.478913017623848\n",
      "Epoch 1/30, Train Loss: 4.4769, Test Loss: 4.5803\n",
      "Loss 4.23974044919014\n",
      "Loss 4.3278606503009796\n",
      "Loss 4.283998619556427\n",
      "Loss 4.238297211661935\n",
      "Loss 4.240291494739056\n",
      "Loss 4.213392652938763\n",
      "Loss 4.243738635480404\n",
      "Loss 4.239058419637382\n",
      "Loss 4.2149116010069845\n",
      "Loss 4.203952664357423\n",
      "Loss 4.193116381824017\n",
      "Loss 4.1794590925176935\n",
      "Loss 4.176875674903393\n",
      "Loss 4.17093684849143\n",
      "Loss 4.156548657993476\n",
      "Loss 4.165493198838085\n",
      "Loss 4.156018837013665\n",
      "Loss 4.148988341553344\n",
      "Loss 4.16159805353378\n",
      "Loss 4.16562491542995\n",
      "Loss 4.162104457426639\n",
      "Loss 4.170610517954285\n",
      "Loss 4.168129391610623\n",
      "Loss 4.173174692499141\n",
      "Loss 4.1755930221319195\n",
      "Loss 4.17749449719374\n",
      "Loss 4.183345297685376\n",
      "Loss 4.181283777075154\n",
      "Loss 4.176055921073617\n",
      "Loss 4.177425427178542\n",
      "Loss 4.179749389948383\n",
      "Loss 4.185313445970416\n",
      "Loss 4.188691053404953\n",
      "Loss 4.185049898173003\n",
      "Loss 4.191848859672035\n",
      "Loss 4.192964215123819\n",
      "Loss 4.194365741482458\n",
      "Loss 4.194297039275891\n",
      "Loss 4.203695579561668\n",
      "Loss 4.205245788484067\n",
      "Loss 4.208535193957207\n",
      "Loss 4.211435218024112\n",
      "Loss 4.211873970482932\n",
      "Loss 4.20959219181199\n",
      "Loss 4.213250131564008\n",
      "Loss 4.21677272712083\n",
      "Loss 4.211285297121774\n",
      "Loss 4.2163325208431734\n",
      "Loss 4.219140431947246\n",
      "Loss 4.22216065372765\n",
      "Loss 4.222847109778839\n",
      "Loss 4.226664302223577\n",
      "Loss 4.229340000753695\n",
      "Loss 4.229276096465963\n",
      "Loss 4.231827450822158\n",
      "Loss 4.229711403811084\n",
      "Loss 4.231458135668123\n",
      "Loss 4.233562094397072\n",
      "Loss 4.233401079511744\n",
      "Loss 4.232916305053731\n",
      "Loss 4.23322604260728\n",
      "Loss 4.233314240075408\n",
      "Epoch 2/30, Train Loss: 4.2317, Test Loss: 4.5645\n",
      "Loss 4.153606585264206\n",
      "Loss 4.234546764194965\n",
      "Loss 4.196786380986373\n",
      "Loss 4.155725038945675\n",
      "Loss 4.160587040877342\n",
      "Loss 4.132604235549768\n",
      "Loss 4.165034192732402\n",
      "Loss 4.161859687894583\n",
      "Loss 4.140101544724571\n",
      "Loss 4.1304802486896515\n",
      "Loss 4.1206989634362134\n",
      "Loss 4.108048890545964\n",
      "Loss 4.106367526049797\n",
      "Loss 4.100955498571906\n",
      "Loss 4.087162220303218\n",
      "Loss 4.096104666776955\n",
      "Loss 4.087526288032532\n",
      "Loss 4.0806342885891596\n",
      "Loss 4.0937471043718485\n",
      "Loss 4.0981761101901535\n",
      "Loss 4.094827890589124\n",
      "Loss 4.10389640766924\n",
      "Loss 4.10183416301012\n",
      "Loss 4.107272366610666\n",
      "Loss 4.110571152112484\n",
      "Loss 4.113271806453283\n",
      "Loss 4.118894475647696\n",
      "Loss 4.116548821719629\n",
      "Loss 4.11135202893101\n",
      "Loss 4.112839850952228\n",
      "Loss 4.1153199883526375\n",
      "Loss 4.121091813189909\n",
      "Loss 4.124918884138267\n",
      "Loss 4.121679369598627\n",
      "Loss 4.128628039085865\n",
      "Loss 4.130014387314518\n",
      "Loss 4.131587513567628\n",
      "Loss 4.131401316369835\n",
      "Loss 4.140785726262973\n",
      "Loss 4.142399910482764\n",
      "Loss 4.145776557355393\n",
      "Loss 4.148714968448593\n",
      "Loss 4.149448561818101\n",
      "Loss 4.14732348930023\n",
      "Loss 4.1512290553967155\n",
      "Loss 4.155012428151524\n",
      "Loss 4.149712403967025\n",
      "Loss 4.154849976493667\n",
      "Loss 4.157955040212797\n",
      "Loss 4.161121330808401\n",
      "Loss 4.161819463995157\n",
      "Loss 4.165791862472892\n",
      "Loss 4.1685702470754675\n",
      "Loss 4.168631884796752\n",
      "Loss 4.171215452919223\n",
      "Loss 4.169357124644731\n",
      "Loss 4.171233385072465\n",
      "Loss 4.1735039375290786\n",
      "Loss 4.17360763481815\n",
      "Loss 4.173103797893723\n",
      "Loss 4.173398505719959\n",
      "Loss 4.173509466170303\n",
      "Epoch 3/30, Train Loss: 4.1719, Test Loss: 4.5694\n",
      "Loss 4.094554077863693\n",
      "Loss 4.1685170458555225\n",
      "Loss 4.1276091803312305\n",
      "Loss 4.091331280738116\n",
      "Loss 4.0969194715738295\n",
      "Loss 4.067737786422173\n",
      "Loss 4.102447536970888\n",
      "Loss 4.102166389353573\n",
      "Loss 4.082863242394394\n",
      "Loss 4.075312011688948\n",
      "Loss 4.066419478324327\n",
      "Loss 4.054544542094072\n",
      "Loss 4.053578609484893\n",
      "Loss 4.049055663457938\n",
      "Loss 4.035840179137389\n",
      "Loss 4.044886851970106\n",
      "Loss 4.036566277198932\n",
      "Loss 4.029960469361809\n",
      "Loss 4.043381517363222\n",
      "Loss 4.048159090332687\n",
      "Loss 4.045380239871286\n",
      "Loss 4.054432136935267\n",
      "Loss 4.052629968982676\n",
      "Loss 4.058400069393217\n",
      "Loss 4.062128700082302\n",
      "Loss 4.064768758950325\n",
      "Loss 4.070821084907761\n",
      "Loss 4.068616170957685\n",
      "Loss 4.063648083277817\n",
      "Loss 4.065245416456461\n",
      "Loss 4.067878132922034\n",
      "Loss 4.073696230592206\n",
      "Loss 4.077807771518375\n",
      "Loss 4.0747722369318495\n",
      "Loss 4.082309172683955\n",
      "Loss 4.084013988460931\n",
      "Loss 4.08578502698444\n",
      "Loss 4.085948846441351\n",
      "Loss 4.0951462203119045\n",
      "Loss 4.096837881148606\n",
      "Loss 4.100256676282098\n",
      "Loss 4.103589691951871\n",
      "Loss 4.104416147651367\n",
      "Loss 4.101900683063675\n",
      "Loss 4.1059286310878065\n",
      "Loss 4.109693712340101\n",
      "Loss 4.104267343493852\n",
      "Loss 4.1092903097290545\n",
      "Loss 4.1126002678183875\n",
      "Loss 4.115947643768191\n",
      "Loss 4.116756855398417\n",
      "Loss 4.120910320721567\n",
      "Loss 4.123584959308494\n",
      "Loss 4.123751864942688\n",
      "Loss 4.1264159415976565\n",
      "Loss 4.124559652408851\n",
      "Loss 4.126605017860208\n",
      "Loss 4.128912400555508\n",
      "Loss 4.129045718007673\n",
      "Loss 4.128692235861719\n",
      "Loss 4.12923825130746\n",
      "Loss 4.129528556190672\n",
      "Epoch 4/30, Train Loss: 4.1280, Test Loss: 4.5638\n",
      "Loss 4.047609416007996\n",
      "Loss 4.107474296092987\n",
      "Loss 4.067431226849556\n",
      "Loss 4.032952506691218\n",
      "Loss 4.0394561384439465\n",
      "Loss 4.0101120866239075\n",
      "Loss 4.046118768598352\n",
      "Loss 4.047230402030051\n",
      "Loss 4.029627524978585\n",
      "Loss 4.023029871445894\n",
      "Loss 4.015437173231081\n",
      "Loss 4.004458417509993\n",
      "Loss 4.004094877701539\n",
      "Loss 3.999461014841284\n",
      "Loss 3.9876171561042466\n",
      "Loss 3.9982076226510106\n",
      "Loss 3.9901106086303204\n",
      "Loss 3.9843198655545713\n",
      "Loss 3.9981790546712124\n",
      "Loss 4.003300207732618\n",
      "Loss 4.000933166241362\n",
      "Loss 4.0098026209947735\n",
      "Loss 4.008307841175276\n",
      "Loss 4.013944431656351\n",
      "Loss 4.018460931612253\n",
      "Loss 4.021464682428883\n",
      "Loss 4.027420196053055\n",
      "Loss 4.025385862496282\n",
      "Loss 4.02094003238863\n",
      "Loss 4.023061133938034\n",
      "Loss 4.025769597427499\n",
      "Loss 4.031601309125311\n",
      "Loss 4.035809438677449\n",
      "Loss 4.0330920403880235\n",
      "Loss 4.0408147568038535\n",
      "Loss 4.042750756719046\n",
      "Loss 4.044991575703428\n",
      "Loss 4.045503134203584\n",
      "Loss 4.054672330489526\n",
      "Loss 4.056638995727897\n",
      "Loss 4.060197173519832\n",
      "Loss 4.0633958456544645\n",
      "Loss 4.064458020712054\n",
      "Loss 4.062446737915278\n",
      "Loss 4.066681885743141\n",
      "Loss 4.070616126656533\n",
      "Loss 4.065370567608387\n",
      "Loss 4.070220552893977\n",
      "Loss 4.073635275916177\n",
      "Loss 4.076942269086838\n",
      "Loss 4.077860364371655\n",
      "Loss 4.08190163187568\n",
      "Loss 4.084563276223417\n",
      "Loss 4.0847748201467375\n",
      "Loss 4.087373607024279\n",
      "Loss 4.085462148704699\n",
      "Loss 4.087482200921627\n",
      "Loss 4.089885848273491\n",
      "Loss 4.089868442392955\n",
      "Loss 4.089612620664636\n",
      "Loss 4.090051116088374\n",
      "Loss 4.0902713055677955\n",
      "Epoch 5/30, Train Loss: 4.0887, Test Loss: 4.5807\n",
      "Loss 4.001582045435906\n",
      "Loss 4.0564948124289515\n",
      "Loss 4.018230157971382\n",
      "Loss 3.986051256924868\n",
      "Loss 3.992719593024254\n",
      "Loss 3.9595738540391126\n",
      "Loss 3.9950889897431647\n",
      "Loss 3.9982460711449384\n",
      "Loss 3.980983861592081\n",
      "Loss 3.9757513235211372\n",
      "Loss 3.9691683686971664\n",
      "Loss 3.9590313273270925\n",
      "Loss 3.959536574803866\n",
      "Loss 3.95591429070064\n",
      "Loss 3.944367878083388\n",
      "Loss 3.9563591499067843\n",
      "Loss 3.9486674177120715\n",
      "Loss 3.9425537826584445\n",
      "Loss 3.9559154082756294\n",
      "Loss 3.9620977647677065\n",
      "Loss 3.960190758297841\n",
      "Loss 3.9692669672925365\n",
      "Loss 3.9678343908475795\n",
      "Loss 3.9741796455780665\n",
      "Loss 3.9785567223215104\n",
      "Loss 3.982221207531599\n",
      "Loss 3.988321310705609\n",
      "Loss 3.9858014544546605\n",
      "Loss 3.981239433662645\n",
      "Loss 3.983658439497153\n",
      "Loss 3.986500236149757\n",
      "Loss 3.992396688438952\n",
      "Loss 3.9967610192262764\n",
      "Loss 3.9943662424363633\n",
      "Loss 4.001988760229094\n",
      "Loss 4.004184062218914\n",
      "Loss 4.00674357804052\n",
      "Loss 4.0077052063561585\n",
      "Loss 4.016842026902697\n",
      "Loss 4.018934879758581\n",
      "Loss 4.022890316064402\n",
      "Loss 4.0266158136012296\n",
      "Loss 4.027924840885193\n",
      "Loss 4.0256688099202105\n",
      "Loss 4.029529737906655\n",
      "Loss 4.033556517395961\n",
      "Loss 4.028435197445623\n",
      "Loss 4.03338472140301\n",
      "Loss 4.037140885975592\n",
      "Loss 4.0405104189226035\n",
      "Loss 4.041520901504393\n",
      "Loss 4.0458208618390445\n",
      "Loss 4.048756053915282\n",
      "Loss 4.048823746703013\n",
      "Loss 4.051385387749835\n",
      "Loss 4.049754162581637\n",
      "Loss 4.051999995915252\n",
      "Loss 4.05444053507031\n",
      "Loss 4.054422079494191\n",
      "Loss 4.054012830340614\n",
      "Loss 4.0546484776029335\n",
      "Loss 4.054690491313655\n",
      "Epoch 6/30, Train Loss: 4.0532, Test Loss: 4.5783\n",
      "Loss 3.9624685381650924\n",
      "Loss 4.010982632339001\n",
      "Loss 3.975597927570343\n",
      "Loss 3.9439765528440476\n",
      "Loss 3.9516847210407255\n",
      "Loss 3.9178162313699723\n",
      "Loss 3.951835428578513\n",
      "Loss 3.954328714825213\n",
      "Loss 3.93970801816384\n",
      "Loss 3.9366707190215586\n",
      "Loss 3.931900998879563\n",
      "Loss 3.923808337718248\n",
      "Loss 3.9246354348934616\n",
      "Loss 3.92081164096083\n",
      "Loss 3.9082791949709255\n",
      "Loss 3.919533773828298\n",
      "Loss 3.912480566126459\n",
      "Loss 3.9072180095712343\n",
      "Loss 3.9202150255159327\n",
      "Loss 3.925771566902101\n",
      "Loss 3.924223849857137\n",
      "Loss 3.933256571269848\n",
      "Loss 3.931510149307873\n",
      "Loss 3.93801086119314\n",
      "Loss 3.9431138497662546\n",
      "Loss 3.9466213695842485\n",
      "Loss 3.9521048820725193\n",
      "Loss 3.9489089534836155\n",
      "Loss 3.944496434318608\n",
      "Loss 3.946452578628063\n",
      "Loss 3.949602860931427\n",
      "Loss 3.9557481492832305\n",
      "Loss 3.959929625605092\n",
      "Loss 3.957470878328909\n",
      "Loss 3.9654299649779285\n",
      "Loss 3.967952424727794\n",
      "Loss 3.9707206635922194\n",
      "Loss 3.9716732157809953\n",
      "Loss 3.980984705686187\n",
      "Loss 3.9830729831483214\n",
      "Loss 3.9870803176277296\n",
      "Loss 3.990949220004181\n",
      "Loss 3.9923964178253746\n",
      "Loss 3.9902859483439137\n",
      "Loss 3.994230328568816\n",
      "Loss 3.99841610210972\n",
      "Loss 3.993471955343447\n",
      "Loss 3.9984207841055466\n",
      "Loss 4.001846784187519\n",
      "Loss 4.005327776691615\n",
      "Loss 4.0063923105232275\n",
      "Loss 4.010720307063312\n",
      "Loss 4.013628059114769\n",
      "Loss 4.013682569271713\n",
      "Loss 4.016322062086788\n",
      "Loss 4.014869084702805\n",
      "Loss 4.017233479413808\n",
      "Loss 4.0198001950915\n",
      "Loss 4.01978594682454\n",
      "Loss 4.019271783400327\n",
      "Loss 4.019843940299798\n",
      "Loss 4.019644290893068\n",
      "Epoch 7/30, Train Loss: 4.0181, Test Loss: 4.5894\n",
      "Loss 3.927346689939499\n",
      "Loss 3.9632085421085357\n",
      "Loss 3.927680553197861\n",
      "Loss 3.899090144261718\n",
      "Loss 3.9073168357014656\n",
      "Loss 3.8785408962170282\n",
      "Loss 3.9119103253739222\n",
      "Loss 3.9120551781132815\n",
      "Loss 3.896604298836655\n",
      "Loss 3.8935666513741016\n",
      "Loss 3.888678476349874\n",
      "Loss 3.8806913688033817\n",
      "Loss 3.884047032076579\n",
      "Loss 3.8809445414585726\n",
      "Loss 3.8683087414542836\n",
      "Loss 3.879781723957509\n",
      "Loss 3.873201565409408\n",
      "Loss 3.8677664857904115\n",
      "Loss 3.8813242957654754\n",
      "Loss 3.887298800215125\n",
      "Loss 3.88592661378781\n",
      "Loss 3.894264306244525\n",
      "Loss 3.8930039837671364\n",
      "Loss 3.898811286931237\n",
      "Loss 3.9040891303515433\n",
      "Loss 3.90763227094366\n",
      "Loss 3.913132524157012\n",
      "Loss 3.909951953732542\n",
      "Loss 3.9052146329037076\n",
      "Loss 3.907446634231011\n",
      "Loss 3.9103451484730165\n",
      "Loss 3.916490071577951\n",
      "Loss 3.920987291789416\n",
      "Loss 3.918757854122888\n",
      "Loss 3.9265622466253385\n",
      "Loss 3.9290026745361586\n",
      "Loss 3.9314753917709395\n",
      "Loss 3.9323033624271813\n",
      "Loss 3.9415894568222454\n",
      "Loss 3.944004026330635\n",
      "Loss 3.9479646715372803\n",
      "Loss 3.9521405774450726\n",
      "Loss 3.9539748890438053\n",
      "Loss 3.9521530052284626\n",
      "Loss 3.956271072876122\n",
      "Loss 3.960635135643832\n",
      "Loss 3.9559519988751792\n",
      "Loss 3.961038246081211\n",
      "Loss 3.9644673597797446\n",
      "Loss 3.9680542474469545\n",
      "Loss 3.9691343525025773\n",
      "Loss 3.973823451304378\n",
      "Loss 3.9768167222296853\n",
      "Loss 3.977048931149145\n",
      "Loss 3.9794171647426757\n",
      "Loss 3.9779968348494066\n",
      "Loss 3.9804857929973747\n",
      "Loss 3.9832442199266676\n",
      "Loss 3.9833558639204605\n",
      "Loss 3.9830216945605974\n",
      "Loss 3.9835905201198134\n",
      "Loss 3.983362675944403\n",
      "Epoch 8/30, Train Loss: 3.9818, Test Loss: 4.6255\n",
      "Loss 3.891163857221603\n",
      "Loss 3.9210018830895423\n",
      "Loss 3.8813628914356233\n",
      "Loss 3.855603749603033\n",
      "Loss 3.8629123288154603\n",
      "Loss 3.8299874301056067\n",
      "Loss 3.8654213515605247\n",
      "Loss 3.866370649687946\n",
      "Loss 3.852072496778435\n",
      "Loss 3.8494826121985914\n",
      "Loss 3.84480661477284\n",
      "Loss 3.837245261376103\n",
      "Loss 3.8412121292352674\n",
      "Loss 3.8385536862100875\n",
      "Loss 3.8255409617384273\n",
      "Loss 3.8364425910972058\n",
      "Loss 3.8295922649152137\n",
      "Loss 3.824990105642213\n",
      "Loss 3.8385770255044886\n",
      "Loss 3.8453222244530916\n",
      "Loss 3.8450253303079376\n",
      "Loss 3.8541644774431534\n",
      "Loss 3.853432397239882\n",
      "Loss 3.8590266437220078\n",
      "Loss 3.8641329077541826\n",
      "Loss 3.868022646038578\n",
      "Loss 3.8735723908400095\n",
      "Loss 3.870889939364578\n",
      "Loss 3.8657645644905236\n",
      "Loss 3.868438854067524\n",
      "Loss 3.871459715774944\n",
      "Loss 3.8780174188623207\n",
      "Loss 3.8827299765068473\n",
      "Loss 3.880686062562553\n",
      "Loss 3.888718105846218\n",
      "Loss 3.8910426923156614\n",
      "Loss 3.89360648726974\n",
      "Loss 3.8947579741042695\n",
      "Loss 3.9041006781172296\n",
      "Loss 3.906587794000283\n",
      "Loss 3.910622531027692\n",
      "Loss 3.9150314296118562\n",
      "Loss 3.916983100181749\n",
      "Loss 3.915188479818065\n",
      "Loss 3.9193439606206284\n",
      "Loss 3.9237420166747077\n",
      "Loss 3.9192832644876647\n",
      "Loss 3.9238951177264876\n",
      "Loss 3.927490981986632\n",
      "Loss 3.9311311972370744\n",
      "Loss 3.932339347564999\n",
      "Loss 3.9369333439712912\n",
      "Loss 3.939867702849912\n",
      "Loss 3.940213257159624\n",
      "Loss 3.942685118464177\n",
      "Loss 3.9410848394219897\n",
      "Loss 3.943935566282325\n",
      "Loss 3.9467630829577303\n",
      "Loss 3.946979485224112\n",
      "Loss 3.946476873369267\n",
      "Loss 3.947127924834363\n",
      "Loss 3.9467642936785854\n",
      "Epoch 9/30, Train Loss: 3.9453, Test Loss: 4.6087\n",
      "Loss 3.842177757740021\n",
      "Loss 3.881730130374432\n",
      "Loss 3.837657574613889\n",
      "Loss 3.8100467878580093\n",
      "Loss 3.814266344809532\n",
      "Loss 3.7812014803886416\n",
      "Loss 3.8160292249917984\n",
      "Loss 3.8190302702262997\n",
      "Loss 3.8042252759337427\n",
      "Loss 3.802367192846537\n",
      "Loss 3.798911212980747\n",
      "Loss 3.790950851688782\n",
      "Loss 3.795858250246598\n",
      "Loss 3.7945459118953773\n",
      "Loss 3.7823342551151913\n",
      "Loss 3.7933735778555273\n",
      "Loss 3.78742068289308\n",
      "Loss 3.7839519641664294\n",
      "Loss 3.7976297780526314\n",
      "Loss 3.804166974078119\n",
      "Loss 3.804345586111148\n",
      "Loss 3.8140928175815128\n",
      "Loss 3.81307829800896\n",
      "Loss 3.818656365295251\n",
      "Loss 3.8240205995416643\n",
      "Loss 3.827520401615363\n",
      "Loss 3.8325487550585358\n",
      "Loss 3.829924510994128\n",
      "Loss 3.8256470249973495\n",
      "Loss 3.828172264953454\n",
      "Loss 3.8310586381266196\n",
      "Loss 3.8378300518095494\n",
      "Loss 3.8431465227459416\n",
      "Loss 3.8411145748268156\n",
      "Loss 3.8492375030721937\n",
      "Loss 3.85192721424169\n",
      "Loss 3.854542542270712\n",
      "Loss 3.8557300682883513\n",
      "Loss 3.865520810980063\n",
      "Loss 3.8683788866519926\n",
      "Loss 3.872600984765262\n",
      "Loss 3.8768708650498165\n",
      "Loss 3.8790559243878655\n",
      "Loss 3.877397747069597\n",
      "Loss 3.881937345451779\n",
      "Loss 3.886606041897898\n",
      "Loss 3.8818526049674826\n",
      "Loss 3.8866178820667168\n",
      "Loss 3.890261151874552\n",
      "Loss 3.8937277993404864\n",
      "Loss 3.8949369222007544\n",
      "Loss 3.8996884932139744\n",
      "Loss 3.9027883968342025\n",
      "Loss 3.9031916255785357\n",
      "Loss 3.9058950925642795\n",
      "Loss 3.9042544576664056\n",
      "Loss 3.906939437543091\n",
      "Loss 3.909700803821457\n",
      "Loss 3.9096649737721783\n",
      "Loss 3.909489858762423\n",
      "Loss 3.9101367538014395\n",
      "Loss 3.9098972506744247\n",
      "Epoch 10/30, Train Loss: 3.9084, Test Loss: 4.6234\n",
      "Loss 3.7903835639953614\n",
      "Loss 3.8172632169723513\n",
      "Loss 3.7764371117750803\n",
      "Loss 3.7570787563323975\n",
      "Loss 3.7603647357940675\n",
      "Loss 3.7272876466810705\n",
      "Loss 3.764133209475449\n",
      "Loss 3.7679013663455843\n",
      "Loss 3.7569143702520265\n",
      "Loss 3.7543323132812976\n",
      "Loss 3.7505831226164643\n",
      "Loss 3.743629463300109\n",
      "Loss 3.74890228581887\n",
      "Loss 3.747023670124156\n",
      "Loss 3.7367202582716943\n",
      "Loss 3.7482474805302917\n",
      "Loss 3.7437411546812336\n",
      "Loss 3.7411743849118553\n",
      "Loss 3.7556358042171127\n",
      "Loss 3.7613543797031044\n",
      "Loss 3.7622718122757615\n",
      "Loss 3.772858757930723\n",
      "Loss 3.772060404614262\n",
      "Loss 3.7783663031980397\n",
      "Loss 3.7834253016257287\n",
      "Loss 3.7869196647611947\n",
      "Loss 3.792032123612033\n",
      "Loss 3.789546962748681\n",
      "Loss 3.784895048973889\n",
      "Loss 3.7876792182981966\n",
      "Loss 3.790864005840594\n",
      "Loss 3.797845619155094\n",
      "Loss 3.8032722806153876\n",
      "Loss 3.8011547878117247\n",
      "Loss 3.8094574082302195\n",
      "Loss 3.8122063038543694\n",
      "Loss 3.8150445545553358\n",
      "Loss 3.8164337785114584\n",
      "Loss 3.8260629399674824\n",
      "Loss 3.829269057693705\n",
      "Loss 3.83356114115039\n",
      "Loss 3.8377567743400025\n",
      "Loss 3.84000449236569\n",
      "Loss 3.83848636626757\n",
      "Loss 3.842792558727993\n",
      "Loss 3.8472018565610053\n",
      "Loss 3.8426681783183456\n",
      "Loss 3.847654504661448\n",
      "Loss 3.8513665981143714\n",
      "Loss 3.854755513393581\n",
      "Loss 3.856169809144794\n",
      "Loss 3.860671148297592\n",
      "Loss 3.863932860913985\n",
      "Loss 3.8642182511618293\n",
      "Loss 3.8672245691816913\n",
      "Loss 3.8657575329794946\n",
      "Loss 3.8685778991776076\n",
      "Loss 3.8716647755192786\n",
      "Loss 3.871721991062922\n",
      "Loss 3.871289055213084\n",
      "Loss 3.872118688398453\n",
      "Loss 3.871922200148865\n",
      "Epoch 11/30, Train Loss: 3.8705, Test Loss: 4.6282\n",
      "Loss 3.7339663944244386\n",
      "Loss 3.761225035786629\n",
      "Loss 3.7222552156051\n",
      "Loss 3.7067445158064367\n",
      "Loss 3.712044585633278\n",
      "Loss 3.6761802695691586\n",
      "Loss 3.7124943370052748\n",
      "Loss 3.7190696266889574\n",
      "Loss 3.708999025411076\n",
      "Loss 3.7105896661877633\n",
      "Loss 3.7082195080193605\n",
      "Loss 3.70103339620928\n",
      "Loss 3.707108394228495\n",
      "Loss 3.7070418600865773\n",
      "Loss 3.696980059683323\n",
      "Loss 3.7081588459424673\n",
      "Loss 3.703713511491523\n",
      "Loss 3.7018154574897553\n",
      "Loss 3.716330625653267\n",
      "Loss 3.723216770897806\n",
      "Loss 3.7250144723753134\n",
      "Loss 3.7357060248350553\n",
      "Loss 3.73535718104632\n",
      "Loss 3.7414048215597866\n",
      "Loss 3.746682169561386\n",
      "Loss 3.750149493070749\n",
      "Loss 3.7546973870860207\n",
      "Loss 3.7521358196650234\n",
      "Loss 3.7479502983298794\n",
      "Loss 3.7508492514530816\n",
      "Loss 3.7541207883704093\n",
      "Loss 3.7606476384587584\n",
      "Loss 3.765769868186026\n",
      "Loss 3.7644600341543555\n",
      "Loss 3.7727946664448297\n",
      "Loss 3.775477298174881\n",
      "Loss 3.778300960023258\n",
      "Loss 3.779305627773859\n",
      "Loss 3.7886181698498818\n",
      "Loss 3.7923480377119034\n",
      "Loss 3.796667164507072\n",
      "Loss 3.8011095826153953\n",
      "Loss 3.803573999369907\n",
      "Loss 3.802010811174119\n",
      "Loss 3.8062726791616943\n",
      "Loss 3.8105256503635774\n",
      "Loss 3.8059114496197473\n",
      "Loss 3.810797882701891\n",
      "Loss 3.8145117072970893\n",
      "Loss 3.8178904490837455\n",
      "Loss 3.819276071194048\n",
      "Loss 3.823827287434099\n",
      "Loss 3.827101309169857\n",
      "Loss 3.8277198796413012\n",
      "Loss 3.831049845685471\n",
      "Loss 3.829775936727811\n",
      "Loss 3.8325992902985266\n",
      "Loss 3.83589928035361\n",
      "Loss 3.835831805080428\n",
      "Loss 3.8354178064651787\n",
      "Loss 3.8363590324635877\n",
      "Loss 3.8361726573664816\n",
      "Epoch 12/30, Train Loss: 3.8347, Test Loss: 4.6433\n",
      "Loss 3.6870517305135726\n",
      "Loss 3.706667203783989\n",
      "Loss 3.6736920620997746\n",
      "Loss 3.6588578527718782\n",
      "Loss 3.6658875891208647\n",
      "Loss 3.6294638245900472\n",
      "Loss 3.665802375027112\n",
      "Loss 3.6731940554976465\n",
      "Loss 3.664345257308748\n",
      "Loss 3.6663146055698395\n",
      "Loss 3.665378015496514\n",
      "Loss 3.65912322020034\n",
      "Loss 3.6667462955208925\n",
      "Loss 3.667650000406163\n",
      "Loss 3.657580762461821\n",
      "Loss 3.669205155003816\n",
      "Loss 3.665436154151664\n",
      "Loss 3.6632380386855865\n",
      "Loss 3.6775683489394817\n",
      "Loss 3.6849135731980205\n",
      "Loss 3.6866002308343138\n",
      "Loss 3.6980700605931607\n",
      "Loss 3.6975004172597243\n",
      "Loss 3.703885943185538\n",
      "Loss 3.7095154881751538\n",
      "Loss 3.713021093582878\n",
      "Loss 3.71712711017772\n",
      "Loss 3.714450275188046\n",
      "Loss 3.710986191717715\n",
      "Loss 3.714235774605473\n",
      "Loss 3.7177721720097527\n",
      "Loss 3.7246885805325585\n",
      "Loss 3.729930760662664\n",
      "Loss 3.728734085938948\n",
      "Loss 3.7373326881923847\n",
      "Loss 3.740225176119556\n",
      "Loss 3.7432514434122557\n",
      "Loss 3.744621877338149\n",
      "Loss 3.754358146566993\n",
      "Loss 3.7582817895743994\n",
      "Loss 3.762873839198453\n",
      "Loss 3.767366118979241\n",
      "Loss 3.7695996387535056\n",
      "Loss 3.767701692632992\n",
      "Loss 3.7715919899519945\n",
      "Loss 3.775829241294252\n",
      "Loss 3.771477381653291\n",
      "Loss 3.776393992009573\n",
      "Loss 3.7802446213136522\n",
      "Loss 3.7834861223080756\n",
      "Loss 3.7850990537828673\n",
      "Loss 3.789711516366842\n",
      "Loss 3.7934269678415555\n",
      "Loss 3.7940080366954207\n",
      "Loss 3.7970820550747892\n",
      "Loss 3.7958782761014467\n",
      "Loss 3.7987999824894625\n",
      "Loss 3.8020445892792836\n",
      "Loss 3.802077202729502\n",
      "Loss 3.801666467453291\n",
      "Loss 3.8025532408026885\n",
      "Loss 3.802280398662292\n",
      "Epoch 13/30, Train Loss: 3.8008, Test Loss: 4.6448\n",
      "Loss 3.6278620166778563\n",
      "Loss 3.65267007291317\n",
      "Loss 3.6211475779215494\n",
      "Loss 3.6050381255596875\n",
      "Loss 3.6127998926877973\n",
      "Loss 3.5767180180052915\n",
      "Loss 3.6124287593279565\n",
      "Loss 3.6221421131044624\n",
      "Loss 3.6138542246421177\n",
      "Loss 3.6165576404869557\n",
      "Loss 3.6174888159741054\n",
      "Loss 3.6125067523916563\n",
      "Loss 3.6212650643220314\n",
      "Loss 3.622528670660087\n",
      "Loss 3.6133058589220046\n",
      "Loss 3.624949498794973\n",
      "Loss 3.6210660186094397\n",
      "Loss 3.620358344035016\n",
      "Loss 3.635420076586698\n",
      "Loss 3.6427980690404773\n",
      "Loss 3.6450192265099\n",
      "Loss 3.6564615326130934\n",
      "Loss 3.656516459236974\n",
      "Loss 3.6633564836184185\n",
      "Loss 3.668929177737236\n",
      "Loss 3.672894199174184\n",
      "Loss 3.676810171122904\n",
      "Loss 3.674018313642059\n",
      "Loss 3.6703635257523635\n",
      "Loss 3.673529604323705\n",
      "Loss 3.6769786767805774\n",
      "Loss 3.6838300254158676\n",
      "Loss 3.689371530937426\n",
      "Loss 3.6884362416517207\n",
      "Loss 3.6967736972744976\n",
      "Loss 3.6998016860555443\n",
      "Loss 3.703173314832755\n",
      "Loss 3.7052784528751905\n",
      "Loss 3.7151594004589015\n",
      "Loss 3.719435359947756\n",
      "Loss 3.7241014625346516\n",
      "Loss 3.7287289530255254\n",
      "Loss 3.7313416444357745\n",
      "Loss 3.729930401024832\n",
      "Loss 3.7341548674719203\n",
      "Loss 3.7383512583974263\n",
      "Loss 3.7338344376749815\n",
      "Loss 3.7387470025770986\n",
      "Loss 3.742696728548529\n",
      "Loss 3.7463133950594067\n",
      "Loss 3.747799958610359\n",
      "Loss 3.752690827055906\n",
      "Loss 3.7562164235837616\n",
      "Loss 3.7571486027133134\n",
      "Loss 3.760386839797551\n",
      "Loss 3.7595502315741034\n",
      "Loss 3.7626444830416066\n",
      "Loss 3.7660240516295205\n",
      "Loss 3.766008091873284\n",
      "Loss 3.765662530725449\n",
      "Loss 3.7667644080698\n",
      "Loss 3.766783938782109\n",
      "Epoch 14/30, Train Loss: 3.7654, Test Loss: 4.6622\n",
      "Loss 3.596436031937599\n",
      "Loss 3.600525997519493\n",
      "Loss 3.5778846945762632\n",
      "Loss 3.561937877967954\n",
      "Loss 3.5693013768434523\n",
      "Loss 3.5350525557398798\n",
      "Loss 3.57090329677718\n",
      "Loss 3.5791657510325314\n",
      "Loss 3.5735930214921634\n",
      "Loss 3.577681345170736\n",
      "Loss 3.5795533520579337\n",
      "Loss 3.576337134733796\n",
      "Loss 3.58518443775177\n",
      "Loss 3.587046839126519\n",
      "Loss 3.577024292210738\n",
      "Loss 3.589063761923462\n",
      "Loss 3.5857901335218374\n",
      "Loss 3.584863768282864\n",
      "Loss 3.5994781886794067\n",
      "Loss 3.6079555798619984\n",
      "Loss 3.6101469251201266\n",
      "Loss 3.621140167610212\n",
      "Loss 3.621914986009183\n",
      "Loss 3.6288721317648887\n",
      "Loss 3.635010340986252\n",
      "Loss 3.639554296433926\n",
      "Loss 3.6430804846397153\n",
      "Loss 3.6394322767704725\n",
      "Loss 3.636531812583578\n",
      "Loss 3.6401225574314595\n",
      "Loss 3.643583091856972\n",
      "Loss 3.650687622366473\n",
      "Loss 3.656543161105026\n",
      "Loss 3.655751319707755\n",
      "Loss 3.664418228004234\n",
      "Loss 3.6678559151072467\n",
      "Loss 3.6708605686921527\n",
      "Loss 3.6730676815788215\n",
      "Loss 3.682799345074174\n",
      "Loss 3.6869610823418943\n",
      "Loss 3.6915937497437725\n",
      "Loss 3.69643699240649\n",
      "Loss 3.6991847052432076\n",
      "Loss 3.6977573872990908\n",
      "Loss 3.702431053391761\n",
      "Loss 3.7068718144942236\n",
      "Loss 3.7021586473783916\n",
      "Loss 3.7066849089435614\n",
      "Loss 3.710362228215653\n",
      "Loss 3.713917615549266\n",
      "Loss 3.715256562609006\n",
      "Loss 3.7202281103200066\n",
      "Loss 3.724551270894003\n",
      "Loss 3.7259314522961224\n",
      "Loss 3.7295071237344635\n",
      "Loss 3.72888531033881\n",
      "Loss 3.732085140890981\n",
      "Loss 3.7355322119981564\n",
      "Loss 3.735324240855999\n",
      "Loss 3.7352429001944762\n",
      "Loss 3.736604929659943\n",
      "Loss 3.7364150913201515\n",
      "Epoch 15/30, Train Loss: 3.7350, Test Loss: 4.6648\n",
      "Loss 3.570273954629898\n",
      "Loss 3.566408338427544\n",
      "Loss 3.5415634484887124\n",
      "Loss 3.524148353561759\n",
      "Loss 3.5310657550573348\n",
      "Loss 3.4953799205621086\n",
      "Loss 3.534084067446845\n",
      "Loss 3.542555863440037\n",
      "Loss 3.538376151363055\n",
      "Loss 3.5420677883982656\n",
      "Loss 3.5455127342397517\n",
      "Loss 3.5411870207339526\n",
      "Loss 3.550465033723758\n",
      "Loss 3.5526318912080357\n",
      "Loss 3.5429682862957317\n",
      "Loss 3.555189576152712\n",
      "Loss 3.5517033075129283\n",
      "Loss 3.5518746046457026\n",
      "Loss 3.5666866232297925\n",
      "Loss 3.5753102619066834\n",
      "Loss 3.5771153189298652\n",
      "Loss 3.5886336793100293\n",
      "Loss 3.5895414578487044\n",
      "Loss 3.5957031098989147\n",
      "Loss 3.6015041994154453\n",
      "Loss 3.6054722149566962\n",
      "Loss 3.609392408694382\n",
      "Loss 3.6059508182055184\n",
      "Loss 3.6026260786745055\n",
      "Loss 3.6062830022960903\n",
      "Loss 3.610168277204998\n",
      "Loss 3.617351013711654\n",
      "Loss 3.622945411287474\n",
      "Loss 3.6223803536707866\n",
      "Loss 3.6311462924250533\n",
      "Loss 3.634814123806854\n",
      "Loss 3.6375577566921713\n",
      "Loss 3.6396862698926737\n",
      "Loss 3.6490345077124924\n",
      "Loss 3.653552025888115\n",
      "Loss 3.658864453150732\n",
      "Loss 3.6634261109552213\n",
      "Loss 3.665750011283991\n",
      "Loss 3.6640788566368547\n",
      "Loss 3.66825210783018\n",
      "Loss 3.6726098283924484\n",
      "Loss 3.668392285249969\n",
      "Loss 3.6730051035390545\n",
      "Loss 3.6769565467378316\n",
      "Loss 3.6809512039095162\n",
      "Loss 3.68229118612058\n",
      "Loss 3.687211909329089\n",
      "Loss 3.691091823702151\n",
      "Loss 3.692330101567838\n",
      "Loss 3.6956019983253694\n",
      "Loss 3.694764106555177\n",
      "Loss 3.6980429123896257\n",
      "Loss 3.701364080694729\n",
      "Loss 3.701423494711266\n",
      "Loss 3.7016911227072278\n",
      "Loss 3.7032175791366178\n",
      "Loss 3.703000503182892\n",
      "Epoch 16/30, Train Loss: 3.7016, Test Loss: 4.6818\n",
      "Loss 3.537415088891983\n",
      "Loss 3.522587587058544\n",
      "Loss 3.5047183557550112\n",
      "Loss 3.4957060164809226\n",
      "Loss 3.506120226752758\n",
      "Loss 3.4654021720389525\n",
      "Loss 3.5020555212071964\n",
      "Loss 3.5112512488365173\n",
      "Loss 3.506494660642412\n",
      "Loss 3.5101848673939706\n",
      "Loss 3.5134108535376463\n",
      "Loss 3.509993032038212\n",
      "Loss 3.5195911878164\n",
      "Loss 3.5218152673670224\n",
      "Loss 3.514281524904569\n",
      "Loss 3.525513651408255\n",
      "Loss 3.5225231607100542\n",
      "Loss 3.522478703743882\n",
      "Loss 3.5374455593008745\n",
      "Loss 3.546046422895789\n",
      "Loss 3.548327163858073\n",
      "Loss 3.559200250487436\n",
      "Loss 3.5599568250671676\n",
      "Loss 3.5666584760074813\n",
      "Loss 3.572973012192249\n",
      "Loss 3.5765591940902746\n",
      "Loss 3.579197769176077\n",
      "Loss 3.5746800265078034\n",
      "Loss 3.5717521029443575\n",
      "Loss 3.575640941216548\n",
      "Loss 3.5792933213499283\n",
      "Loss 3.5861428553592414\n",
      "Loss 3.592006034159299\n",
      "Loss 3.591629373901469\n",
      "Loss 3.6002459658099073\n",
      "Loss 3.6041040814175376\n",
      "Loss 3.6073016846361194\n",
      "Loss 3.6095461686163355\n",
      "Loss 3.618562952419504\n",
      "Loss 3.6229847859133035\n",
      "Loss 3.6279339911519752\n",
      "Loss 3.632255701367699\n",
      "Loss 3.6346148416264805\n",
      "Loss 3.6329241714738307\n",
      "Loss 3.6369186297287546\n",
      "Loss 3.6414263969611214\n",
      "Loss 3.6371772075285937\n",
      "Loss 3.6416687389975415\n",
      "Loss 3.6452245219450217\n",
      "Loss 3.6489671509614587\n",
      "Loss 3.6505154517202403\n",
      "Loss 3.655483874210085\n",
      "Loss 3.6593206001736647\n",
      "Loss 3.6605073480421195\n",
      "Loss 3.663743323834647\n",
      "Loss 3.663020547046459\n",
      "Loss 3.6666073464691116\n",
      "Loss 3.669975435182195\n",
      "Loss 3.670037347726145\n",
      "Loss 3.6702875014277794\n",
      "Loss 3.6714602972554866\n",
      "Loss 3.6711531944719535\n",
      "Epoch 17/30, Train Loss: 3.6698, Test Loss: 4.7081\n",
      "Loss 3.4783475046157837\n",
      "Loss 3.4703128018379212\n",
      "Loss 3.458792573928833\n",
      "Loss 3.4492236665785314\n",
      "Loss 3.456156447696686\n",
      "Loss 3.4190487624406813\n",
      "Loss 3.4552659282343727\n",
      "Loss 3.4666540465801954\n",
      "Loss 3.462731373641226\n",
      "Loss 3.4668922276973726\n",
      "Loss 3.4711378096233716\n",
      "Loss 3.4677166309754055\n",
      "Loss 3.4771362586250674\n",
      "Loss 3.481679072988885\n",
      "Loss 3.4758735690196354\n",
      "Loss 3.4882126348614695\n",
      "Loss 3.485851261882221\n",
      "Loss 3.487139625986417\n",
      "Loss 3.503056721223028\n",
      "Loss 3.512633890800178\n",
      "Loss 3.514482678559564\n",
      "Loss 3.5257171647318386\n",
      "Loss 3.526923319931911\n",
      "Loss 3.5334966047617296\n",
      "Loss 3.539780762654543\n",
      "Loss 3.5435415568409057\n",
      "Loss 3.54643502874838\n",
      "Loss 3.5426648852857094\n",
      "Loss 3.5392143682231163\n",
      "Loss 3.5428317435890437\n",
      "Loss 3.5471097887014187\n",
      "Loss 3.554302339646034\n",
      "Loss 3.5602718294994395\n",
      "Loss 3.5598235765231006\n",
      "Loss 3.5685550386403286\n",
      "Loss 3.571984181656606\n",
      "Loss 3.57494670433692\n",
      "Loss 3.576964200899005\n",
      "Loss 3.586442653372502\n",
      "Loss 3.5911602242954075\n",
      "Loss 3.5964753893475705\n",
      "Loss 3.6009262167761724\n",
      "Loss 3.603319732411656\n",
      "Loss 3.601605842536823\n",
      "Loss 3.605567546823952\n",
      "Loss 3.610034166002403\n",
      "Loss 3.6059924310046307\n",
      "Loss 3.610455838622525\n",
      "Loss 3.614038474568907\n",
      "Loss 3.6182036700099705\n",
      "Loss 3.619601088392384\n",
      "Loss 3.62454551576823\n",
      "Loss 3.628243454514247\n",
      "Loss 3.629606344745667\n",
      "Loss 3.6328953033138407\n",
      "Loss 3.632058845830283\n",
      "Loss 3.6356364005610606\n",
      "Loss 3.63913285114796\n",
      "Loss 3.6394120556969765\n",
      "Loss 3.639692818234861\n",
      "Loss 3.6410663995122325\n",
      "Loss 3.640762416855462\n",
      "Epoch 18/30, Train Loss: 3.6394, Test Loss: 4.7149\n",
      "Loss 3.4669106191396715\n",
      "Loss 3.4384514931440355\n",
      "Loss 3.422266385157903\n",
      "Loss 3.408104352295399\n",
      "Loss 3.4170621699213983\n",
      "Loss 3.3787732735474902\n",
      "Loss 3.417393057193075\n",
      "Loss 3.4310145913884043\n",
      "Loss 3.429690692047278\n",
      "Loss 3.4343664341270923\n",
      "Loss 3.437879829195413\n",
      "Loss 3.435783520867427\n",
      "Loss 3.445916821154264\n",
      "Loss 3.4496916591567652\n",
      "Loss 3.4443920224587123\n",
      "Loss 3.4562629324644805\n",
      "Loss 3.454681048224954\n",
      "Loss 3.456942144761483\n",
      "Loss 3.473467656447699\n",
      "Loss 3.482757044878602\n",
      "Loss 3.484449236832914\n",
      "Loss 3.4956855661029165\n",
      "Loss 3.497345350465049\n",
      "Loss 3.504417316488922\n",
      "Loss 3.510933052892685\n",
      "Loss 3.5146664464427873\n",
      "Loss 3.516844895347401\n",
      "Loss 3.5130680694047896\n",
      "Loss 3.509924358197327\n",
      "Loss 3.5132544198771316\n",
      "Loss 3.517323469740729\n",
      "Loss 3.5242373500410467\n",
      "Loss 3.5301076490391385\n",
      "Loss 3.529720841970514\n",
      "Loss 3.5381584994724817\n",
      "Loss 3.541553494469987\n",
      "Loss 3.5450491438363048\n",
      "Loss 3.5473970248338422\n",
      "Loss 3.556725719456489\n",
      "Loss 3.5611679095909\n",
      "Loss 3.566706362574566\n",
      "Loss 3.571271007025526\n",
      "Loss 3.5739025595784186\n",
      "Loss 3.5722656144012106\n",
      "Loss 3.5758678879525925\n",
      "Loss 3.580526714545229\n",
      "Loss 3.5764242781984046\n",
      "Loss 3.580738543535272\n",
      "Loss 3.584598235981805\n",
      "Loss 3.5886977652835848\n",
      "Loss 3.5901235021703384\n",
      "Loss 3.594762865357674\n",
      "Loss 3.5987918802117402\n",
      "Loss 3.600124812474957\n",
      "Loss 3.603459781078859\n",
      "Loss 3.602592934774501\n",
      "Loss 3.605983614612044\n",
      "Loss 3.6096029656365\n",
      "Loss 3.609902551989434\n",
      "Loss 3.609962759038806\n",
      "Loss 3.6113974873863284\n",
      "Loss 3.6112224678618294\n",
      "Epoch 19/30, Train Loss: 3.6099, Test Loss: 4.7143\n",
      "Loss 3.4323431268930436\n",
      "Loss 3.394992645442486\n",
      "Loss 3.3881702456871667\n",
      "Loss 3.378032265484333\n",
      "Loss 3.3870466333031652\n",
      "Loss 3.3469976636668046\n",
      "Loss 3.3846810332281247\n",
      "Loss 3.3963596593737604\n",
      "Loss 3.39377813106113\n",
      "Loss 3.3994988897919654\n",
      "Loss 3.4045962577299638\n",
      "Loss 3.4026998623857896\n",
      "Loss 3.4129813087124092\n",
      "Loss 3.4176551450874126\n",
      "Loss 3.412096557899316\n",
      "Loss 3.424122504670173\n",
      "Loss 3.4225188352290323\n",
      "Loss 3.4244819335970615\n",
      "Loss 3.4409806327098296\n",
      "Loss 3.450654269036651\n",
      "Loss 3.453197770904927\n",
      "Loss 3.4649339845478533\n",
      "Loss 3.4670421528479327\n",
      "Loss 3.473659768650929\n",
      "Loss 3.480552052330971\n",
      "Loss 3.48438951087915\n",
      "Loss 3.486621449424161\n",
      "Loss 3.4826943492995843\n",
      "Loss 3.4802666836339853\n",
      "Loss 3.48407919092377\n",
      "Loss 3.488502910346754\n",
      "Loss 3.495350781040266\n",
      "Loss 3.501185397218574\n",
      "Loss 3.5007118284250884\n",
      "Loss 3.509504577591164\n",
      "Loss 3.513196998022083\n",
      "Loss 3.516524848511493\n",
      "Loss 3.518760160418325\n",
      "Loss 3.5277836630730293\n",
      "Loss 3.532503952916339\n",
      "Loss 3.537795664620472\n",
      "Loss 3.542472173431445\n",
      "Loss 3.544773180833043\n",
      "Loss 3.5430665427233006\n",
      "Loss 3.5467675136132373\n",
      "Loss 3.551299996872635\n",
      "Loss 3.5473983040239583\n",
      "Loss 3.5515283285022403\n",
      "Loss 3.5552156107440895\n",
      "Loss 3.559623053800166\n",
      "Loss 3.5613586128193373\n",
      "Loss 3.565921470946131\n",
      "Loss 3.5699586547503492\n",
      "Loss 3.5713335581027246\n",
      "Loss 3.5744590706134383\n",
      "Loss 3.5736723372917623\n",
      "Loss 3.577886193901039\n",
      "Loss 3.5813519973531367\n",
      "Loss 3.5818254697911316\n",
      "Loss 3.5818297587774692\n",
      "Loss 3.5832272045302096\n",
      "Loss 3.5830874088168625\n",
      "Epoch 20/30, Train Loss: 3.5818, Test Loss: 4.7270\n",
      "Loss 3.405819957137108\n",
      "Loss 3.3614923512935637\n",
      "Loss 3.3516216159860295\n",
      "Loss 3.3401859880238773\n",
      "Loss 3.349561809742451\n",
      "Loss 3.3122739563981694\n",
      "Loss 3.3482031087534767\n",
      "Loss 3.3590359234809877\n",
      "Loss 3.3573496520651713\n",
      "Loss 3.364705468535423\n",
      "Loss 3.3691419740806925\n",
      "Loss 3.3680040850540003\n",
      "Loss 3.3797609680891036\n",
      "Loss 3.3846980808717864\n",
      "Loss 3.3782458257516224\n",
      "Loss 3.3901842363104224\n",
      "Loss 3.3886709095379883\n",
      "Loss 3.391324874990516\n",
      "Loss 3.4077260136761165\n",
      "Loss 3.417752086830139\n",
      "Loss 3.420405761040392\n",
      "Loss 3.432491578679193\n",
      "Loss 3.434461013318404\n",
      "Loss 3.441225170866897\n",
      "Loss 3.447974168897867\n",
      "Loss 3.452247443548762\n",
      "Loss 3.454496464494202\n",
      "Loss 3.4508814161898833\n",
      "Loss 3.4489138142045204\n",
      "Loss 3.4521502647131683\n",
      "Loss 3.456470031829611\n",
      "Loss 3.463423944070004\n",
      "Loss 3.4697793000710733\n",
      "Loss 3.470388704731184\n",
      "Loss 3.4793208170090404\n",
      "Loss 3.4832849884910715\n",
      "Loss 3.4867007754283983\n",
      "Loss 3.489097421664941\n",
      "Loss 3.4984682565316176\n",
      "Loss 3.5035299782037734\n",
      "Loss 3.508749860321603\n",
      "Loss 3.5131738862622353\n",
      "Loss 3.5161416180078375\n",
      "Loss 3.514220542315732\n",
      "Loss 3.517812995986144\n",
      "Loss 3.522552656483391\n",
      "Loss 3.518126530005577\n",
      "Loss 3.5222680420801042\n",
      "Loss 3.5257432839213587\n",
      "Loss 3.5300492092967035\n",
      "Loss 3.531643476243113\n",
      "Loss 3.536457772607987\n",
      "Loss 3.5404338781428786\n",
      "Loss 3.5418312419145197\n",
      "Loss 3.544958028004386\n",
      "Loss 3.5442862902901004\n",
      "Loss 3.54780398721444\n",
      "Loss 3.551548643165621\n",
      "Loss 3.5522713572797127\n",
      "Loss 3.5523063954750698\n",
      "Loss 3.5539533366805216\n",
      "Loss 3.5535382692131305\n",
      "Epoch 21/30, Train Loss: 3.5523, Test Loss: 4.7447\n",
      "Loss 3.379955528855324\n",
      "Loss 3.3290059858858587\n",
      "Loss 3.3155803822278975\n",
      "Loss 3.3094236519038676\n",
      "Loss 3.319492253935337\n",
      "Loss 3.2798106652696926\n",
      "Loss 3.316359863127981\n",
      "Loss 3.328518993742764\n",
      "Loss 3.328366234269407\n",
      "Loss 3.3374099858224393\n",
      "Loss 3.3421771713224326\n",
      "Loss 3.3404428055038053\n",
      "Loss 3.3520887978352034\n",
      "Loss 3.357576423764229\n",
      "Loss 3.3508855128884316\n",
      "Loss 3.3631912133954467\n",
      "Loss 3.3620517066611963\n",
      "Loss 3.3642168621354633\n",
      "Loss 3.3807733566541422\n",
      "Loss 3.39069630574882\n",
      "Loss 3.3933285062114398\n",
      "Loss 3.4050359663123433\n",
      "Loss 3.4070822203366653\n",
      "Loss 3.4137575644056004\n",
      "Loss 3.4197852814292906\n",
      "Loss 3.423394241663126\n",
      "Loss 3.425341038229289\n",
      "Loss 3.421873576345188\n",
      "Loss 3.4192498578018156\n",
      "Loss 3.4222336622774603\n",
      "Loss 3.4266940851653778\n",
      "Loss 3.4338743946719914\n",
      "Loss 3.439615586972598\n",
      "Loss 3.440160230683053\n",
      "Loss 3.4487257012512003\n",
      "Loss 3.452343665127125\n",
      "Loss 3.455987945489787\n",
      "Loss 3.45824658305943\n",
      "Loss 3.467608866797808\n",
      "Loss 3.472432142701\n",
      "Loss 3.478051593026737\n",
      "Loss 3.4824591617775815\n",
      "Loss 3.4850287875262804\n",
      "Loss 3.4831535100225697\n",
      "Loss 3.4868269759529165\n",
      "Loss 3.4910359741870476\n",
      "Loss 3.4866492521578962\n",
      "Loss 3.491002792186414\n",
      "Loss 3.494999723742811\n",
      "Loss 3.4995075465124845\n",
      "Loss 3.5015573134019093\n",
      "Loss 3.506276033946528\n",
      "Loss 3.510347409139827\n",
      "Loss 3.51196236926262\n",
      "Loss 3.5151066227864134\n",
      "Loss 3.5144644876755775\n",
      "Loss 3.518338515253966\n",
      "Loss 3.522530315867272\n",
      "Loss 3.523066209378384\n",
      "Loss 3.523064419443905\n",
      "Loss 3.524493734095429\n",
      "Loss 3.5240750688098132\n",
      "Epoch 22/30, Train Loss: 3.5228, Test Loss: 4.7635\n",
      "Loss 3.3370650950670244\n",
      "Loss 3.285915785044432\n",
      "Loss 3.277384510457516\n",
      "Loss 3.27066504958272\n",
      "Loss 3.280795078253746\n",
      "Loss 3.241268161445856\n",
      "Loss 3.281068671405315\n",
      "Loss 3.295478320091963\n",
      "Loss 3.296491283006138\n",
      "Loss 3.305110675561428\n",
      "Loss 3.3097715579813176\n",
      "Loss 3.3091600076754886\n",
      "Loss 3.3205505156012682\n",
      "Loss 3.32631170338818\n",
      "Loss 3.3208576388518014\n",
      "Loss 3.333071105118841\n",
      "Loss 3.331609210347428\n",
      "Loss 3.3345547540883222\n",
      "Loss 3.3516249873042105\n",
      "Loss 3.3619935256183147\n",
      "Loss 3.3647777513293993\n",
      "Loss 3.376849903201515\n",
      "Loss 3.3795634663143885\n",
      "Loss 3.3859363615649443\n",
      "Loss 3.3922699242293834\n",
      "Loss 3.3959500736857837\n",
      "Loss 3.3982057552238305\n",
      "Loss 3.39487708530575\n",
      "Loss 3.3928938655596355\n",
      "Loss 3.3963472236980996\n",
      "Loss 3.4010147490684064\n",
      "Loss 3.4076613611271607\n",
      "Loss 3.4135462746864014\n",
      "Loss 3.413854164276053\n",
      "Loss 3.4223861417974746\n",
      "Loss 3.42578370893995\n",
      "Loss 3.4292388772223448\n",
      "Loss 3.4313409548903766\n",
      "Loss 3.440479132507092\n",
      "Loss 3.4453618928685783\n",
      "Loss 3.4505518281619723\n",
      "Loss 3.4554174786252636\n",
      "Loss 3.458063426462717\n",
      "Loss 3.4560232865647835\n",
      "Loss 3.459840355943309\n",
      "Loss 3.4643070958451085\n",
      "Loss 3.460041247934737\n",
      "Loss 3.463919771872461\n",
      "Loss 3.467590806632626\n",
      "Loss 3.4720544609737396\n",
      "Loss 3.47421818568426\n",
      "Loss 3.4790779277338433\n",
      "Loss 3.4831269772963704\n",
      "Loss 3.484509576803004\n",
      "Loss 3.487763279853084\n",
      "Loss 3.4875283145255276\n",
      "Loss 3.491441604351788\n",
      "Loss 3.4955717533508253\n",
      "Loss 3.4963904427835497\n",
      "Loss 3.496505758635203\n",
      "Loss 3.497847698532167\n",
      "Loss 3.4977268275407054\n",
      "Epoch 23/30, Train Loss: 3.4965, Test Loss: 4.7860\n",
      "Loss 3.3101267614364622\n",
      "Loss 3.2621525485813616\n",
      "Loss 3.2508115762074787\n",
      "Loss 3.248135673284531\n",
      "Loss 3.2607421507954597\n",
      "Loss 3.2206098333895206\n",
      "Loss 3.2545822958350183\n",
      "Loss 3.2664727912060916\n",
      "Loss 3.268790775295761\n",
      "Loss 3.2810544539183377\n",
      "Loss 3.284713764057918\n",
      "Loss 3.282745146371424\n",
      "Loss 3.2936568222481473\n",
      "Loss 3.299562571191362\n",
      "Loss 3.2939882799764475\n",
      "Loss 3.306102213187143\n",
      "Loss 3.3059464993354153\n",
      "Loss 3.3084108948955935\n",
      "Loss 3.325334801026081\n",
      "Loss 3.3352482504069805\n",
      "Loss 3.338623328302588\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 2\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(seq2seq, train_pairs_final, optimizer, criterion, device)\n\u001b[1;32m      3\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m evaluate(seq2seq, test_pairs_final, criterion, device)    \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [70], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, pairs, optimizer, criterion, device, teacher_forcing_ratio, print_every)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(seq2seq, train_pairs_final, optimizer, criterion, device)\n",
    "    test_loss = evaluate(seq2seq, test_pairs_final, criterion, device)    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    total_train_loss.append(train_loss)\n",
    "    total_test_loss.append(test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef025b4f-94a2-44b2-9c6e-b128a7c70929",
   "metadata": {},
   "source": [
    "### stopped after 23 epochs, doesn't seem to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdb1cfe2-66b2-4958-a11c-43b052cf2ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f82f724c-6453-4f0e-bf20-e67471f4c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, N_EPOCHS+1), total_train_loss, color = 'blue', label = 'train loss')\n",
    "ax.plot(range(1, N_EPOCHS+1), total_test_loss, color = 'orange', label = 'test loss')\n",
    "ax.legend()\n",
    "ax.set_title(f'Seq2Seq, {N_EPOCHS} epochs')\n",
    "ax.set_xticks(range(1, N_EPOCHS+1))\n",
    "ax.set_ylim(0,10)\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5b49a-fe9d-4546-bfcf-a53c8ead299e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_chatbot",
   "language": "python",
   "name": "lstm_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
