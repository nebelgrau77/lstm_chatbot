{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716bcc37-8e19-40cf-b73c-2573a962882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc31efee-972f-4c88-b8f3-892e6135a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2404e937-88f8-4252-a276-88ea59c1eaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589da3e3-0c7b-4312-8dac-c7b02b5e1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import SQuAD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91bfdb20-70b1-42bb-9a2e-4016119c6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = SQuAD1(\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67c8f73-9397-4840-a938-3c4cf882064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/nebelgrau/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nebelgrau/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nebelgrau/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from modules.data import get_dataframe,  get_pairs_from_df, cols, sample_df_perc, get_thresholds, get_outliers, tokenize_sentence, remove_least_common, to_tensor,  filter_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96e33e4-7b66-482d-aae5-703acbe9f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test dataframes of sentences\n",
    "train_df, test_df = get_dataframe(train), get_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d35eea8-a028-4950-b8fc-e21eb79567d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sample_df_perc(train_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca84778e-1032-40ce-9cd9-8e1e77de2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sample_df_perc(test_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364d7fa4-227a-4cc0-a820-02c04bd08245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17519, 2), (2114, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b973dec-def9-46dc-b930-3bfd24ad2db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what year were the Jews expelled from England?</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was the Pacific War Council formed in Was...</td>\n",
       "      <td>1 April 1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many of a 25-member Premier League squad m...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did the English order hope to gain knowled...</td>\n",
       "      <td>through an imitation of His life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When were several new villages built in France...</td>\n",
       "      <td>the 1970s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  In what year were the Jews expelled from England?   \n",
       "1  When was the Pacific War Council formed in Was...   \n",
       "2  How many of a 25-member Premier League squad m...   \n",
       "3  How did the English order hope to gain knowled...   \n",
       "4  When were several new villages built in France...   \n",
       "\n",
       "                             Answer  \n",
       "0                              1290  \n",
       "1                      1 April 1942  \n",
       "2                                 8  \n",
       "3  through an imitation of His life  \n",
       "4                         the 1970s  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef01711-dc10-45ee-8da8-ff9772f963aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Democratic candidate was the first to win 40% of the vote in Alaska since 1964?\n",
      "['which', 'democratic', 'candidate', 'first', 'win', '40', 'vote', 'alaska', 'since', '1964']\n",
      "['which', 'democrat', 'candid', 'first', 'win', '40', 'vote', 'alaska', 'sinc', '1964']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "rand_question = train_df.at[random.randint(0,train_df.shape[0]), 'Question']\n",
    "print(rand_question)\n",
    "\n",
    "print(tokenize_sentence(rand_question))\n",
    "print(tokenize_sentence(rand_question, normalization='stem'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f415da-a1b1-48b7-8f60-d709cadba824",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e834ec-f5be-4267-a333-da8363d4c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477798a-6d40-4ea5-9897-239f14f71d89",
   "metadata": {},
   "source": [
    "## Make pairs to add to the vocabularies. \n",
    "\n",
    "#### Only the questions will be normalized (stemmed) but not the answers - otherwise we would get stemmed words in the chatbot answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c449294-d806-484a-964d-3ecec1814be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, norm in zip(cols, ['stem', None]):\n",
    "    train_df[f'{col}_tokens'] = train_df[col].apply(lambda s: tokenize_sentence(s, normalization=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2381e04e-1612-4547-bdfd-a9c145963c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, norm in zip(cols, ['stem', None]):\n",
    "    test_df[f'{col}_tokens'] = test_df[col].apply(lambda s: tokenize_sentence(s, normalization=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8937ef7-0fa7-4274-82a1-4d1fcbefd9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_tokens</th>\n",
       "      <th>Answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>What label did ABC sell in 1979?</td>\n",
       "      <td>MCA Records</td>\n",
       "      <td>[what, label, abc, sell, 1979]</td>\n",
       "      <td>[mca, records]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>What country invaded Panama to capture Noriega?</td>\n",
       "      <td>United States</td>\n",
       "      <td>[what, countri, invad, panama, captur, noriega]</td>\n",
       "      <td>[united, states]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>What position was the teacher later given by t...</td>\n",
       "      <td>appoint Spada Master of the Sacred Palace in 1867</td>\n",
       "      <td>[what, posit, teacher, later, given, holi, rom...</td>\n",
       "      <td>[appoint, spada, master, sacred, palace, 1867]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "8184                   What label did ABC sell in 1979?   \n",
       "6043    What country invaded Panama to capture Noriega?   \n",
       "8115  What position was the teacher later given by t...   \n",
       "\n",
       "                                                 Answer  \\\n",
       "8184                                        MCA Records   \n",
       "6043                                      United States   \n",
       "8115  appoint Spada Master of the Sacred Palace in 1867   \n",
       "\n",
       "                                        Question_tokens  \\\n",
       "8184                     [what, label, abc, sell, 1979]   \n",
       "6043    [what, countri, invad, panama, captur, noriega]   \n",
       "8115  [what, posit, teacher, later, given, holi, rom...   \n",
       "\n",
       "                                       Answer_tokens  \n",
       "8184                                  [mca, records]  \n",
       "6043                                [united, states]  \n",
       "8115  [appoint, spada, master, sacred, palace, 1867]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e2abc35-9fb0-4c6f-9a09-e155652e96c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Question_tokens</th>\n",
       "      <th>Answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>Why was the Rhine regulated?</td>\n",
       "      <td>constant flooding</td>\n",
       "      <td>[whi, rhine, regul]</td>\n",
       "      <td>[constant, flooding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Who was Shi Tianze's father?</td>\n",
       "      <td>Shi Bingzhi</td>\n",
       "      <td>[who, shi, tianz, father]</td>\n",
       "      <td>[shi, bingzhi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>When did the Normans attack Dyrrachium?</td>\n",
       "      <td>1185</td>\n",
       "      <td>[when, norman, attack, dyrrachium]</td>\n",
       "      <td>[1185]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Question             Answer  \\\n",
       "2050            Why was the Rhine regulated?   constant flooding   \n",
       "185              Who was Shi Tianze's father?        Shi Bingzhi   \n",
       "1523  When did the Normans attack Dyrrachium?               1185   \n",
       "\n",
       "                         Question_tokens         Answer_tokens  \n",
       "2050                 [whi, rhine, regul]  [constant, flooding]  \n",
       "185            [who, shi, tianz, father]        [shi, bingzhi]  \n",
       "1523  [when, norman, attack, dyrrachium]                [1185]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183fe987-52b1-4aa9-a7b9-7a280801b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tokens = [f'{col}_tokens' for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7fbb827-376c-4ad7-af82-3d7cc06cd79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = get_pairs_from_df(train_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a99de2e-b85d-4cd2-aee4-a9b69e6c6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = get_pairs_from_df(test_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fdd71ac-b64d-44d7-a802-b50fd0518de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_vocab, A_vocab = Vocab(), Vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64f0726a-eac3-4183-b683-fb633b335d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in train_pairs:\n",
    "    Q_vocab.add_sentence(pair.question)\n",
    "    A_vocab.add_sentence(pair.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "177bb76f-4436-4356-9801-76f9b79afda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13033, 15973)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.n_words, A_vocab.n_words, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e56822d-103c-494d-94a1-db13521ae226",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in test_pairs:\n",
    "    Q_vocab.add_sentence(pair.question)\n",
    "    A_vocab.add_sentence(pair.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4209b40e-4fd4-4588-87f8-5c553269afc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13961, 17220)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.n_words, A_vocab.n_words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7efe36-e605-4ca6-81f6-60c73f363d77",
   "metadata": {},
   "source": [
    "## Functions for some data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc52ed74-0995-4cdf-bba0-33585a603473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.stats import sentences_stats, histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c697be1-74c0-4359-9b9b-4302b9dd5596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.43\n",
      "\t         median: 6.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 24)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.45\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 22)\n"
     ]
    }
   ],
   "source": [
    "# statistics for tokenized sentences\n",
    "sentences_stats(train_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "930637ed-160c-4baa-8826-32dbacaafb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.52\n",
      "\t         median: 6.00\n",
      "\t         minimum: 2\n",
      "\t         maximum: 16)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.33\n",
      "\t         median: 2.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 18)\n"
     ]
    }
   ],
   "source": [
    "# statistics for tokenized sentences\n",
    "sentences_stats(test_df, cols_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbd9e86-a9d3-49fb-9450-c36d8dd93b11",
   "metadata": {},
   "source": [
    "## Remove the least common words from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b707d766-d916-4fa2-af93-9cfcda7e63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times at most a word occurs to be considered an outlier\n",
    "outlier_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e10a684-60d8-468e-b852-936fbf2c38b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['washingto',\n",
       "  '25member',\n",
       "  'appeas',\n",
       "  'businesspeopl',\n",
       "  'nomenclatur',\n",
       "  'spong',\n",
       "  'fidd',\n",
       "  'sciarra',\n",
       "  'canonburi',\n",
       "  'grandmoth',\n",
       "  'puget',\n",
       "  'dormit',\n",
       "  'troy',\n",
       "  'austrailia',\n",
       "  '850',\n",
       "  'coincid',\n",
       "  'swish',\n",
       "  'beal',\n",
       "  'mid2008',\n",
       "  'stick',\n",
       "  'legionnair',\n",
       "  'intermarriag',\n",
       "  'bingley',\n",
       "  'peruvian',\n",
       "  'lowdens',\n",
       "  'highdens',\n",
       "  'ron',\n",
       "  'youlou',\n",
       "  'downsid',\n",
       "  'constern',\n",
       "  'haemophiliac',\n",
       "  'footwear',\n",
       "  'jouvert',\n",
       "  'drag',\n",
       "  'hussein',\n",
       "  'magnus',\n",
       "  'hui',\n",
       "  'hivaid',\n",
       "  'bicommut',\n",
       "  'chile',\n",
       "  'ndp',\n",
       "  'soli',\n",
       "  'borodino',\n",
       "  'vaudevill',\n",
       "  'amphetamin',\n",
       "  'nasal',\n",
       "  'decongest',\n",
       "  'nettl',\n",
       "  'romani',\n",
       "  'pharaoh',\n",
       "  'camys',\n",
       "  'statutori',\n",
       "  'citat',\n",
       "  'ofr',\n",
       "  'fick',\n",
       "  'sober',\n",
       "  '4500',\n",
       "  'zane',\n",
       "  'sercic',\n",
       "  '342',\n",
       "  'vernal',\n",
       "  '1310',\n",
       "  'indentifi',\n",
       "  'fifteenth',\n",
       "  'gorka',\n",
       "  'cetdz',\n",
       "  'astham',\n",
       "  'dawn',\n",
       "  'weissenbach',\n",
       "  'sputnik',\n",
       "  'stle',\n",
       "  'burst',\n",
       "  'corixid',\n",
       "  'narthex',\n",
       "  'dissert',\n",
       "  'metrolog',\n",
       "  'sprang',\n",
       "  'thorium',\n",
       "  'rubato',\n",
       "  'summerhaven',\n",
       "  'naginata',\n",
       "  'ucla',\n",
       "  'studyhow',\n",
       "  'commer',\n",
       "  'asimov',\n",
       "  'aarohan',\n",
       "  'picturetel',\n",
       "  'nonservic',\n",
       "  'tacomaseattl',\n",
       "  'ada',\n",
       "  'dominantparti',\n",
       "  '1904',\n",
       "  'kierkegaard',\n",
       "  'gajapati',\n",
       "  'ilsung',\n",
       "  'loge',\n",
       "  'ncac',\n",
       "  'coreless',\n",
       "  'mia',\n",
       "  'gumb',\n",
       "  'dept',\n",
       "  'polymeras',\n",
       "  'grumet',\n",
       "  'langton',\n",
       "  'sri',\n",
       "  'lankan',\n",
       "  'darken',\n",
       "  'innkeep',\n",
       "  'fst',\n",
       "  'shouldnt',\n",
       "  'overpopul',\n",
       "  'aphid',\n",
       "  'rasa',\n",
       "  'hered',\n",
       "  'prose',\n",
       "  'preelect',\n",
       "  'causeway',\n",
       "  'finnish',\n",
       "  'stepinac',\n",
       "  'mapuch',\n",
       "  'honori',\n",
       "  'forgotten',\n",
       "  'distiguish',\n",
       "  'policeman',\n",
       "  'succul',\n",
       "  'karoo',\n",
       "  'gunlick',\n",
       "  'länder',\n",
       "  'mustard',\n",
       "  'bitter',\n",
       "  'resent',\n",
       "  'demoisell',\n",
       "  'arcadia',\n",
       "  'patti',\n",
       "  'polari',\n",
       "  'nihil',\n",
       "  'prius',\n",
       "  'fuerit',\n",
       "  'sensu',\n",
       "  'eod',\n",
       "  'rhenish',\n",
       "  'ale',\n",
       "  'frozen',\n",
       "  'eastleigh',\n",
       "  'dharamshala',\n",
       "  'drasric',\n",
       "  'quartz',\n",
       "  'ngo',\n",
       "  'outfield',\n",
       "  'thursday',\n",
       "  'switzer',\n",
       "  'reconcilli',\n",
       "  'pitchfork',\n",
       "  'yarmouk',\n",
       "  'compnai',\n",
       "  'mandela',\n",
       "  'interrog',\n",
       "  'tawfiq',\n",
       "  'alhakim',\n",
       "  'mcg',\n",
       "  'notorieti',\n",
       "  'noon',\n",
       "  'philosph',\n",
       "  'tikhonov',\n",
       "  '1893',\n",
       "  'bronchi',\n",
       "  'conjoint',\n",
       "  'trna',\n",
       "  'threethousand',\n",
       "  'nehemiah',\n",
       "  'underag',\n",
       "  'piss',\n",
       "  'banknot',\n",
       "  'qf4',\n",
       "  'fractur',\n",
       "  'oregon',\n",
       "  '55',\n",
       "  'frightus',\n",
       "  'complianc',\n",
       "  'dissect',\n",
       "  'cadev',\n",
       "  'dewey',\n",
       "  'tidepredict',\n",
       "  'qbuzz',\n",
       "  'gnb',\n",
       "  'elsewher',\n",
       "  'sudharma',\n",
       "  'grandchild',\n",
       "  'parthenogenesi',\n",
       "  'cograilway',\n",
       "  'turkomongol',\n",
       "  'tughlaq',\n",
       "  'venetianstyl',\n",
       "  '1675',\n",
       "  'sania',\n",
       "  'mirza',\n",
       "  'craze',\n",
       "  'messiah',\n",
       "  'murad',\n",
       "  '1448',\n",
       "  'myse',\n",
       "  'larme',\n",
       "  'lat',\n",
       "  'ner',\n",
       "  'thrid',\n",
       "  'confisc',\n",
       "  'protestor',\n",
       "  'workd',\n",
       "  'indepent',\n",
       "  'maya',\n",
       "  'kms',\n",
       "  'eacg',\n",
       "  'karnev',\n",
       "  'maradona',\n",
       "  'specialist',\n",
       "  '13tholdest',\n",
       "  'manumiss',\n",
       "  'clap',\n",
       "  'ucol',\n",
       "  'conductor',\n",
       "  'antiislam',\n",
       "  'dummett',\n",
       "  'restaurantqu',\n",
       "  'sellasia',\n",
       "  'blenheim',\n",
       "  'f1',\n",
       "  'topograph',\n",
       "  'pretext',\n",
       "  'qrowth',\n",
       "  'cardigan',\n",
       "  'eurpoean',\n",
       "  'reckless',\n",
       "  'shook',\n",
       "  '47',\n",
       "  'geneva',\n",
       "  'semist',\n",
       "  'foley',\n",
       "  'firebird',\n",
       "  'semisytet',\n",
       "  'tommi',\n",
       "  'shaw',\n",
       "  'styx',\n",
       "  'impuls',\n",
       "  '70',\n",
       "  'narrat',\n",
       "  'delta5desaturas',\n",
       "  'famiy',\n",
       "  '1609',\n",
       "  'maney',\n",
       "  'safest',\n",
       "  'chorus',\n",
       "  'folder',\n",
       "  'drydock',\n",
       "  'samkhya',\n",
       "  'delus',\n",
       "  'guerra',\n",
       "  'hokkein',\n",
       "  'perci',\n",
       "  'sceneri',\n",
       "  'imprint',\n",
       "  'goodman',\n",
       "  'flightless',\n",
       "  'sequenti',\n",
       "  'sheal',\n",
       "  'nick',\n",
       "  'timberlak',\n",
       "  '5g',\n",
       "  'nguyễn',\n",
       "  'văn',\n",
       "  'hải',\n",
       "  'supercarri',\n",
       "  'walton',\n",
       "  'walker',\n",
       "  'boycot',\n",
       "  'dyke',\n",
       "  'visa',\n",
       "  'preemptiv',\n",
       "  'zemecki',\n",
       "  'eurocup',\n",
       "  'meus',\n",
       "  'moltk',\n",
       "  'mpoulgari',\n",
       "  'lyria',\n",
       "  'vasodil',\n",
       "  'problemat',\n",
       "  'mrap',\n",
       "  'yoeman',\n",
       "  'unansw',\n",
       "  'magician',\n",
       "  'pend',\n",
       "  'tariqah',\n",
       "  'lenght',\n",
       "  'implor',\n",
       "  'digniti',\n",
       "  'kinkaid',\n",
       "  'fermi',\n",
       "  'soap',\n",
       "  'vigil',\n",
       "  'rereleas',\n",
       "  'maay',\n",
       "  'btsr',\n",
       "  'mexcian',\n",
       "  'trammel',\n",
       "  '332016',\n",
       "  'rassmann',\n",
       "  'sewer',\n",
       "  'nlcs',\n",
       "  'curtail',\n",
       "  'reconsid',\n",
       "  'spine',\n",
       "  'zocor',\n",
       "  'cholesterol',\n",
       "  'gibson',\n",
       "  'ampitheatr',\n",
       "  'http',\n",
       "  'bbb',\n",
       "  'wader',\n",
       "  'accru',\n",
       "  'tripoli',\n",
       "  'lsd',\n",
       "  '1499',\n",
       "  'facto',\n",
       "  'telewizja',\n",
       "  'polska',\n",
       "  'brethren',\n",
       "  'moulin',\n",
       "  'roug',\n",
       "  'silistra',\n",
       "  '120',\n",
       "  'kmh',\n",
       "  'peintur',\n",
       "  'gunlay',\n",
       "  'casino',\n",
       "  'victoy',\n",
       "  'potsdam',\n",
       "  'felix',\n",
       "  'icrisat',\n",
       "  'lowgrad',\n",
       "  'magna',\n",
       "  'carta',\n",
       "  'universitatum',\n",
       "  'pancak',\n",
       "  'ultraport',\n",
       "  'ultrabook',\n",
       "  'crick',\n",
       "  'pubgoer',\n",
       "  'fieldeffect',\n",
       "  'collier',\n",
       "  'knowabl',\n",
       "  'agd',\n",
       "  'kino',\n",
       "  'layla',\n",
       "  'majnun',\n",
       "  'bathsheba',\n",
       "  'syllabl',\n",
       "  'downplay',\n",
       "  'spes',\n",
       "  'confid',\n",
       "  'comrad',\n",
       "  'pose',\n",
       "  'balconi',\n",
       "  'evactu',\n",
       "  'concerto',\n",
       "  'plebiscitum',\n",
       "  'ovinium',\n",
       "  'satellaview',\n",
       "  'uta',\n",
       "  'multizon',\n",
       "  'qail',\n",
       "  'xxi',\n",
       "  'tollway',\n",
       "  'otay',\n",
       "  'mesa',\n",
       "  '54',\n",
       "  'undeclar',\n",
       "  'flemish',\n",
       "  'shipment',\n",
       "  'bombgrad',\n",
       "  'plutonium',\n",
       "  'ravin',\n",
       "  'sevr',\n",
       "  'roundup',\n",
       "  'huston',\n",
       "  'boweri',\n",
       "  'frustrat',\n",
       "  'sailsburi',\n",
       "  'hutcheson',\n",
       "  'ogonek',\n",
       "  'motorsport',\n",
       "  'terrestri',\n",
       "  'duet',\n",
       "  'liar',\n",
       "  'sumner',\n",
       "  '16151684',\n",
       "  'guin',\n",
       "  'provenci',\n",
       "  'codon',\n",
       "  'schlacht',\n",
       "  'montgomeri',\n",
       "  'hess',\n",
       "  'iwo',\n",
       "  'jima',\n",
       "  'antisemet',\n",
       "  'hrothgar',\n",
       "  'checkout',\n",
       "  'ilford',\n",
       "  '3200',\n",
       "  'msnbc',\n",
       "  'collegeag',\n",
       "  'seato',\n",
       "  'verdingkind',\n",
       "  '1700s',\n",
       "  '1542',\n",
       "  'jīdū',\n",
       "  'suncent',\n",
       "  'ag3cu',\n",
       "  'intermetal',\n",
       "  'bharatpur',\n",
       "  'tar',\n",
       "  'macadam',\n",
       "  'bovington',\n",
       "  'insuffici',\n",
       "  'goos',\n",
       "  'kapodistria',\n",
       "  'neoconfucian',\n",
       "  'animos',\n",
       "  'cliqu',\n",
       "  'kef',\n",
       "  'manmad',\n",
       "  'disat',\n",
       "  'neuter',\n",
       "  'tonn',\n",
       "  'capot',\n",
       "  'ventil',\n",
       "  'norbulingka',\n",
       "  'submerg',\n",
       "  'brimhal',\n",
       "  'arduous',\n",
       "  'skip',\n",
       "  'multiwir',\n",
       "  'welfar',\n",
       "  'antigovern',\n",
       "  'antichurch',\n",
       "  'bergen',\n",
       "  'marveltim',\n",
       "  'ppnb',\n",
       "  'reorgan',\n",
       "  'shoemart',\n",
       "  'rustan',\n",
       "  'bandai',\n",
       "  'reboot',\n",
       "  '200407',\n",
       "  'kfor',\n",
       "  'hemlock',\n",
       "  'walnut',\n",
       "  'medicaid',\n",
       "  'costeffici',\n",
       "  'convect',\n",
       "  'uncertainti',\n",
       "  'mou',\n",
       "  'defi',\n",
       "  'lite',\n",
       "  'nonhuman',\n",
       "  'geoligist',\n",
       "  'wrangellia',\n",
       "  '20067',\n",
       "  'leaa',\n",
       "  'alstom',\n",
       "  'samsara',\n",
       "  'delawar',\n",
       "  'insur',\n",
       "  'bey',\n",
       "  'hive',\n",
       "  'pipe',\n",
       "  'frick',\n",
       "  'lundenw',\n",
       "  'alllowercas',\n",
       "  'bargat',\n",
       "  'taliban',\n",
       "  'clive',\n",
       "  'rice',\n",
       "  'hoard',\n",
       "  'visigoth',\n",
       "  'paldiski',\n",
       "  'cabrini',\n",
       "  'rooftop',\n",
       "  'salamand',\n",
       "  'massalia',\n",
       "  'i2a1b1',\n",
       "  'striker',\n",
       "  'b2a',\n",
       "  '640580',\n",
       "  'woolwich',\n",
       "  'councilperson',\n",
       "  'di',\n",
       "  'diagheliv',\n",
       "  'ballet',\n",
       "  'russ',\n",
       "  'tussl',\n",
       "  'ṣalībī',\n",
       "  'ṣalīb',\n",
       "  '5050',\n",
       "  'cosan',\n",
       "  'synthesi',\n",
       "  'bicamer',\n",
       "  'stuff',\n",
       "  'waterloo',\n",
       "  '720',\n",
       "  'curaçao',\n",
       "  'sint',\n",
       "  'maarten',\n",
       "  'hps',\n",
       "  'kolmaš',\n",
       "  'mukden',\n",
       "  '1808',\n",
       "  'afonso',\n",
       "  'reminisc',\n",
       "  'schindler',\n",
       "  'vandal',\n",
       "  'encycl',\n",
       "  'mpeg25',\n",
       "  'tenui',\n",
       "  'lothair',\n",
       "  'fo',\n",
       "  'marx',\n",
       "  'wts',\n",
       "  'capet',\n",
       "  'realize',\n",
       "  'kroc',\n",
       "  'icbm',\n",
       "  'no46',\n",
       "  'meritori',\n",
       "  'asi',\n",
       "  'mere',\n",
       "  'reactionari',\n",
       "  'ezra',\n",
       "  'stile',\n",
       "  'cowrit',\n",
       "  '201112',\n",
       "  'audubon',\n",
       "  'gooner',\n",
       "  'olympus',\n",
       "  'petrochem',\n",
       "  'refineri',\n",
       "  'waymark',\n",
       "  'speciat',\n",
       "  'trainer',\n",
       "  'β',\n",
       "  'hind',\n",
       "  'maneuver',\n",
       "  'scott',\n",
       "  'butera',\n",
       "  'attrit',\n",
       "  'quaran',\n",
       "  'flac',\n",
       "  'arlin',\n",
       "  'succumb',\n",
       "  'axon',\n",
       "  'wrap',\n",
       "  'konigsberg',\n",
       "  'proteincod',\n",
       "  '1417',\n",
       "  'merk',\n",
       "  'philatel',\n",
       "  'submiss',\n",
       "  'imper',\n",
       "  'depos',\n",
       "  'vill',\n",
       "  'nouvell',\n",
       "  'delouvri',\n",
       "  'constuct',\n",
       "  'bori',\n",
       "  'arkadievich',\n",
       "  'monigoloid',\n",
       "  'holocen',\n",
       "  'skyfal',\n",
       "  'ethnint',\n",
       "  'declassifi',\n",
       "  'sarmat',\n",
       "  'archeolog',\n",
       "  'veil',\n",
       "  'norepinephrin',\n",
       "  'zaha',\n",
       "  'hadid',\n",
       "  'reproduc',\n",
       "  'moldavia',\n",
       "  'owe',\n",
       "  'cemetari',\n",
       "  'amateur',\n",
       "  'poulti',\n",
       "  'nobilita',\n",
       "  'deflat',\n",
       "  'hasid',\n",
       "  'workday',\n",
       "  'suspos',\n",
       "  'strang',\n",
       "  'facet',\n",
       "  'disapprov',\n",
       "  'śuddhodana',\n",
       "  'kleptocraci',\n",
       "  'tendon',\n",
       "  'luí',\n",
       "  'camõ',\n",
       "  'sac',\n",
       "  'cyril',\n",
       "  'martha',\n",
       "  'petropavlovsk',\n",
       "  'spinal',\n",
       "  'cullen',\n",
       "  'juror',\n",
       "  '450th',\n",
       "  'inde',\n",
       "  'diaz',\n",
       "  'alsacelorrain',\n",
       "  'morrison',\n",
       "  'phoenician',\n",
       "  'myrrh',\n",
       "  'neurosci',\n",
       "  'subfield',\n",
       "  'churchman',\n",
       "  'odd',\n",
       "  'sectet',\n",
       "  'outstand',\n",
       "  'lourd',\n",
       "  'inquirer',\n",
       "  'autodidact',\n",
       "  'seep',\n",
       "  'abstand',\n",
       "  'ausbau',\n",
       "  'garz',\n",
       "  'zoig',\n",
       "  'merci',\n",
       "  'sean',\n",
       "  'stunt',\n",
       "  'fungtion',\n",
       "  'slum',\n",
       "  'gm',\n",
       "  'pontiac',\n",
       "  'tafseer',\n",
       "  'kabir',\n",
       "  'nitric',\n",
       "  'alic',\n",
       "  'springss',\n",
       "  'elctron',\n",
       "  'rot',\n",
       "  'bjts',\n",
       "  'fond',\n",
       "  'msdos',\n",
       "  'landform',\n",
       "  'traci',\n",
       "  'tetracyclin',\n",
       "  'noma',\n",
       "  'judah',\n",
       "  'reopen',\n",
       "  'bursa',\n",
       "  '4000m',\n",
       "  'underworld',\n",
       "  'slag',\n",
       "  'selfworth',\n",
       "  'handel',\n",
       "  'accourd',\n",
       "  'normanist',\n",
       "  'voltair',\n",
       "  'calypso',\n",
       "  'icki',\n",
       "  'defraud',\n",
       "  'agasint',\n",
       "  'brook',\n",
       "  'akrita',\n",
       "  'chaeta',\n",
       "  'conven',\n",
       "  'bohm',\n",
       "  'genotyp',\n",
       "  'tintin',\n",
       "  'cohost',\n",
       "  'maci',\n",
       "  '2014s',\n",
       "  'eusoci',\n",
       "  'miamidad',\n",
       "  'recogniz',\n",
       "  'damp',\n",
       "  'catalonia',\n",
       "  'peshwa',\n",
       "  'stanhop',\n",
       "  'furi',\n",
       "  'illwil',\n",
       "  'sinotibetan',\n",
       "  'xenon',\n",
       "  'd4',\n",
       "  'effervesc',\n",
       "  'heterodox',\n",
       "  'receptacl',\n",
       "  'affix',\n",
       "  'glue',\n",
       "  'parker',\n",
       "  'austronesian',\n",
       "  'taikadai',\n",
       "  'nonbeliev',\n",
       "  'fuli',\n",
       "  'tubedwel',\n",
       "  'armando',\n",
       "  'dia',\n",
       "  '446',\n",
       "  'barotrauma',\n",
       "  'malawi',\n",
       "  'mississipian',\n",
       "  'canaan',\n",
       "  'kennel',\n",
       "  'disproportion',\n",
       "  'areonaut',\n",
       "  '1640s',\n",
       "  '327',\n",
       "  'precious',\n",
       "  'biezma',\n",
       "  'hartshorn',\n",
       "  'wilber',\n",
       "  'paperwork',\n",
       "  'vermont',\n",
       "  '199',\n",
       "  'lavinia',\n",
       "  'venus',\n",
       "  'original',\n",
       "  'largescal',\n",
       "  'swr',\n",
       "  'drift',\n",
       "  'oneil',\n",
       "  'carillion',\n",
       "  'nester',\n",
       "  'arigucultur',\n",
       "  'irenaeus',\n",
       "  'distress',\n",
       "  'windsor',\n",
       "  'credienti',\n",
       "  'amblin',\n",
       "  'raytheon',\n",
       "  'schnellweg',\n",
       "  'pickler',\n",
       "  'feuerleitung',\n",
       "  'singleent',\n",
       "  'christensen',\n",
       "  'saati',\n",
       "  'igor',\n",
       "  'mandic',\n",
       "  'pluricentr',\n",
       "  'everest',\n",
       "  'risktak',\n",
       "  'rippl',\n",
       "  '1492',\n",
       "  'temperley',\n",
       "  'ballad',\n",
       "  'scherzo',\n",
       "  'xp',\n",
       "  'unrol',\n",
       "  'premodern',\n",
       "  'gesner',\n",
       "  'contracte',\n",
       "  'liliuss',\n",
       "  'psychic',\n",
       "  'leucothea',\n",
       "  'payer',\n",
       "  'brasseri',\n",
       "  'cst',\n",
       "  'swansea',\n",
       "  'hermann',\n",
       "  'nanumea',\n",
       "  'excel',\n",
       "  'scientism',\n",
       "  'orozco',\n",
       "  '20s',\n",
       "  'rioter',\n",
       "  'knickebein',\n",
       "  'lorenz',\n",
       "  'beam',\n",
       "  'juggler',\n",
       "  'ammend',\n",
       "  'regimen',\n",
       "  'śuddhāvāsa',\n",
       "  'abod',\n",
       "  'sounth',\n",
       "  'mound',\n",
       "  'dail',\n",
       "  'sulfonamid',\n",
       "  'arsphenamin',\n",
       "  'dwindl',\n",
       "  '683',\n",
       "  'flügel',\n",
       "  'eisler',\n",
       "  'webli',\n",
       "  '198889',\n",
       "  'rhinewestphalia',\n",
       "  'backwood',\n",
       "  'afrocaribbean',\n",
       "  'recit',\n",
       "  'wohler',\n",
       "  'cdo',\n",
       "  'antikythera',\n",
       "  '19n',\n",
       "  '19s',\n",
       "  '154',\n",
       "  'lyon',\n",
       "  'counterpetit',\n",
       "  'haploid',\n",
       "  'attende',\n",
       "  'sindh',\n",
       "  'thunderbal',\n",
       "  'zhung',\n",
       "  'superintend',\n",
       "  'renssela',\n",
       "  'pieta',\n",
       "  'coeffici',\n",
       "  'veda',\n",
       "  'fluent',\n",
       "  'mandarin',\n",
       "  'barn',\n",
       "  '1841',\n",
       "  'entrust',\n",
       "  'plotinus',\n",
       "  'risch',\n",
       "  '999',\n",
       "  '20032004',\n",
       "  'simla',\n",
       "  'peertop',\n",
       "  'bernard',\n",
       "  'rollin',\n",
       "  'duroch',\n",
       "  'populist',\n",
       "  'addtion',\n",
       "  'britanica',\n",
       "  'ssbn',\n",
       "  'boomer',\n",
       "  'homeport',\n",
       "  'ethnohistori',\n",
       "  'shrink',\n",
       "  'lister',\n",
       "  'secretori',\n",
       "  'acdc',\n",
       "  'inquir',\n",
       "  'deregul',\n",
       "  'nuestra',\n",
       "  'senora',\n",
       "  'sagrado',\n",
       "  'corazon',\n",
       "  'tajik',\n",
       "  'mva85a',\n",
       "  'blow',\n",
       "  'kuomintang',\n",
       "  'bartolomeo',\n",
       "  'citadel',\n",
       "  'hoar',\n",
       "  'distract',\n",
       "  'paleontolog',\n",
       "  'unaspir',\n",
       "  'unless',\n",
       "  'scriptio',\n",
       "  'mrigavyadha',\n",
       "  'ethnocentr',\n",
       "  'basel',\n",
       "  'copytext',\n",
       "  'masjid',\n",
       "  'bilal',\n",
       "  'chosun',\n",
       "  'heknow',\n",
       "  'familiar',\n",
       "  'vestig',\n",
       "  'mauric',\n",
       "  'ravel',\n",
       "  'tientsin',\n",
       "  'germ',\n",
       "  'iclud',\n",
       "  'esperienza',\n",
       "  'empower',\n",
       "  'bele',\n",
       "  '7eleven',\n",
       "  'cameron',\n",
       "  'languagespecif',\n",
       "  'wiretap',\n",
       "  'bootlegg',\n",
       "  'semiperman',\n",
       "  'flora',\n",
       "  'mid2012',\n",
       "  'unclean',\n",
       "  'designintel',\n",
       "  'basso',\n",
       "  'continuo',\n",
       "  'michel',\n",
       "  'vii',\n",
       "  'dusti',\n",
       "  'offshoot',\n",
       "  'unseg',\n",
       "  'umbrella',\n",
       "  'sue',\n",
       "  'hewlettpackard',\n",
       "  'illustri',\n",
       "  'collectiv',\n",
       "  'disesas',\n",
       "  'enobl',\n",
       "  'percul',\n",
       "  'boulogn',\n",
       "  'vincenn',\n",
       "  'turnout',\n",
       "  'cheroke',\n",
       "  'tear',\n",
       "  'mule',\n",
       "  'rechristen',\n",
       "  '1807',\n",
       "  'sunris',\n",
       "  'kansass',\n",
       "  'offsit',\n",
       "  'estrang',\n",
       "  'didyma',\n",
       "  'rhone',\n",
       "  'ticino',\n",
       "  'po',\n",
       "  'bohemia',\n",
       "  'lhds',\n",
       "  'skijump',\n",
       "  'ramp',\n",
       "  'bsemumbai',\n",
       "  'sealer',\n",
       "  'hulbert',\n",
       "  'eyesight',\n",
       "  'hemp',\n",
       "  'gellmann',\n",
       "  'kannauj',\n",
       "  'stabilis',\n",
       "  'themat',\n",
       "  'heirarh',\n",
       "  'beomc',\n",
       "  'eglitarian',\n",
       "  'gardezi',\n",
       "  'inclin',\n",
       "  'conveyor',\n",
       "  'deduct',\n",
       "  'vilanova',\n",
       "  'mubariz',\n",
       "  'picasso',\n",
       "  'laymen',\n",
       "  'stratford',\n",
       "  'galveston',\n",
       "  'kuul',\n",
       "  'luthier',\n",
       "  'unabsorb',\n",
       "  'nonorthodox',\n",
       "  'electrif',\n",
       "  'fullduplex',\n",
       "  'superspe',\n",
       "  'hectar',\n",
       "  'ecdicius',\n",
       "  'bolivia',\n",
       "  'neurotransmitt',\n",
       "  'fourjudg',\n",
       "  'trib',\n",
       "  'hephthalit',\n",
       "  'spaniel',\n",
       "  'europen',\n",
       "  'parabol',\n",
       "  'polytechniqu',\n",
       "  'prune',\n",
       "  'firstclass',\n",
       "  'mardyk',\n",
       "  'palm',\n",
       "  'cann',\n",
       "  'toth',\n",
       "  'uno',\n",
       "  'ab',\n",
       "  'alto',\n",
       "  'lafortun',\n",
       "  'readabl',\n",
       "  'unintellig',\n",
       "  '106th',\n",
       "  'unaffect',\n",
       "  'honduran',\n",
       "  'francorussian',\n",
       "  'bobsleigh',\n",
       "  'welch',\n",
       "  'polabian',\n",
       "  'wend',\n",
       "  'élìsī',\n",
       "  'armycivilian',\n",
       "  'satelit',\n",
       "  'rdn',\n",
       "  'workshop',\n",
       "  'pulmonari',\n",
       "  'offkey',\n",
       "  'koppen',\n",
       "  'chattanooga',\n",
       "  'anchor',\n",
       "  'stupid',\n",
       "  'motorist',\n",
       "  'ѭ',\n",
       "  'corrient',\n",
       "  'krei',\n",
       "  'osamu',\n",
       "  'tezuka',\n",
       "  'polk',\n",
       "  'oz',\n",
       "  'siku',\n",
       "  'quanshu',\n",
       "  'costanza',\n",
       "  'fifti',\n",
       "  ...],\n",
       " ['1290',\n",
       "  'sulaf',\n",
       "  'fawakherji',\n",
       "  'amish',\n",
       "  'horribilis',\n",
       "  'shareholders',\n",
       "  'hgnc',\n",
       "  'turcophile',\n",
       "  'arrived',\n",
       "  'sardinian',\n",
       "  'priteca',\n",
       "  'dispossession',\n",
       "  'receives',\n",
       "  'loader',\n",
       "  'canonbury',\n",
       "  'arthropod',\n",
       "  'musician',\n",
       "  'talks',\n",
       "  'harding',\n",
       "  'earley',\n",
       "  'follmer',\n",
       "  'frailey',\n",
       "  'captaincies',\n",
       "  'altogether',\n",
       "  '07204',\n",
       "  'modes',\n",
       "  'mahdist',\n",
       "  'kmart',\n",
       "  'garreth',\n",
       "  'mallory',\n",
       "  'persistent',\n",
       "  'drought',\n",
       "  'suggested',\n",
       "  'hexagonal',\n",
       "  'economise',\n",
       "  'soan',\n",
       "  'weiss',\n",
       "  'moriscos',\n",
       "  'pterygota',\n",
       "  'narrow',\n",
       "  'phasmatodea',\n",
       "  'switches',\n",
       "  'swimming',\n",
       "  'contexts',\n",
       "  'recommendation',\n",
       "  'terraces',\n",
       "  'consumable',\n",
       "  'item',\n",
       "  '905',\n",
       "  'pioneers',\n",
       "  '670171',\n",
       "  'kiran',\n",
       "  'bedi',\n",
       "  'huxley',\n",
       "  'mstyslav',\n",
       "  'alphonse',\n",
       "  'massambadébat',\n",
       "  'passenger',\n",
       "  'allocated',\n",
       "  'depart',\n",
       "  'semiconsolidated',\n",
       "  'authoritarian',\n",
       "  '1498',\n",
       "  'tsarevich',\n",
       "  'alexei',\n",
       "  'asturias',\n",
       "  'infante',\n",
       "  'gonzalo',\n",
       "  'witty',\n",
       "  'politicalsocial',\n",
       "  'israeliamerican',\n",
       "  'saddled',\n",
       "  'barely',\n",
       "  'surrounds',\n",
       "  'nutritionrelated',\n",
       "  'analytic',\n",
       "  'symmetries',\n",
       "  'periphery',\n",
       "  'benzedrine',\n",
       "  'inhaler',\n",
       "  'neptune',\n",
       "  'roma',\n",
       "  'cafe',\n",
       "  'procope',\n",
       "  'psamtik',\n",
       "  '15402',\n",
       "  'hypothetical',\n",
       "  'machs',\n",
       "  'enforcing',\n",
       "  'thirds',\n",
       "  'switch',\n",
       "  'alauddin',\n",
       "  'schwarzenegger',\n",
       "  'amar',\n",
       "  'singh',\n",
       "  'amos',\n",
       "  'blackpool',\n",
       "  'allergic',\n",
       "  'rhinitis',\n",
       "  'sinusitis',\n",
       "  'genoscope',\n",
       "  'freemasonry',\n",
       "  'beagle',\n",
       "  'goštautai',\n",
       "  '1675',\n",
       "  'surname',\n",
       "  'signatures',\n",
       "  'suburbicarian',\n",
       "  'dioceses',\n",
       "  '1430',\n",
       "  '889',\n",
       "  'redevelopment',\n",
       "  'bra',\n",
       "  'climates',\n",
       "  'declined',\n",
       "  'omniscient',\n",
       "  'principia',\n",
       "  'mathematica',\n",
       "  'mid20th',\n",
       "  'showing',\n",
       "  'geometry',\n",
       "  'bhimsen',\n",
       "  '205344',\n",
       "  'listed',\n",
       "  'minimized',\n",
       "  'practice',\n",
       "  'disregarding',\n",
       "  'covering',\n",
       "  'prone',\n",
       "  'backfirst',\n",
       "  'doughboys',\n",
       "  'cuneiform',\n",
       "  'utilized',\n",
       "  'kandeh',\n",
       "  'yumkella',\n",
       "  'dependence',\n",
       "  'marquee',\n",
       "  'nu',\n",
       "  'mt',\n",
       "  'lemmon',\n",
       "  'polearm',\n",
       "  'ajima',\n",
       "  'rental',\n",
       "  'payments',\n",
       "  'tenants',\n",
       "  'landowners',\n",
       "  'montreal',\n",
       "  'erroneous',\n",
       "  'sonoran',\n",
       "  'pcs1',\n",
       "  'cyclists',\n",
       "  'swimmers',\n",
       "  'skiers',\n",
       "  'epilepsy',\n",
       "  'vital',\n",
       "  'balochistan',\n",
       "  'routinely',\n",
       "  'anthropologists',\n",
       "  'xxxiv',\n",
       "  '1191',\n",
       "  'sinuiju',\n",
       "  'mastership',\n",
       "  'aurangazeb',\n",
       "  'pirates',\n",
       "  'syncretist',\n",
       "  'amorós',\n",
       "  'ondeano',\n",
       "  'hooke',\n",
       "  'cardinalpriest',\n",
       "  'prisca',\n",
       "  'flac',\n",
       "  'mccarthyism',\n",
       "  'neoconfucian',\n",
       "  'transcript',\n",
       "  'duwamish',\n",
       "  'swann',\n",
       "  'revolutionaries',\n",
       "  'resulting',\n",
       "  'cooler',\n",
       "  'fothergill',\n",
       "  'ladybugs',\n",
       "  '205',\n",
       "  'pete',\n",
       "  'nan',\n",
       "  'trans',\n",
       "  '229762',\n",
       "  'berber',\n",
       "  'warships',\n",
       "  'ebury',\n",
       "  'granular',\n",
       "  'tornado',\n",
       "  'discounted',\n",
       "  'verse',\n",
       "  'jon',\n",
       "  'brion',\n",
       "  'multivendor',\n",
       "  'snowboarder',\n",
       "  'windsurfer',\n",
       "  'sailor',\n",
       "  'peso',\n",
       "  '422000',\n",
       "  'stereotypical',\n",
       "  'witch',\n",
       "  'presbyteries',\n",
       "  'seceded',\n",
       "  'pheromones',\n",
       "  '29526',\n",
       "  'housearrest',\n",
       "  '788000',\n",
       "  'dais',\n",
       "  'ogun',\n",
       "  'rd',\n",
       "  'kimoon',\n",
       "  'daialmutlaq',\n",
       "  'northumbria',\n",
       "  'kendals',\n",
       "  'kendal',\n",
       "  'milne',\n",
       "  'faulkner',\n",
       "  'rob',\n",
       "  'lowe',\n",
       "  'ērān',\n",
       "  'toward',\n",
       "  'rabta',\n",
       "  'macedonians',\n",
       "  'deductions',\n",
       "  'unhistorical',\n",
       "  'jazzrb',\n",
       "  'fusion',\n",
       "  'highestgrossing',\n",
       "  'tobacco',\n",
       "  'populous',\n",
       "  'stresses',\n",
       "  'senses',\n",
       "  'exemption',\n",
       "  '457',\n",
       "  'ordnance',\n",
       "  'disposal',\n",
       "  'fractional',\n",
       "  'houck',\n",
       "  'kangra',\n",
       "  'miniature',\n",
       "  'onset',\n",
       "  'pulitzer',\n",
       "  'predominantly',\n",
       "  'incorporate',\n",
       "  'cbc',\n",
       "  'schedules',\n",
       "  'alemannic',\n",
       "  'schwiizer',\n",
       "  'concordat',\n",
       "  'sprouting',\n",
       "  'orascom',\n",
       "  'raya',\n",
       "  'nondenominational',\n",
       "  'datadriven',\n",
       "  'strictempiricist',\n",
       "  'typhoid',\n",
       "  '79yearold',\n",
       "  '117600',\n",
       "  '45406',\n",
       "  '334',\n",
       "  'zeitgebers',\n",
       "  'eager',\n",
       "  'embrace',\n",
       "  'eze',\n",
       "  'nri',\n",
       "  'hardly',\n",
       "  'aspect',\n",
       "  'campaigning',\n",
       "  'occupied',\n",
       "  'pilton',\n",
       "  'shepton',\n",
       "  'mallet',\n",
       "  'assignments',\n",
       "  'donating',\n",
       "  'caseous',\n",
       "  'necrotic',\n",
       "  'biotechnology',\n",
       "  '30thlargest',\n",
       "  'digitalprint',\n",
       "  'ideal',\n",
       "  'manufactured',\n",
       "  'fea',\n",
       "  'mineralized',\n",
       "  'fastest',\n",
       "  'f16',\n",
       "  'qf16',\n",
       "  'eugenics',\n",
       "  'purity',\n",
       "  'comedydrama',\n",
       "  'please',\n",
       "  'yingxiubeichuan',\n",
       "  'fracture',\n",
       "  'singular',\n",
       "  'willamette',\n",
       "  '631',\n",
       "  'suddenly',\n",
       "  'agree',\n",
       "  'whatsoever',\n",
       "  'healthy',\n",
       "  'neoplatonism',\n",
       "  'usefulness',\n",
       "  'herophilos',\n",
       "  'juzheng',\n",
       "  'thomson',\n",
       "  'qbuzz',\n",
       "  'highfrequency',\n",
       "  'uithof',\n",
       "  '345',\n",
       "  'establish',\n",
       "  'bombardment',\n",
       "  'peers',\n",
       "  'contentious',\n",
       "  'freedmen',\n",
       "  'civillybinding',\n",
       "  'grover',\n",
       "  'timur',\n",
       "  'sisto',\n",
       "  'formalization',\n",
       "  'diletsky',\n",
       "  'refining',\n",
       "  'kerosene',\n",
       "  'minimize',\n",
       "  'tomb',\n",
       "  'heroin',\n",
       "  'confiscations',\n",
       "  'rogan',\n",
       "  '24hrsday',\n",
       "  'stepwise',\n",
       "  '1230',\n",
       "  'deecd',\n",
       "  '2258',\n",
       "  'breathyvoiced',\n",
       "  'durability',\n",
       "  'textbooks',\n",
       "  'rosemont',\n",
       "  'horizon',\n",
       "  'johan',\n",
       "  'svendsens',\n",
       "  'supercargo',\n",
       "  'uncultivated',\n",
       "  'moorland',\n",
       "  'separator',\n",
       "  'antirealists',\n",
       "  'gastropubs',\n",
       "  'sparta',\n",
       "  'cherbourg',\n",
       "  'oncology',\n",
       "  'struggled',\n",
       "  'moraine',\n",
       "  'restoring',\n",
       "  'equals',\n",
       "  'baselstadt',\n",
       "  'dielectric',\n",
       "  'countering',\n",
       "  'triassic',\n",
       "  'doctorate',\n",
       "  'clauses',\n",
       "  'firms',\n",
       "  'percapita',\n",
       "  '8170',\n",
       "  'blossoms',\n",
       "  'metlife',\n",
       "  'entertaining',\n",
       "  'bohm',\n",
       "  'dagoult',\n",
       "  'growl',\n",
       "  'flanders',\n",
       "  'tawhid',\n",
       "  'dorsolateral',\n",
       "  'prefrontal',\n",
       "  'recognize',\n",
       "  'ancestral',\n",
       "  'finbarr',\n",
       "  'graecia',\n",
       "  'fresco',\n",
       "  'glucagon',\n",
       "  'youtube',\n",
       "  'orchestras',\n",
       "  'cemetery',\n",
       "  'grunts',\n",
       "  'repair',\n",
       "  'boats',\n",
       "  'zionist',\n",
       "  'solving',\n",
       "  'experimentation',\n",
       "  'ophicleide',\n",
       "  'selfidentification',\n",
       "  'multiparty',\n",
       "  'cutbacks',\n",
       "  'anagami',\n",
       "  'bribe',\n",
       "  'relaxed',\n",
       "  'rupture',\n",
       "  'nunchuk',\n",
       "  'thein',\n",
       "  'sein',\n",
       "  'canto',\n",
       "  'airtraffic',\n",
       "  'controllers',\n",
       "  'telencephalon',\n",
       "  'basal',\n",
       "  'decisions',\n",
       "  'designated',\n",
       "  'joints',\n",
       "  'bonein',\n",
       "  'deboned',\n",
       "  'ready',\n",
       "  'atlas',\n",
       "  'île',\n",
       "  'e1',\n",
       "  'maid',\n",
       "  'lancashire',\n",
       "  'cherokee',\n",
       "  '13040',\n",
       "  'cremona',\n",
       "  'mediolanum',\n",
       "  'rekindle',\n",
       "  'thenfading',\n",
       "  'woolf',\n",
       "  'evasion',\n",
       "  'monitor',\n",
       "  'onomatopoeia',\n",
       "  'chamba',\n",
       "  'bilaspur',\n",
       "  'bhagal',\n",
       "  'dhami',\n",
       "  'prediction',\n",
       "  'hainanese',\n",
       "  'morale',\n",
       "  'carrefour',\n",
       "  'seismically',\n",
       "  'dyke',\n",
       "  'lucrative',\n",
       "  'lwt',\n",
       "  'featured',\n",
       "  'shovel',\n",
       "  'shutup',\n",
       "  'kalevcramo',\n",
       "  'everyday',\n",
       "  'forum',\n",
       "  'stadtpark',\n",
       "  'stelios',\n",
       "  'foustalierakis',\n",
       "  'prefixes',\n",
       "  'manteia',\n",
       "  'hydralazine',\n",
       "  'problematic',\n",
       "  'resistant',\n",
       "  'ambush',\n",
       "  'trinity',\n",
       "  'clodius',\n",
       "  'certifications',\n",
       "  'ρ',\n",
       "  'qa',\n",
       "  'bai',\n",
       "  'yansong',\n",
       "  'finds',\n",
       "  'antler',\n",
       "  'pins',\n",
       "  'seerdoctors',\n",
       "  'quota',\n",
       "  'nondirectional',\n",
       "  'credere',\n",
       "  '1602',\n",
       "  'dinmukhamed',\n",
       "  'konayev',\n",
       "  'hominids',\n",
       "  'icy',\n",
       "  'micrometres',\n",
       "  'urged',\n",
       "  'slaveholders',\n",
       "  'enyorar',\n",
       "  'augustan',\n",
       "  'gauguin',\n",
       "  'bday',\n",
       "  'capacitative',\n",
       "  'reactance',\n",
       "  'thirtyseven',\n",
       "  'oratory',\n",
       "  'thuringian',\n",
       "  'buffer',\n",
       "  'squirts',\n",
       "  '1660',\n",
       "  'alrazi',\n",
       "  'viii',\n",
       "  'tokyo',\n",
       "  'alison',\n",
       "  'hypertext',\n",
       "  'rohingya',\n",
       "  'bloodbrain',\n",
       "  'comanche',\n",
       "  '1045',\n",
       "  '3800',\n",
       "  'shorebirds',\n",
       "  'architectura',\n",
       "  'numerically',\n",
       "  'americano',\n",
       "  'outra',\n",
       "  'vez',\n",
       "  'tvp',\n",
       "  'polonia',\n",
       "  'ex',\n",
       "  'sola',\n",
       "  'scriptura',\n",
       "  '559',\n",
       "  'rugg',\n",
       "  'interception',\n",
       "  'colline',\n",
       "  'gaas',\n",
       "  'diode',\n",
       "  '40year',\n",
       "  'britishfrench',\n",
       "  'timedelay',\n",
       "  'suga',\n",
       "  'mama',\n",
       "  'hellenized',\n",
       "  'substitutions',\n",
       "  'rhenish',\n",
       "  'beaten',\n",
       "  'polygenism',\n",
       "  'dponchen',\n",
       "  '001',\n",
       "  '025',\n",
       "  'capstans',\n",
       "  'christopheros',\n",
       "  'savva',\n",
       "  'scholarteacher',\n",
       "  'constitutionality',\n",
       "  'expressly',\n",
       "  'manhwa',\n",
       "  'represented',\n",
       "  'massalia',\n",
       "  'xavier',\n",
       "  'bac',\n",
       "  'overhead',\n",
       "  'gregory',\n",
       "  'xvi',\n",
       "  'philippine',\n",
       "  'kavod',\n",
       "  'habriyot',\n",
       "  'heineken',\n",
       "  'lynn',\n",
       "  '3150',\n",
       "  'redgrave',\n",
       "  'vivaldi',\n",
       "  'ioannis',\n",
       "  'kigalas',\n",
       "  '312',\n",
       "  '24000yearold',\n",
       "  'telecommunication',\n",
       "  'xband',\n",
       "  'rei',\n",
       "  'technique',\n",
       "  'knight',\n",
       "  'seeds',\n",
       "  'sparky',\n",
       "  'ainsworth',\n",
       "  'mp',\n",
       "  'connotation',\n",
       "  'chicagos',\n",
       "  'assistant',\n",
       "  'bhushan',\n",
       "  'shri',\n",
       "  '28095',\n",
       "  '1585',\n",
       "  'nee',\n",
       "  'roncourt',\n",
       "  'bahu',\n",
       "  'bulleh',\n",
       "  'mian',\n",
       "  'baksh',\n",
       "  'waris',\n",
       "  'borrowing',\n",
       "  'thallium',\n",
       "  'flee',\n",
       "  'remainder',\n",
       "  'victorias',\n",
       "  'writ',\n",
       "  'longmenshan',\n",
       "  'referendums',\n",
       "  'palmisano',\n",
       "  'holder',\n",
       "  'publisher',\n",
       "  'whom',\n",
       "  'trophies',\n",
       "  'dot',\n",
       "  'alain',\n",
       "  'golfo',\n",
       "  'fix',\n",
       "  'millbay',\n",
       "  'shakira',\n",
       "  'cartesian',\n",
       "  '10year',\n",
       "  'rockford',\n",
       "  'troponin',\n",
       "  'somers',\n",
       "  'werent',\n",
       "  'fukushima',\n",
       "  'daiichi',\n",
       "  '632',\n",
       "  'suribachi',\n",
       "  'scyld',\n",
       "  'translational',\n",
       "  'sales',\n",
       "  'counters',\n",
       "  'rita',\n",
       "  'developer',\n",
       "  'multilingual',\n",
       "  'creole',\n",
       "  'norfuk',\n",
       "  'handed',\n",
       "  'romanticism',\n",
       "  'partially',\n",
       "  'withdrawn',\n",
       "  'cession',\n",
       "  'hibernia',\n",
       "  'rodríguez',\n",
       "  'cabrillo',\n",
       "  'pamphlet',\n",
       "  'kito',\n",
       "  'cantonese',\n",
       "  'aristarchus',\n",
       "  'samos',\n",
       "  'nationalism',\n",
       "  'amenities',\n",
       "  'characterise',\n",
       "  'kennel',\n",
       "  'nathaniel',\n",
       "  'batts',\n",
       "  'numismatic',\n",
       "  'cu5sn6',\n",
       "  'morales',\n",
       "  'princely',\n",
       "  'appointed',\n",
       "  'willibrordus',\n",
       "  'imminent',\n",
       "  'clarmac',\n",
       "  'amusing',\n",
       "  'cheerful',\n",
       "  'hardworking',\n",
       "  'conscientious',\n",
       "  'goose',\n",
       "  'acclimated',\n",
       "  'abs',\n",
       "  'sitka',\n",
       "  'nationalities',\n",
       "  'urinary',\n",
       "  'incontinence',\n",
       "  'shoulders',\n",
       "  'knee',\n",
       "  'neck',\n",
       "  'rib',\n",
       "  'kenney',\n",
       "  '112934',\n",
       "  'relieve',\n",
       "  'echelon',\n",
       "  'diffusive',\n",
       "  'ventilation',\n",
       "  'obesity',\n",
       "  'concorde',\n",
       "  'glorious',\n",
       "  'bacteriostatic',\n",
       "  'routing',\n",
       "  'aggregate4',\n",
       "  '蝴',\n",
       "  'húdié',\n",
       "  '瑚',\n",
       "  'shānhú',\n",
       "  '51739',\n",
       "  'ipec',\n",
       "  'strip',\n",
       "  'pubs',\n",
       "  'longstanding',\n",
       "  'policymilitary',\n",
       "  'infringe',\n",
       "  '8491079',\n",
       "  'metrogoldwynmayer',\n",
       "  'khrushchev',\n",
       "  'subtle',\n",
       "  'gradient',\n",
       "  'galilean',\n",
       "  'humility',\n",
       "  '1665',\n",
       "  'uncompressed',\n",
       "  'us210',\n",
       "  'androgen',\n",
       "  'hormones',\n",
       "  'modernising',\n",
       "  'deserts',\n",
       "  'stateregistered',\n",
       "  'relegation',\n",
       "  'ship',\n",
       "  'burned',\n",
       "  'diplomats',\n",
       "  'mpeg1',\n",
       "  'helms',\n",
       "  'heian',\n",
       "  '445',\n",
       "  'salafis',\n",
       "  'zahiris',\n",
       "  'interrupt',\n",
       "  '320',\n",
       "  'threeyear',\n",
       "  '302nd',\n",
       "  'natoled',\n",
       "  'items',\n",
       "  'kazimierz',\n",
       "  'nigeria',\n",
       "  'alta',\n",
       "  'ram',\n",
       "  'lisa',\n",
       "  'piedigrotta',\n",
       "  'loosening',\n",
       "  'rue',\n",
       "  'chausséedantin',\n",
       "  'douglas',\n",
       "  'mistakes',\n",
       "  'magistrates',\n",
       "  'dispersed',\n",
       "  'undergoing',\n",
       "  'dasmann',\n",
       "  '207800',\n",
       "  'newcastleupontyne',\n",
       "  'sunderland',\n",
       "  'continual',\n",
       "  '1370',\n",
       "  '1614',\n",
       "  '1528',\n",
       "  'soka',\n",
       "  'gakkai',\n",
       "  'stanford',\n",
       "  'illustrated',\n",
       "  'beehive',\n",
       "  'circumpolar',\n",
       "  'macrocosm',\n",
       "  'microcosm',\n",
       "  'favourable',\n",
       "  'unconstitutional',\n",
       "  'pleads',\n",
       "  'cuauhtémoc',\n",
       "  'venustiano',\n",
       "  'carranza',\n",
       "  'benito',\n",
       "  'avatar',\n",
       "  'pervez',\n",
       "  'musharraf',\n",
       "  'lush',\n",
       "  'paradise',\n",
       "  'beside',\n",
       "  'guarantee',\n",
       "  'solvency',\n",
       "  'thiamine',\n",
       "  'guarrazar',\n",
       "  'virginias',\n",
       "  'bleachers',\n",
       "  'abstractions',\n",
       "  'timing',\n",
       "  '1269765',\n",
       "  'laying',\n",
       "  'kuwait',\n",
       "  'strabo',\n",
       "  'bosniaherzegovina',\n",
       "  'twodimensional',\n",
       "  'icons',\n",
       "  '1254',\n",
       "  '1263',\n",
       "  '3570',\n",
       "  'théâtre',\n",
       "  'champsélysées',\n",
       "  'scudamore',\n",
       "  'constables',\n",
       "  'raízen',\n",
       "  'hydrocarbons',\n",
       "  'manly',\n",
       "  'induced',\n",
       "  'uzbek',\n",
       "  'aruba',\n",
       "  'interdisciplinary',\n",
       "  'platypus',\n",
       "  '326',\n",
       "  'corvée',\n",
       "  'kane',\n",
       "  'multimodal',\n",
       "  'mmts',\n",
       "  'retainers',\n",
       "  'shoah',\n",
       "  'testimony',\n",
       "  'survivors',\n",
       "  'generals',\n",
       "  'iberia',\n",
       "  'infantile',\n",
       "  'paralysis',\n",
       "  'shelflife',\n",
       "  'proprietary',\n",
       "  'verdigris',\n",
       "  'leann',\n",
       "  'rimes',\n",
       "  'button',\n",
       "  'pinyin',\n",
       "  'rhone',\n",
       "  'butter',\n",
       "  '9468',\n",
       "  'priorities',\n",
       "  'ingvaeonic',\n",
       "  'dome',\n",
       "  'jorge',\n",
       "  'burgues',\n",
       "  'carnivores',\n",
       "  'omnivores',\n",
       "  'songcraft',\n",
       "  'sophistication',\n",
       "  'allowable',\n",
       "  'fractions',\n",
       "  'treatments',\n",
       "  '987',\n",
       "  'womans',\n",
       "  'frilly',\n",
       "  'obstacles',\n",
       "  'sizable',\n",
       "  'asserted',\n",
       "  'greediness',\n",
       "  'identifier',\n",
       "  'sake',\n",
       "  'joachim',\n",
       "  'usul',\n",
       "  'know',\n",
       "  '256',\n",
       "  '240',\n",
       "  'merging',\n",
       "  'experts',\n",
       "  '1778',\n",
       "  'himalayas',\n",
       "  'borneiro',\n",
       "  'audubon',\n",
       "  'naguib',\n",
       "  'gunners',\n",
       "  '6404',\n",
       "  'bilingual',\n",
       "  'linguists',\n",
       "  'orthologous',\n",
       "  'academys',\n",
       "  'edsel',\n",
       "  'freeway',\n",
       "  '1439',\n",
       "  'fan',\n",
       "  'transfusions',\n",
       "  'foxwoods',\n",
       "  'misinformation',\n",
       "  '492',\n",
       "  'hadith',\n",
       "  'eaten',\n",
       "  'globally',\n",
       "  'myelin',\n",
       "  'kaliningrad',\n",
       "  'djs',\n",
       "  'blessed',\n",
       "  'occupations',\n",
       "  'us1',\n",
       "  'rivalry',\n",
       "  'touring',\n",
       "  'promotions',\n",
       "  'presiding',\n",
       "  'polymerase',\n",
       "  'terrazas',\n",
       "  'progressivescan',\n",
       "  'humors',\n",
       "  'inconspicuous',\n",
       "  'riser',\n",
       "  'ream',\n",
       "  '13526',\n",
       "  'integrate',\n",
       "  'harriet',\n",
       "  'smithson',\n",
       "  'locus',\n",
       "  'coeruleus',\n",
       "  'hoenheimnord',\n",
       "  'churchs',\n",
       "  'tithing',\n",
       "  '2300',\n",
       "  'sapir',\n",
       "  'reproduce',\n",
       "  '12713',\n",
       "  'lignin',\n",
       "  'aviation',\n",
       "  'bahriye',\n",
       "  'tayyare',\n",
       "  'mektebi',\n",
       "  'denmark',\n",
       "  'unstressed',\n",
       "  'palatalized',\n",
       "  'preceding',\n",
       "  'syllable',\n",
       "  'innocents',\n",
       "  'terror',\n",
       "  'sergel',\n",
       "  'hollywoodgenerated',\n",
       "  'sponsored',\n",
       "  'colloquially',\n",
       "  'premiership',\n",
       "  'torsten',\n",
       "  'thriving',\n",
       "  'commentaries',\n",
       "  'sober',\n",
       "  'narrative',\n",
       "  'partitions',\n",
       "  'nonmetropolitan',\n",
       "  '246639',\n",
       "  'cittamatra',\n",
       "  'thieves',\n",
       "  'quinolone',\n",
       "  'systemic',\n",
       "  'corticosteroid',\n",
       "  'fiftieth',\n",
       "  'virgils',\n",
       "  'footlight',\n",
       "  'nick',\n",
       "  'clegg',\n",
       "  'miliband',\n",
       "  'liberian',\n",
       "  'quilters',\n",
       "  'finalised',\n",
       "  'kamchatka',\n",
       "  'phage',\n",
       "  '4800',\n",
       "  'adelta',\n",
       "  'succeeded',\n",
       "  'regrow',\n",
       "  'opportunistic',\n",
       "  'chemist',\n",
       "  '3785',\n",
       "  'spent',\n",
       "  '373',\n",
       "  'fredrik',\n",
       "  'schiotz',\n",
       "  'reelection',\n",
       "  'tribunate',\n",
       "  'primordial',\n",
       "  'canonsregular',\n",
       "  '1738',\n",
       "  'mycenaeans',\n",
       "  'nuffield',\n",
       "  'cnet',\n",
       "  'æthelwold',\n",
       "  'domestically',\n",
       "  'sabercats',\n",
       "  'hamburger',\n",
       "  'leighton',\n",
       "  'sands',\n",
       "  'embassy',\n",
       "  'discourages',\n",
       "  'amiibo',\n",
       "  'zara',\n",
       "  'polygenes',\n",
       "  'bernadette',\n",
       "  'soubirous',\n",
       "  'socialcognitive',\n",
       "  '1747',\n",
       "  'enquire',\n",
       "  'ms',\n",
       "  'pacman',\n",
       "  'raid',\n",
       "  'concealment',\n",
       "  'heinz',\n",
       "  'kloss',\n",
       "  'subarctic',\n",
       "  'birthday',\n",
       "  'transmitting',\n",
       "  'prec',\n",
       "  'credible',\n",
       "  'realistic',\n",
       "  'airs',\n",
       "  '47400',\n",
       "  'pontiacs',\n",
       "  'nimitz',\n",
       "  'nexus',\n",
       "  'hydrochloric',\n",
       "  '2794',\n",
       "  'ashkenazim',\n",
       "  'phylogenetic',\n",
       "  'kaldor',\n",
       "  'derriford',\n",
       "  'tetrahedral',\n",
       "  'aref',\n",
       "  'lederle',\n",
       "  '8mile',\n",
       "  'semester',\n",
       "  'strengthens',\n",
       "  'enlarges',\n",
       "  'disuse',\n",
       "  'diminishes',\n",
       "  'corey',\n",
       "  'blodig',\n",
       "  'identities',\n",
       "  'osiris',\n",
       "  'ulisse',\n",
       "  'aldrovandi',\n",
       "  'floats',\n",
       "  'oratorios',\n",
       "  ...])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_outliers(Q_vocab, outlier_threshold+1), get_outliers(A_vocab, outlier_threshold+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cdbecc0-91aa-48c8-b5f6-2d23e678fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_outliers, a_outliers = get_outliers(Q_vocab,outlier_threshold+1), get_outliers(A_vocab,outlier_threshold+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f358c326-8d7f-42d6-8d88-86b584df0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = remove_least_common(train_df, cols_tokens, [q_outliers, a_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d87f3e0e-e0fd-473c-acfc-a16f268d849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final = remove_least_common(test_df, cols_tokens, [q_outliers, a_outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb07602b-aea8-45c8-ba71-6552c7d9372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.06\n",
      "\t         median: 6.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 19)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 1.89\n",
      "\t         median: 1.00\n",
      "\t         minimum: 0\n",
      "\t         maximum: 20)\n"
     ]
    }
   ],
   "source": [
    "# tokenized & least common removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1266c61-293c-4538-91ca-a6f96db0f005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6be62ca4-d53b-4160-90a1-7c1ad7850c32",
   "metadata": {},
   "source": [
    "# remove questions that have less than three words and answers that have less than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0766ef0-c9ca-480e-b340-e2d6d9e9bf07",
   "metadata": {},
   "source": [
    "\n",
    "## Remove long outliers: long sentences that occure rarely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "463b6dc1-5958-4159-861b-c27fe6c5002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = filter_sentences(train_df_final, cols_tokens, [2,0], condition='longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dfc2c42-dc82-40fd-8bc2-1dbf3cb34c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question_tokens 3\n",
      "Answer_tokens 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_final_thresholds = histograms(train_df_final, cols_tokens, name = 'tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2df7a9-ba59-4d3d-b0a7-e2598cbe57f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14404, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb9bda52-35a3-42d1-a9d9-68a2cd367542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.18\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 19)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 2.23\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 20)\n"
     ]
    }
   ],
   "source": [
    "# shortest sentences removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77da65c8-2c35-4d75-b44f-da13d1c49d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the 95% of the data\n",
    "\n",
    "cutoff = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a354225-c26f-41ae-8df7-8525335070ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question_tokens': 10, 'Answer_tokens': 6}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keeping only the 95% of the data\n",
    "\n",
    "get_thresholds(train_df_final_thresholds, cutoff = cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cff27613-b810-4187-836c-054eac3a8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MAX, A_MAX = get_thresholds(train_df_final_thresholds, cutoff = cutoff).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cdd6285-1796-4471-8732-7722d8911b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = filter_sentences(train_df_final, cols_tokens, [Q_MAX+1,A_MAX+1], condition='shorter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdf774d2-8616-4098-adfa-1fa04b9691f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in column Question_tokens:\n",
      "\t         mean: 6.01\n",
      "\t         median: 6.00\n",
      "\t         minimum: 3\n",
      "\t         maximum: 10)\n",
      "Sentences in column Answer_tokens:\n",
      "\t         mean: 1.97\n",
      "\t         median: 2.00\n",
      "\t         minimum: 1\n",
      "\t         maximum: 6)\n"
     ]
    }
   ],
   "source": [
    "# long outliers removed\n",
    "sentences_stats(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae3d59ac-5592-44be-9ed2-797fad4525f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13406, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1eb96-b9d0-4df7-9f30-85a81053a689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a78154df-71c0-45f8-a6a6-d25b73b48f89",
   "metadata": {},
   "source": [
    "# Must make pairs from the dataset with removed short and long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2768b432-a865-4f63-9037-12df43107b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs_final = get_pairs_from_df(train_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf4c95c1-cf4e-4bb4-8333-f6ba7df58500",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs_final = get_pairs_from_df(test_df_final, cols_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b159a71-086a-4456-97d8-caaab0e24bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13406, 2114)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs_final), len(test_pairs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0d3bf-2369-4803-b8f0-b934713371b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e26f36-5d24-48b1-a705-062eead87753",
   "metadata": {},
   "source": [
    "# building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37fcac69-a3bb-4cee-9b31-bbe55ac2fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from modules.models import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb312e78-4032-442f-b29c-aa7799ca2248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fbbe773-3e36-4c69-bb91-ca7115185a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    # We initialize the Encoder object with appropriate layers\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, embedding_size):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        #self.hidden = torch.zeros(1, 1, hidden_size)\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size).to(device)\n",
    "        \n",
    "        # The LSTM is our last cell because it produces the hidden state        \n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, 1).to(device)\n",
    "    \n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x.view(1, 1, -1)\n",
    "        \n",
    "        #x = x.view(x.shape[0], 1, -1)\n",
    "        \n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        return x, hidden, cell_state\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # The Decoder is initialized in the same manner.\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, embedding_size):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size)\n",
    "        \n",
    "        # The LSTM produces an output by passing the hidden state to the   Linear layer\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim= 1)     \n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        x = self.softmax(self.fc(x[0]))\n",
    "        return x, hidden, cell_state\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    #def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, output_size, device):    \n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = Encoder(self.input_size, self.hidden_size, self.embedding_size).to(device)\n",
    "        self.decoder = Decoder(self.hidden_size, self.output_size, self.embedding_size).to(device)\n",
    "        #self.device = device\n",
    "        \n",
    "    def forward(self, src_batch: torch.LongTensor, trg_batch: torch.LongTensor, src_len, trg_len, teacher_forcing_ratio: float = 0.5):\n",
    "        \n",
    "        max_len, batch_size = trg_batch.shape\n",
    "                \n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(device) #.to(self.device) \n",
    "\n",
    "         # initialize hidden and cell state\n",
    "        encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) \n",
    "        cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)\n",
    "\n",
    "        for i in range(src_len):\n",
    "        \n",
    "            # last hidden & cell state of the encoder is used as the decoder's initial hidden state\n",
    "            _, hidden, cell = self.encoder(src_batch[i], encoder_hidden, cell_state)\n",
    "        \n",
    "        \n",
    "        \n",
    "        trg = trg_batch[0]\n",
    "        \n",
    "        for i in range(trg_len):\n",
    "            prediction, hidden, cell = self.decoder(trg, hidden, cell)\n",
    "            outputs[i] = prediction\n",
    "            \n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a46eb906-1886-408c-88a0-f66c9988209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f6d4c7e-b2e7-45e7-ba66-f368e12902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfe54f3b-50a1-4fae-b066-f52a24f85162",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(input_size=Q_vocab.n_words, hidden_size=hidden_size, embedding_size=embedding_dim, output_size=A_vocab.n_words, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "757c0f0e-2adb-431b-8a5c-cf70b542a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = seq2seq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81d1a1-f8ce-4f0b-ba58-f2c3883cb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0f43de7-dd0d-443a-ac36-ef448bb8e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f41769e-db7a-416e-8abc-b0b2a8b48c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80c58fde-eed3-4f41-859b-36f030663754",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(seq2seq.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(ignore_index=0).to(device) # 0 is padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80f6b078-f54a-4052-8f56-571c0899c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, pairs, optimizer, criterion, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for pair in pairs:\n",
    "        \n",
    "        src = pair.question\n",
    "        tgt = pair.answer\n",
    "        \n",
    "        src_tensor = to_tensor(vocab=Q_vocab, tokens=src, seq_len=Q_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "        tgt_tensor = to_tensor(vocab=A_vocab, tokens=tgt, seq_len=A_MAX, device=device)#.to(device) #.unsqueeze(0)\n",
    "\n",
    "        # print(src_tensor.shape, tgt_tensor.shape)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src_tensor, tgt_tensor, src_len=src_tensor.size(0), trg_len=tgt_tensor.size(0), teacher_forcing_ratio=1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_tensor.view(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        count += 1 \n",
    "    \n",
    "        if count % 100 == 0:\n",
    "            print(f'Loss {total_loss/count}')\n",
    "    \n",
    "    return total_loss / len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d043d-a15e-4581-a2d2-c8e851afe187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6832d14c-b060-4ad4-9c91-951a4191b89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2.4556229662895204\n",
      "Loss 2.372065095901489\n",
      "Loss 2.3487071319421133\n",
      "Loss 2.341527414917946\n",
      "Loss 2.338104717731476\n",
      "Loss 2.325567845106125\n",
      "Loss 2.3302439858232225\n",
      "Loss 2.333771576881409\n",
      "Loss 2.3320058721966213\n",
      "Loss 2.327230310320854\n",
      "Loss 2.3225575243343006\n",
      "Loss 2.309572754104932\n",
      "Loss 2.3136848945801076\n",
      "Loss 2.312997648545674\n",
      "Loss 2.30739342101415\n",
      "Loss 2.309167308136821\n",
      "Loss 2.3038703053839065\n",
      "Loss 2.2988817443450293\n",
      "Loss 2.2955052254701918\n",
      "Loss 2.2952830313444137\n",
      "Loss 2.291209115244093\n",
      "Loss 2.2864713983102276\n",
      "Loss 2.281787110774413\n",
      "Loss 2.278064403682947\n",
      "Loss 2.2803227892875673\n",
      "Loss 2.2802535268893607\n",
      "Loss 2.277080228814372\n",
      "Loss 2.2759000903793742\n",
      "Loss 2.272262659853902\n",
      "Loss 2.271752368927002\n",
      "Loss 2.269881042357414\n",
      "Loss 2.2654613884165884\n",
      "Loss 2.265124282909162\n",
      "Loss 2.2632252253153746\n",
      "Loss 2.261338069677353\n",
      "Loss 2.259025158252981\n",
      "Loss 2.25576801093849\n",
      "Loss 2.2542232179328017\n",
      "Loss 2.2529930603809847\n",
      "Loss 2.250760378301144\n",
      "Loss 2.249170450844416\n",
      "Loss 2.2479101900259653\n",
      "Loss 2.2470978114494056\n",
      "Loss 2.246053506515243\n",
      "Loss 2.2457358184655507\n",
      "Loss 2.2428312934222427\n",
      "Loss 2.2408188612664\n",
      "Loss 2.239862678870559\n",
      "Loss 2.2387860273585027\n",
      "Loss 2.2385237884044646\n",
      "Loss 2.238285531389947\n",
      "Loss 2.2388796134178457\n",
      "Loss 2.23774975356066\n",
      "Loss 2.235172416501575\n",
      "Loss 2.233143750234084\n",
      "Loss 2.2318871693525995\n",
      "Loss 2.2302584802058707\n",
      "Loss 2.22766989054351\n",
      "Loss 2.2247706725233694\n",
      "Loss 2.2240616587400437\n",
      "Loss 2.22247959473094\n",
      "Loss 2.219162143238129\n",
      "Loss 2.218882897070476\n",
      "Loss 2.2179550952091813\n",
      "Loss 2.216861191070997\n",
      "Loss 2.215427938356544\n",
      "Loss 2.214812325950879\n",
      "Loss 2.212910294357468\n",
      "Loss 2.2130321993862374\n",
      "Loss 2.2118224620648794\n",
      "Loss 2.209809770147565\n",
      "Loss 2.2107596570915646\n",
      "Loss 2.210848195046595\n",
      "Loss 2.2101750015890276\n",
      "Loss 2.2095272439956664\n",
      "Loss 2.2070766448033483\n",
      "Loss 2.206306959622866\n",
      "Loss 2.2050819914310407\n",
      "Loss 2.203740827071516\n",
      "Loss 2.2024444057792425\n",
      "Loss 2.2010614216327666\n",
      "Loss 2.2001252654122143\n",
      "Loss 2.1996063655686666\n",
      "Loss 2.198530370309239\n",
      "Loss 2.19781131438648\n",
      "Loss 2.1970910070940506\n",
      "Loss 2.1959159835864757\n",
      "Loss 2.1964666886627673\n",
      "Loss 2.195528328124057\n",
      "Loss 2.19540591457155\n",
      "Loss 2.1947217934079224\n",
      "Loss 2.1941126682836076\n",
      "Loss 2.193154559955802\n",
      "Loss 2.1923830148133825\n",
      "Loss 2.1911920709860953\n",
      "Loss 2.1909042763710023\n",
      "Loss 2.1919491701273572\n",
      "Loss 2.1912897348525573\n",
      "Loss 2.1913412863798816\n",
      "Loss 2.1914264329195023\n",
      "Loss 2.1914171816570924\n",
      "Loss 2.1906056514791414\n",
      "Loss 2.190426933753838\n",
      "Loss 2.1902056807164962\n",
      "Loss 2.189686197530656\n",
      "Loss 2.1892868615321395\n",
      "Loss 2.1892514009119193\n",
      "Loss 2.188774473865827\n",
      "Loss 2.1880705143989774\n",
      "Loss 2.187714853633534\n",
      "Loss 2.188431606958578\n",
      "Loss 2.1884881272060532\n",
      "Loss 2.1885639042769913\n",
      "Loss 2.1880969078603543\n",
      "Loss 2.1870488008623536\n",
      "Loss 2.186170616257807\n",
      "Loss 2.186147859733329\n",
      "Loss 2.186051199380624\n",
      "Loss 2.1855571850958992\n",
      "Loss 2.18499987526238\n",
      "Loss 2.184528978959588\n",
      "Loss 2.183909689886648\n",
      "Loss 2.1833428308585794\n",
      "Loss 2.182916418366855\n",
      "Loss 2.182713801035881\n",
      "Loss 2.182402424533216\n",
      "Loss 2.1825531765842063\n",
      "Loss 2.1821841696137563\n",
      "Loss 2.1817342893236367\n",
      "Loss 2.181445316860309\n",
      "Loss 2.1812549674738455\n",
      "Loss 2.180665184209744\n",
      "Loss 2.17995109738712\n",
      "Loss 2.178774716582761\n",
      "Epoch 1/25, Loss: 2.1788\n",
      "Loss 2.3568593060970304\n",
      "Loss 2.2718342328071595\n",
      "Loss 2.249388861656189\n",
      "Loss 2.2381721997261046\n",
      "Loss 2.2395055084228517\n",
      "Loss 2.2319457264741263\n",
      "Loss 2.2399096516200476\n",
      "Loss 2.2422930705547333\n",
      "Loss 2.2421833278073207\n",
      "Loss 2.240891514539719\n",
      "Loss 2.2377682676098565\n",
      "Loss 2.2258962658047676\n",
      "Loss 2.228735199158008\n",
      "Loss 2.2275138971635275\n",
      "Loss 2.2211456607182822\n",
      "Loss 2.22140951693058\n",
      "Loss 2.2163656954204334\n",
      "Loss 2.2121021597915225\n",
      "Loss 2.2093758796390732\n",
      "Loss 2.2091612320542335\n",
      "Loss 2.205296598218736\n",
      "Loss 2.2008213423057037\n",
      "Loss 2.1966083476336107\n",
      "Loss 2.1935678725441297\n",
      "Loss 2.197080952167511\n",
      "Loss 2.1976949425844046\n",
      "Loss 2.194586964669051\n",
      "Loss 2.193376017042569\n",
      "Loss 2.1899407849229617\n",
      "Loss 2.1898824811379116\n",
      "Loss 2.1882408759670873\n",
      "Loss 2.1838971084728835\n",
      "Loss 2.1833495582956255\n",
      "Loss 2.1812464976661348\n",
      "Loss 2.1790610815456937\n",
      "Loss 2.1765301019615597\n",
      "Loss 2.173699495309108\n",
      "Loss 2.1720359354897547\n",
      "Loss 2.171116839433328\n",
      "Loss 2.169385434538126\n",
      "Loss 2.1680537172352397\n",
      "Loss 2.166953032187053\n",
      "Loss 2.1662489942062733\n",
      "Loss 2.165362732383338\n",
      "Loss 2.165495837185118\n",
      "Loss 2.1630768681609114\n",
      "Loss 2.161215020519622\n",
      "Loss 2.160630288322767\n",
      "Loss 2.159330442778918\n",
      "Loss 2.158707337474823\n",
      "Loss 2.158538290753084\n",
      "Loss 2.159240525341951\n",
      "Loss 2.1583448962895377\n",
      "Loss 2.1563852786797066\n",
      "Loss 2.1547271618192845\n",
      "Loss 2.1538129919128757\n",
      "Loss 2.152226813780634\n",
      "Loss 2.149878106343335\n",
      "Loss 2.147141078942913\n",
      "Loss 2.146450442204873\n",
      "Loss 2.144904101236922\n",
      "Loss 2.141856094358429\n",
      "Loss 2.141474353349398\n",
      "Loss 2.140660734819248\n",
      "Loss 2.139811923476366\n",
      "Loss 2.138636975243236\n",
      "Loss 2.137912214487346\n",
      "Loss 2.1364923119807946\n",
      "Loss 2.136694358008495\n",
      "Loss 2.1362823715124812\n",
      "Loss 2.13452791308853\n",
      "Loss 2.1350998673422468\n",
      "Loss 2.1352747885739967\n",
      "Loss 2.1347151989469655\n",
      "Loss 2.1343592643658322\n",
      "Loss 2.132339688735573\n",
      "Loss 2.1317431568093115\n",
      "Loss 2.13071695545545\n",
      "Loss 2.129477193649811\n",
      "Loss 2.128571200825274\n",
      "Loss 2.1271447451541454\n",
      "Loss 2.1265039365974867\n",
      "Loss 2.1261824717650932\n",
      "Loss 2.1251369088675296\n",
      "Loss 2.1244779427822897\n",
      "Loss 2.1239342129438423\n",
      "Loss 2.1230106172547942\n",
      "Loss 2.1235382131758063\n",
      "Loss 2.1227671005015964\n",
      "Loss 2.1228096631566684\n",
      "Loss 2.1222396394381158\n",
      "Loss 2.1217764432080415\n",
      "Loss 2.1208211820292218\n",
      "Loss 2.1200085383970686\n",
      "Loss 2.1190449313552757\n",
      "Loss 2.118818344566971\n",
      "Loss 2.120107354951888\n",
      "Loss 2.1196368067179407\n",
      "Loss 2.1198582997888025\n",
      "Loss 2.1202267483890056\n",
      "Loss 2.1203337884716467\n",
      "Loss 2.1198752581430416\n",
      "Loss 2.1197861887818403\n",
      "Loss 2.1197353979543996\n",
      "Loss 2.1194232246364866\n",
      "Loss 2.1192278194708645\n",
      "Loss 2.119352560973613\n",
      "Loss 2.118883556773265\n",
      "Loss 2.118254817598457\n",
      "Loss 2.118004944394935\n",
      "Loss 2.1187765156632072\n",
      "Loss 2.118969044839697\n",
      "Loss 2.119278038703235\n",
      "Loss 2.1190400158470135\n",
      "Loss 2.118295007980388\n",
      "Loss 2.117686197120568\n",
      "Loss 2.1174925318946185\n",
      "Loss 2.1173611597792577\n",
      "Loss 2.117130976815184\n",
      "Loss 2.1167932839492956\n",
      "Loss 2.1164350658704425\n",
      "Loss 2.115808251099508\n",
      "Loss 2.1152715351911096\n",
      "Loss 2.1149181790697957\n",
      "Loss 2.1145052260684967\n",
      "Loss 2.1142205260954205\n",
      "Loss 2.1144065580968783\n",
      "Loss 2.114095862098038\n",
      "Loss 2.1139528915216754\n",
      "Loss 2.1137505710858564\n",
      "Loss 2.1137107949584495\n",
      "Loss 2.1132181598020323\n",
      "Loss 2.1128135435115127\n",
      "Loss 2.111929458891278\n",
      "Epoch 2/25, Loss: 2.1120\n",
      "Loss 2.275077810287476\n",
      "Loss 2.197876694202423\n",
      "Loss 2.1805177295207976\n",
      "Loss 2.1703213948011397\n",
      "Loss 2.1701454916000364\n",
      "Loss 2.1628529489040376\n",
      "Loss 2.1666792956420355\n",
      "Loss 2.1662886579334737\n",
      "Loss 2.164706197447247\n",
      "Loss 2.1632841283082964\n",
      "Loss 2.159098703102632\n",
      "Loss 2.1495420879125593\n",
      "Loss 2.152801463603973\n",
      "Loss 2.151557269522122\n",
      "Loss 2.145354761918386\n",
      "Loss 2.1459595657885076\n",
      "Loss 2.1422825858873478\n",
      "Loss 2.138453590604994\n",
      "Loss 2.1367971824972254\n",
      "Loss 2.137874330163002\n",
      "Loss 2.1349217406341006\n",
      "Loss 2.131907346844673\n",
      "Loss 2.1296654394916867\n",
      "Loss 2.12734194179376\n",
      "Loss 2.130679690122604\n",
      "Loss 2.1311046556784556\n",
      "Loss 2.128624293141895\n",
      "Loss 2.1273449300442424\n",
      "Loss 2.1243307303149126\n",
      "Loss 2.124490338087082\n",
      "Loss 2.1234017344828575\n",
      "Loss 2.1196430986747146\n",
      "Loss 2.118458729512764\n",
      "Loss 2.1162333982481676\n",
      "Loss 2.114665227276938\n",
      "Loss 2.1121742490265105\n",
      "Loss 2.110111535948676\n",
      "Loss 2.1084850130896817\n",
      "Loss 2.1078101253815187\n",
      "Loss 2.106079805999994\n",
      "Loss 2.1047955678730474\n",
      "Loss 2.1037298805373057\n",
      "Loss 2.1029564298862633\n",
      "Loss 2.1021271084655413\n",
      "Loss 2.102338887373606\n",
      "Loss 2.1001782764040904\n",
      "Loss 2.0988377549800465\n",
      "Loss 2.098282306541999\n",
      "Loss 2.0968685207075004\n",
      "Loss 2.0961436537742615\n",
      "Loss 2.096406525396833\n",
      "Loss 2.097027770074514\n",
      "Loss 2.096252393205211\n",
      "Loss 2.0945543713481336\n",
      "Loss 2.0931123683452606\n",
      "Loss 2.0923255164069787\n",
      "Loss 2.0907485456843125\n",
      "Loss 2.088495268677843\n",
      "Loss 2.085982695161286\n",
      "Loss 2.085466515014569\n",
      "Loss 2.084032984884059\n",
      "Loss 2.081329695380503\n",
      "Loss 2.080895828566854\n",
      "Loss 2.0800438691582532\n",
      "Loss 2.0791714750711736\n",
      "Loss 2.0780834420070504\n",
      "Loss 2.0774898367942267\n",
      "Loss 2.0763935809188028\n",
      "Loss 2.0765411145531614\n",
      "Loss 2.075742148220539\n",
      "Loss 2.073928108257307\n",
      "Loss 2.074349000396\n",
      "Loss 2.074793810640296\n",
      "Loss 2.074377730158535\n",
      "Loss 2.0742490768988926\n",
      "Loss 2.072375102364703\n",
      "Loss 2.071888555388946\n",
      "Loss 2.071016656229129\n",
      "Loss 2.0700607451985156\n",
      "Loss 2.0694907692596316\n",
      "Loss 2.0681599335390843\n",
      "Loss 2.0674713411781847\n",
      "Loss 2.067291000097631\n",
      "Loss 2.0662742333965642\n",
      "Loss 2.0656745595020407\n",
      "Loss 2.0651457990532696\n",
      "Loss 2.064278344484581\n",
      "Loss 2.0646338508819992\n",
      "Loss 2.0639331272411883\n",
      "Loss 2.064022820174694\n",
      "Loss 2.063446550349613\n",
      "Loss 2.063024875411521\n",
      "Loss 2.0621620392607105\n",
      "Loss 2.0614110889650408\n",
      "Loss 2.0607101754201085\n",
      "Loss 2.060742224175483\n",
      "Loss 2.0621365557442006\n",
      "Loss 2.062047507696006\n",
      "Loss 2.062062428870586\n",
      "Loss 2.062255553597212\n",
      "Loss 2.062389230639628\n",
      "Loss 2.0621213999390604\n",
      "Loss 2.0621436665532658\n",
      "Loss 2.0621409101612294\n",
      "Loss 2.0620516725665046\n",
      "Loss 2.0616918196599436\n",
      "Loss 2.0617659089776956\n",
      "Loss 2.061448357872389\n",
      "Loss 2.061019742089674\n",
      "Loss 2.0608564409288492\n",
      "Loss 2.0615597230196\n",
      "Loss 2.061669142975339\n",
      "Loss 2.061891255869275\n",
      "Loss 2.0617524032268606\n",
      "Loss 2.0615490130911702\n",
      "Loss 2.061234437941477\n",
      "Loss 2.0612700778857254\n",
      "Loss 2.061251325521429\n",
      "Loss 2.0609206182165307\n",
      "Loss 2.0608153594185907\n",
      "Loss 2.060641942492201\n",
      "Loss 2.060144690905438\n",
      "Loss 2.0596824014332236\n",
      "Loss 2.0594974503449857\n",
      "Loss 2.059266607270241\n",
      "Loss 2.058957272555147\n",
      "Loss 2.0592521972778277\n",
      "Loss 2.0591997294360773\n",
      "Loss 2.059196504017179\n",
      "Loss 2.0591991941974714\n",
      "Loss 2.059309356863262\n",
      "Loss 2.0588642869528497\n",
      "Loss 2.058531760098343\n",
      "Loss 2.0578616818385336\n",
      "Epoch 3/25, Loss: 2.0579\n",
      "Loss 2.2095719265937803\n",
      "Loss 2.139466438293457\n",
      "Loss 2.122378820180893\n",
      "Loss 2.1100087478756904\n",
      "Loss 2.110718504548073\n",
      "Loss 2.1016279392441115\n",
      "Loss 2.1029502925702506\n",
      "Loss 2.10022727586329\n",
      "Loss 2.0992965273724664\n",
      "Loss 2.0982750303149222\n",
      "Loss 2.0956789433414285\n",
      "Loss 2.0872010938823222\n",
      "Loss 2.08922955260827\n",
      "Loss 2.0883472179089275\n",
      "Loss 2.0839460879564284\n",
      "Loss 2.0850316740199926\n",
      "Loss 2.0829281333264182\n",
      "Loss 2.079672726293405\n",
      "Loss 2.0788298553228377\n",
      "Loss 2.079097701281309\n",
      "Loss 2.0766187286660784\n",
      "Loss 2.074860848215493\n",
      "Loss 2.073229341481043\n",
      "Loss 2.071361426090201\n",
      "Loss 2.0746564723730088\n",
      "Loss 2.0753079695197254\n",
      "Loss 2.073814847977073\n",
      "Loss 2.073360911245857\n",
      "Loss 2.0710133318859953\n",
      "Loss 2.0716447671055795\n",
      "Loss 2.0709388618507694\n",
      "Loss 2.0673215484060345\n",
      "Loss 2.065671432036342\n",
      "Loss 2.0630660456944914\n",
      "Loss 2.061293033446584\n",
      "Loss 2.0595035011072955\n",
      "Loss 2.0572511777523403\n",
      "Loss 2.055872264049555\n",
      "Loss 2.0554569152838145\n",
      "Loss 2.054149081066251\n",
      "Loss 2.05321306831953\n",
      "Loss 2.0519857465511278\n",
      "Loss 2.051336200861044\n",
      "Loss 2.0503153500367293\n",
      "Loss 2.0504645322826174\n",
      "Loss 2.048395831546058\n",
      "Loss 2.0474880631807\n",
      "Loss 2.046997215313216\n",
      "Loss 2.0459874838590624\n",
      "Loss 2.0452681499838827\n",
      "Loss 2.0454332376578277\n",
      "Loss 2.046297494757634\n",
      "Loss 2.0455695807146577\n",
      "Loss 2.0440602381692994\n",
      "Loss 2.0427828726876864\n",
      "Loss 2.0420733498569046\n",
      "Loss 2.041077917050897\n",
      "Loss 2.0388328065851637\n",
      "Loss 2.036293967265194\n",
      "Loss 2.0358076737423736\n",
      "Loss 2.0344288212451778\n",
      "Loss 2.0317564411990103\n",
      "Loss 2.0311484551524357\n",
      "Loss 2.0302885992918163\n",
      "Loss 2.0296306460178815\n",
      "Loss 2.0284350872491346\n",
      "Loss 2.0276204914388374\n",
      "Loss 2.026830251926885\n",
      "Loss 2.027127395220425\n",
      "Loss 2.026684297314712\n",
      "Loss 2.0253961358355803\n",
      "Loss 2.02591670707696\n",
      "Loss 2.026487881067681\n",
      "Loss 2.026329646907948\n",
      "Loss 2.0263495910406113\n",
      "Loss 2.0249785486098966\n",
      "Loss 2.0243903555266267\n",
      "Loss 2.0234914869146468\n",
      "Loss 2.0226670923036867\n",
      "Loss 2.0220526452586056\n",
      "Loss 2.0206909166221267\n",
      "Loss 2.0201030257344246\n",
      "Loss 2.0197455717641186\n",
      "Loss 2.018888921900874\n",
      "Loss 2.0183484925592645\n",
      "Loss 2.0177752051727715\n",
      "Loss 2.0169421942412167\n",
      "Loss 2.017300037599423\n",
      "Loss 2.016473031064098\n",
      "Loss 2.016601507630613\n",
      "Loss 2.015982876315222\n",
      "Loss 2.015415754855975\n",
      "Loss 2.0147937719988565\n",
      "Loss 2.014097160804779\n",
      "Loss 2.013441181753811\n",
      "Loss 2.0134611979561545\n",
      "Loss 2.0147201098301974\n",
      "Loss 2.0147353467223597\n",
      "Loss 2.0148790777271444\n",
      "Loss 2.015113849109411\n",
      "Loss 2.0151173583174695\n",
      "Loss 2.0146985204021135\n",
      "Loss 2.0148029649431267\n",
      "Loss 2.0147739143956165\n",
      "Loss 2.014739536245664\n",
      "Loss 2.0145647521794965\n",
      "Loss 2.014823158450216\n",
      "Loss 2.014668613854382\n",
      "Loss 2.0144178222570943\n",
      "Loss 2.0144340966560623\n",
      "Loss 2.0150564616059397\n",
      "Loss 2.0151712788481797\n",
      "Loss 2.0154223857147504\n",
      "Loss 2.0152834691028847\n",
      "Loss 2.0151146544736362\n",
      "Loss 2.0147246974141435\n",
      "Loss 2.014666963382664\n",
      "Loss 2.0146083145677034\n",
      "Loss 2.0142813057408615\n",
      "Loss 2.0142960730046036\n",
      "Loss 2.0143394184358847\n",
      "Loss 2.0142223506433066\n",
      "Loss 2.0139567518185792\n",
      "Loss 2.0140972522045337\n",
      "Loss 2.014380437464714\n",
      "Loss 2.0143416165501353\n",
      "Loss 2.014610350774968\n",
      "Loss 2.0145246693259105\n",
      "Loss 2.014678331534992\n",
      "Loss 2.0146290475726127\n",
      "Loss 2.0147457602415377\n",
      "Loss 2.0145081523828434\n",
      "Loss 2.014281344274829\n",
      "Loss 2.0137085466420475\n",
      "Epoch 4/25, Loss: 2.0137\n",
      "Loss 2.173446888923645\n",
      "Loss 2.103472276329994\n",
      "Loss 2.0814978194236757\n",
      "Loss 2.0668843659758567\n",
      "Loss 2.0655585281848907\n",
      "Loss 2.056716568470001\n",
      "Loss 2.059091785975865\n",
      "Loss 2.0580434207618237\n",
      "Loss 2.054541601339976\n",
      "Loss 2.051367985725403\n",
      "Loss 2.047894142324274\n",
      "Loss 2.0404039441545803\n",
      "Loss 2.0409833765029908\n",
      "Loss 2.039343558549881\n",
      "Loss 2.0343805103302004\n",
      "Loss 2.0348463858664037\n",
      "Loss 2.0332829452262207\n",
      "Loss 2.0302431386709214\n",
      "Loss 2.0298906452404823\n",
      "Loss 2.029773377776146\n",
      "Loss 2.026834350994655\n",
      "Loss 2.0243163761767473\n",
      "Loss 2.0232506654573523\n",
      "Loss 2.021726325005293\n",
      "Loss 2.0252200020313262\n",
      "Loss 2.0255336981094803\n",
      "Loss 2.0240628095909403\n",
      "Loss 2.02410706694637\n",
      "Loss 2.0216135368264956\n",
      "Loss 2.023534018278122\n",
      "Loss 2.0241462678678572\n",
      "Loss 2.0210616823658345\n",
      "Loss 2.0191726129344016\n",
      "Loss 2.016730602348552\n",
      "Loss 2.014955082109996\n",
      "Loss 2.013114671309789\n",
      "Loss 2.011397212034947\n",
      "Loss 2.009963295051926\n",
      "Loss 2.0093526877501073\n",
      "Loss 2.0079899022579193\n",
      "Loss 2.006989429811152\n",
      "Loss 2.006325070545787\n",
      "Loss 2.0061287003894184\n",
      "Loss 2.0050793384692884\n",
      "Loss 2.005404036415948\n",
      "Loss 2.003495605510214\n",
      "Loss 2.0026072205127554\n",
      "Loss 2.0020391479631265\n",
      "Loss 2.0008880353947074\n",
      "Loss 1.9999657833576203\n",
      "Loss 2.000203217758852\n",
      "Loss 2.0011580976156087\n",
      "Loss 2.000460634006644\n",
      "Loss 1.999295104013549\n",
      "Loss 1.99817357080633\n",
      "Loss 1.9973707409203052\n",
      "Loss 1.9961384581055557\n",
      "Loss 1.9940115058422088\n",
      "Loss 1.991555115752301\n",
      "Loss 1.991290881216526\n",
      "Loss 1.9899310192514639\n",
      "Loss 1.9876657243313327\n",
      "Loss 1.9869785348385098\n",
      "Loss 1.986007439121604\n",
      "Loss 1.9853175352169916\n",
      "Loss 1.9840003348661193\n",
      "Loss 1.9832075276659495\n",
      "Loss 1.982275362856248\n",
      "Loss 1.9821118533265762\n",
      "Loss 1.9815880557639258\n",
      "Loss 1.9800920176170242\n",
      "Loss 1.9806507082283498\n",
      "Loss 1.981040930013134\n",
      "Loss 1.9810449568323187\n",
      "Loss 1.9810512583096822\n",
      "Loss 1.979555557370186\n",
      "Loss 1.979247744687192\n",
      "Loss 1.9784699281056721\n",
      "Loss 1.9780683750140515\n",
      "Loss 1.9776885330379008\n",
      "Loss 1.976575956167998\n",
      "Loss 1.9758617052363185\n",
      "Loss 1.9756024508447532\n",
      "Loss 1.9749194792906444\n",
      "Loss 1.9744158507795895\n",
      "Loss 1.9738382829205934\n",
      "Loss 1.9730122702286161\n",
      "Loss 1.9731465601108291\n",
      "Loss 1.9723944942736893\n",
      "Loss 1.9725437423785528\n",
      "Loss 1.971888201891721\n",
      "Loss 1.9713567216240842\n",
      "Loss 1.9704883914993656\n",
      "Loss 1.9698305317569287\n",
      "Loss 1.9692318797864412\n",
      "Loss 1.9693235527351498\n",
      "Loss 1.970597800729201\n",
      "Loss 1.9707273888101382\n",
      "Loss 1.9708005730190663\n",
      "Loss 1.9709229834914208\n",
      "Loss 1.9710547782288919\n",
      "Loss 1.970780623286378\n",
      "Loss 1.9709555791766897\n",
      "Loss 1.9710540327544395\n",
      "Loss 1.9711608152843656\n",
      "Loss 1.9708461191744175\n",
      "Loss 1.9708521401102297\n",
      "Loss 1.9705498220523199\n",
      "Loss 1.9703396307875256\n",
      "Loss 1.970420097762888\n",
      "Loss 1.9710621411521156\n",
      "Loss 1.971039574476225\n",
      "Loss 1.9713611471441994\n",
      "Loss 1.9711213464172264\n",
      "Loss 1.9707162803877956\n",
      "Loss 1.9703561117936825\n",
      "Loss 1.9703271760186578\n",
      "Loss 1.970283238766557\n",
      "Loss 1.970009459277161\n",
      "Loss 1.9699603990912438\n",
      "Loss 1.9699577502278256\n",
      "Loss 1.969851300442805\n",
      "Loss 1.9695278123723783\n",
      "Loss 1.9696711130103757\n",
      "Loss 1.9696138964366914\n",
      "Loss 1.9694717691531256\n",
      "Loss 1.9697260380917647\n",
      "Loss 1.9697165056224912\n",
      "Loss 1.9698537726642549\n",
      "Loss 1.9698629426589378\n",
      "Loss 1.9700376736207772\n",
      "Loss 1.9699529665708542\n",
      "Loss 1.9697500773300802\n",
      "Loss 1.9692278985923795\n",
      "Epoch 5/25, Loss: 1.9693\n",
      "Loss 2.1185007107257845\n",
      "Loss 2.0551341634988787\n",
      "Loss 2.0336102573076884\n",
      "Loss 2.017042088508606\n",
      "Loss 2.017161685705185\n",
      "Loss 2.008528826435407\n",
      "Loss 2.007367650270462\n",
      "Loss 2.005559505224228\n",
      "Loss 2.0014188016785517\n",
      "Loss 1.9980326702594757\n",
      "Loss 1.9950802434574475\n",
      "Loss 1.9883870789408684\n",
      "Loss 1.9891904537952863\n",
      "Loss 1.9888309840219363\n",
      "Loss 1.9850764500697453\n",
      "Loss 1.9867826847359538\n",
      "Loss 1.9857425043512793\n",
      "Loss 1.9833512218462097\n",
      "Loss 1.9833770507574082\n",
      "Loss 1.9832589507997036\n",
      "Loss 1.9801177738677889\n",
      "Loss 1.9784169008786028\n",
      "Loss 1.9779898048224656\n",
      "Loss 1.9769773687670629\n",
      "Loss 1.980321182179451\n",
      "Loss 1.9810269140967955\n",
      "Loss 1.9792492628097533\n",
      "Loss 1.9796320820280484\n",
      "Loss 1.976786741059402\n",
      "Loss 1.977860455751419\n",
      "Loss 1.9775359249884081\n",
      "Loss 1.9746483404189348\n",
      "Loss 1.9733595077919237\n",
      "Loss 1.971373005474315\n",
      "Loss 1.9698406034026827\n",
      "Loss 1.9681499704221885\n",
      "Loss 1.9666997413538598\n",
      "Loss 1.9658799861763654\n",
      "Loss 1.9651678679386775\n",
      "Loss 1.9637388128489255\n",
      "Loss 1.9629991969102767\n",
      "Loss 1.9623225178463117\n",
      "Loss 1.9619440629454545\n",
      "Loss 1.9611231160841205\n",
      "Loss 1.9613978902101517\n",
      "Loss 1.9593723024103953\n",
      "Loss 1.959099004281328\n",
      "Loss 1.9588381627077858\n",
      "Loss 1.9577641398931036\n",
      "Loss 1.9568991448760034\n",
      "Loss 1.9571048598546608\n",
      "Loss 1.9578182505071162\n",
      "Loss 1.9570867578151092\n",
      "Loss 1.9559896587552847\n",
      "Loss 1.9551489143046465\n",
      "Loss 1.95494068789695\n",
      "Loss 1.9537533449185522\n",
      "Loss 1.9515306283893257\n",
      "Loss 1.94907994955273\n",
      "Loss 1.9486827113231022\n",
      "Loss 1.9472833513041012\n",
      "Loss 1.945203214172394\n",
      "Loss 1.9447971468690841\n",
      "Loss 1.943900481518358\n",
      "Loss 1.9434856127225435\n",
      "Loss 1.9422648616451206\n",
      "Loss 1.941486522297361\n",
      "Loss 1.9410188496814054\n",
      "Loss 1.9409090104483175\n",
      "Loss 1.9402902593272073\n",
      "Loss 1.9387226341308004\n",
      "Loss 1.9391170551379522\n",
      "Loss 1.9393148513852734\n",
      "Loss 1.9392773739550564\n",
      "Loss 1.939475637404124\n",
      "Loss 1.9382604420341945\n",
      "Loss 1.9377158405873682\n",
      "Loss 1.9369083916071135\n",
      "Loss 1.9366126997863191\n",
      "Loss 1.9364728548079728\n",
      "Loss 1.9355105312665304\n",
      "Loss 1.9348773829893369\n",
      "Loss 1.9346125506995673\n",
      "Loss 1.933736292996577\n",
      "Loss 1.9331344006692661\n",
      "Loss 1.932656654958115\n",
      "Loss 1.9318948897342572\n",
      "Loss 1.9318921369517392\n",
      "Loss 1.9312356753764528\n",
      "Loss 1.9313739376134342\n",
      "Loss 1.930636279314429\n",
      "Loss 1.9300273707055526\n",
      "Loss 1.9291214586906535\n",
      "Loss 1.9283761016548948\n",
      "Loss 1.927922474459598\n",
      "Loss 1.9280756266539296\n",
      "Loss 1.9294106195759528\n",
      "Loss 1.9295862886978656\n",
      "Loss 1.9296567095289328\n",
      "Loss 1.9298660853981973\n",
      "Loss 1.9300235802938441\n",
      "Loss 1.9296840863601834\n",
      "Loss 1.9299178696373134\n",
      "Loss 1.9300485345491996\n",
      "Loss 1.9302032444363548\n",
      "Loss 1.9299215014138311\n",
      "Loss 1.9299071603400686\n",
      "Loss 1.9296072359548675\n",
      "Loss 1.9294875968158791\n",
      "Loss 1.9298246397863734\n",
      "Loss 1.9305104017579877\n",
      "Loss 1.9305500866898468\n",
      "Loss 1.9308224611155755\n",
      "Loss 1.9307467130924525\n",
      "Loss 1.9305382767552914\n",
      "Loss 1.9302982557744814\n",
      "Loss 1.930212396892727\n",
      "Loss 1.9301649167477075\n",
      "Loss 1.929976511021622\n",
      "Loss 1.9300180704295635\n",
      "Loss 1.9300188479443228\n",
      "Loss 1.929783328576166\n",
      "Loss 1.9294756373738855\n",
      "Loss 1.929590611371302\n",
      "Loss 1.9295438867855073\n",
      "Loss 1.929335834289354\n",
      "Loss 1.9294815591845926\n",
      "Loss 1.92933248125948\n",
      "Loss 1.929450070044791\n",
      "Loss 1.929441875045116\n",
      "Loss 1.9295933383475734\n",
      "Loss 1.9294443848367893\n",
      "Loss 1.9292882422128117\n",
      "Loss 1.928831463296022\n",
      "Epoch 6/25, Loss: 1.9289\n",
      "Loss 2.0554928612709045\n",
      "Loss 2.0029078984260558\n",
      "Loss 1.9851869837443035\n",
      "Loss 1.9665759471058846\n",
      "Loss 1.965042862534523\n",
      "Loss 1.959529237250487\n",
      "Loss 1.9610993059192385\n",
      "Loss 1.9578303440660239\n",
      "Loss 1.95232059193982\n",
      "Loss 1.9501120168566703\n",
      "Loss 1.947102813449773\n",
      "Loss 1.9412436603009702\n",
      "Loss 1.9415907901525498\n",
      "Loss 1.9408906652671951\n",
      "Loss 1.9357877267599106\n",
      "Loss 1.9373769230023026\n",
      "Loss 1.9365546543808545\n",
      "Loss 1.934975163506137\n",
      "Loss 1.9352582404174303\n",
      "Loss 1.9349884842336178\n",
      "Loss 1.931537333244369\n",
      "Loss 1.930277436619455\n",
      "Loss 1.930253807798676\n",
      "Loss 1.9297892730186383\n",
      "Loss 1.9331063586950301\n",
      "Loss 1.9335867854952813\n",
      "Loss 1.932396794403041\n",
      "Loss 1.9330076892673969\n",
      "Loss 1.9310287095554943\n",
      "Loss 1.9315942092140517\n",
      "Loss 1.931572136552103\n",
      "Loss 1.9289465965516865\n",
      "Loss 1.9277324757612113\n",
      "Loss 1.92617379085106\n",
      "Loss 1.9251572880574634\n",
      "Loss 1.923895777579811\n",
      "Loss 1.9226297791100837\n",
      "Loss 1.9216100165247918\n",
      "Loss 1.9210247458402927\n",
      "Loss 1.9198163301497697\n",
      "Loss 1.9191861912244703\n",
      "Loss 1.9190052258542605\n",
      "Loss 1.9194154446762661\n",
      "Loss 1.9188868514651602\n",
      "Loss 1.919306097653177\n",
      "Loss 1.9173630312085153\n",
      "Loss 1.9175763940430701\n",
      "Loss 1.9169884158298374\n",
      "Loss 1.9161733719645715\n",
      "Loss 1.9153476732611656\n",
      "Loss 1.9157779549033034\n",
      "Loss 1.9163582011254934\n",
      "Loss 1.9155023505440298\n",
      "Loss 1.9146973240706655\n",
      "Loss 1.913990176059983\n",
      "Loss 1.9137690041001354\n",
      "Loss 1.9127379139787273\n",
      "Loss 1.9108536155881553\n",
      "Loss 1.9086158915495468\n",
      "Loss 1.908307652870814\n",
      "Loss 1.907028075984267\n",
      "Loss 1.9050703723199907\n",
      "Loss 1.904359918321882\n",
      "Loss 1.9032220298238098\n",
      "Loss 1.902856977737867\n",
      "Loss 1.901968909014355\n",
      "Loss 1.9010956261940857\n",
      "Loss 1.9002297522215281\n",
      "Loss 1.9001100724330846\n",
      "Loss 1.899482953258923\n",
      "Loss 1.898241440645406\n",
      "Loss 1.898753876586755\n",
      "Loss 1.8992582429761755\n",
      "Loss 1.8990872044176668\n",
      "Loss 1.8991067635059358\n",
      "Loss 1.8978669616423156\n",
      "Loss 1.8974769500942974\n",
      "Loss 1.8966369416163518\n",
      "Loss 1.8960903589484057\n",
      "Loss 1.8958168712854386\n",
      "Loss 1.8946431576469798\n",
      "Loss 1.8940698935709348\n",
      "Loss 1.8936444030827786\n",
      "Loss 1.893090033155112\n",
      "Loss 1.8926890347635046\n",
      "Loss 1.8921778260344684\n",
      "Loss 1.8913782159966983\n",
      "Loss 1.8914938760684294\n",
      "Loss 1.8908661505546462\n",
      "Loss 1.8910722147160106\n",
      "Loss 1.8903019768523646\n",
      "Loss 1.8897489425734333\n",
      "Loss 1.8888346857601597\n",
      "Loss 1.888045018740157\n",
      "Loss 1.8879510886041742\n",
      "Loss 1.888119394145906\n",
      "Loss 1.8892836043269363\n",
      "Loss 1.889469045935845\n",
      "Loss 1.8894537399633966\n",
      "Loss 1.889656105351448\n",
      "Loss 1.8898388267271589\n",
      "Loss 1.8895570707438039\n",
      "Loss 1.8899204235169493\n",
      "Loss 1.8900310087777101\n",
      "Loss 1.8903161611443475\n",
      "Loss 1.8899430861563054\n",
      "Loss 1.8899300930098952\n",
      "Loss 1.889729762673378\n",
      "Loss 1.8896791805914783\n",
      "Loss 1.8899056936394085\n",
      "Loss 1.8906712212433685\n",
      "Loss 1.8906486021620887\n",
      "Loss 1.8909202923078452\n",
      "Loss 1.8908355374503554\n",
      "Loss 1.8908329705466396\n",
      "Loss 1.8907619385780958\n",
      "Loss 1.890710620880127\n",
      "Loss 1.8907195041745395\n",
      "Loss 1.8907171908346545\n",
      "Loss 1.8908167748351892\n",
      "Loss 1.8907664903284105\n",
      "Loss 1.8905812522378125\n",
      "Loss 1.8902567529726804\n",
      "Loss 1.8904443130329731\n",
      "Loss 1.8904929298353195\n",
      "Loss 1.8904513481259346\n",
      "Loss 1.89097922291812\n",
      "Loss 1.8908539131330326\n",
      "Loss 1.8910306743457337\n",
      "Loss 1.8910047402794545\n",
      "Loss 1.8911904634910686\n",
      "Loss 1.8910329615302157\n",
      "Loss 1.8908828793656558\n",
      "Loss 1.8906204145924368\n",
      "Epoch 7/25, Loss: 1.8907\n",
      "Loss 2.013650426864624\n",
      "Loss 1.9668792951107026\n",
      "Loss 1.9483661850293477\n",
      "Loss 1.9308755481243134\n",
      "Loss 1.9255766413211823\n",
      "Loss 1.9199782701333363\n",
      "Loss 1.9211958711487906\n",
      "Loss 1.919490184187889\n",
      "Loss 1.9133693921566008\n",
      "Loss 1.9105290621519089\n",
      "Loss 1.9080273053862833\n",
      "Loss 1.9025404193003972\n",
      "Loss 1.9025326498655173\n",
      "Loss 1.9017523404530117\n",
      "Loss 1.8969243434270222\n",
      "Loss 1.8987293249368669\n",
      "Loss 1.8980280132854686\n",
      "Loss 1.8969057134124967\n",
      "Loss 1.897361002846768\n",
      "Loss 1.897430684030056\n",
      "Loss 1.8946774565038227\n",
      "Loss 1.893575541973114\n",
      "Loss 1.8940085913823999\n",
      "Loss 1.8948310440282028\n",
      "Loss 1.8980936406612396\n",
      "Loss 1.8988817740862187\n",
      "Loss 1.8982136596573724\n",
      "Loss 1.8995501178928784\n",
      "Loss 1.8983223571037424\n",
      "Loss 1.8997929157018663\n",
      "Loss 1.9000015557581378\n",
      "Loss 1.8977305711433292\n",
      "Loss 1.89662268057014\n",
      "Loss 1.8944858337500516\n",
      "Loss 1.893419229064669\n",
      "Loss 1.8922050031688478\n",
      "Loss 1.8911157502999176\n",
      "Loss 1.8904790977741543\n",
      "Loss 1.889970743625592\n",
      "Loss 1.8890355418324472\n",
      "Loss 1.88839190299918\n",
      "Loss 1.8880206110080082\n",
      "Loss 1.8878769642530486\n",
      "Loss 1.886951157613234\n",
      "Loss 1.8877777576181625\n",
      "Loss 1.8857355898618697\n",
      "Loss 1.885601174298753\n",
      "Loss 1.885109018360575\n",
      "Loss 1.8842495246079503\n",
      "Loss 1.8834698907613754\n",
      "Loss 1.8836132753362842\n",
      "Loss 1.884057531104638\n",
      "Loss 1.8831513064987255\n",
      "Loss 1.8831244250359358\n",
      "Loss 1.8824311970797452\n",
      "Loss 1.8822358518413136\n",
      "Loss 1.881279304142584\n",
      "Loss 1.8794278066836554\n",
      "Loss 1.8770619393506291\n",
      "Loss 1.8766149961253007\n",
      "Loss 1.8751916030293605\n",
      "Loss 1.8734440005114001\n",
      "Loss 1.8729223256546355\n",
      "Loss 1.8718211660627275\n",
      "Loss 1.871387021110608\n",
      "Loss 1.8705696963270506\n",
      "Loss 1.8697459416336089\n",
      "Loss 1.868656866944888\n",
      "Loss 1.8684539579567703\n",
      "Loss 1.868076584960733\n",
      "Loss 1.8666625257361102\n",
      "Loss 1.8674419395873945\n",
      "Loss 1.8675811215541134\n",
      "Loss 1.8675250450098837\n",
      "Loss 1.867623250857989\n",
      "Loss 1.8661149258754754\n",
      "Loss 1.8655983124383084\n",
      "Loss 1.8650123305733388\n",
      "Loss 1.8644770106710966\n",
      "Loss 1.8643273725286127\n",
      "Loss 1.8632440884098596\n",
      "Loss 1.8624102784802274\n",
      "Loss 1.8620482501208064\n",
      "Loss 1.8613725505698295\n",
      "Loss 1.8610165981404923\n",
      "Loss 1.8603495941605679\n",
      "Loss 1.8595359738119717\n",
      "Loss 1.8595830290561373\n",
      "Loss 1.8589535573761116\n",
      "Loss 1.8591104302008947\n",
      "Loss 1.8582055317307566\n",
      "Loss 1.8576016280055045\n",
      "Loss 1.8569100828580958\n",
      "Loss 1.8561966750342795\n",
      "Loss 1.8557495404168178\n",
      "Loss 1.8557562333717943\n",
      "Loss 1.8568266091518795\n",
      "Loss 1.856924252522235\n",
      "Loss 1.8570794303850695\n",
      "Loss 1.8573154207825662\n",
      "Loss 1.8575665591140784\n",
      "Loss 1.8576888310091169\n",
      "Loss 1.8580497466707693\n",
      "Loss 1.8582961174731072\n",
      "Loss 1.8586155458064306\n",
      "Loss 1.8583916800989295\n",
      "Loss 1.8586135729562456\n",
      "Loss 1.8583536029965788\n",
      "Loss 1.8583299145129843\n",
      "Loss 1.8585762312954122\n",
      "Loss 1.8594130742335104\n",
      "Loss 1.859343984052539\n",
      "Loss 1.8595975597242338\n",
      "Loss 1.859570047238417\n",
      "Loss 1.8593620389337124\n",
      "Loss 1.8591634319671269\n",
      "Loss 1.8590764500850285\n",
      "Loss 1.8590343452005063\n",
      "Loss 1.8589092417023763\n",
      "Loss 1.8589884859820207\n",
      "Loss 1.8589618146665825\n",
      "Loss 1.8588036037224238\n",
      "Loss 1.8583776920258515\n",
      "Loss 1.8584953217016111\n",
      "Loss 1.858468494143486\n",
      "Loss 1.8584573948525247\n",
      "Loss 1.8586924572770052\n",
      "Loss 1.858576121092774\n",
      "Loss 1.858716535637545\n",
      "Loss 1.8586702491274247\n",
      "Loss 1.8588684833186273\n",
      "Loss 1.8586958345364442\n",
      "Loss 1.858568656538662\n",
      "Loss 1.858255217742564\n",
      "Epoch 8/25, Loss: 1.8583\n",
      "Loss 1.9581238532066345\n",
      "Loss 1.9227033597230911\n",
      "Loss 1.9066639145215352\n",
      "Loss 1.888396140038967\n",
      "Loss 1.885005797147751\n",
      "Loss 1.8816584648688635\n",
      "Loss 1.8839057723113468\n",
      "Loss 1.8806725598871707\n",
      "Loss 1.8730411018265618\n",
      "Loss 1.8703019680976867\n",
      "Loss 1.8683052770657973\n",
      "Loss 1.8632879068454107\n",
      "Loss 1.8636901464829079\n",
      "Loss 1.8637322242770875\n",
      "Loss 1.8590552651087442\n",
      "Loss 1.8610038700699807\n",
      "Loss 1.861992978699067\n",
      "Loss 1.860742820567555\n",
      "Loss 1.8616338461951205\n",
      "Loss 1.8609210968613625\n",
      "Loss 1.8582010215237028\n",
      "Loss 1.8574564298174598\n",
      "Loss 1.8582910335063934\n",
      "Loss 1.8590239997208118\n",
      "Loss 1.8639476890563964\n",
      "Loss 1.8644468450546265\n",
      "Loss 1.8640339174977056\n",
      "Loss 1.8643889129587583\n",
      "Loss 1.862017177754435\n",
      "Loss 1.8639797168970107\n",
      "Loss 1.8640902393864047\n",
      "Loss 1.8618668044358493\n",
      "Loss 1.86062576955015\n",
      "Loss 1.858709246095489\n",
      "Loss 1.8570825247083391\n",
      "Loss 1.8556427618198925\n",
      "Loss 1.8543714391218649\n",
      "Loss 1.853467958977348\n",
      "Loss 1.852988775418355\n",
      "Loss 1.8521597231030464\n",
      "Loss 1.8515653721006906\n",
      "Loss 1.8513645512717112\n",
      "Loss 1.8514163903580156\n",
      "Loss 1.8506120066751133\n",
      "Loss 1.8513511638376448\n",
      "Loss 1.849626897469811\n",
      "Loss 1.8492674953886803\n",
      "Loss 1.8484828460216522\n",
      "Loss 1.847523521744475\n",
      "Loss 1.8468710107564925\n",
      "Loss 1.8476209698237624\n",
      "Loss 1.8486054021807816\n",
      "Loss 1.8479579592875714\n",
      "Loss 1.848219925849526\n",
      "Loss 1.84771981549263\n",
      "Loss 1.8475866160009589\n",
      "Loss 1.8466004586742635\n",
      "Loss 1.8449189348467465\n",
      "Loss 1.8427987909114967\n",
      "Loss 1.842454077998797\n",
      "Loss 1.8411101970711692\n",
      "Loss 1.8393817327099462\n",
      "Loss 1.8387120225505222\n",
      "Loss 1.8376130393706263\n",
      "Loss 1.837132740515929\n",
      "Loss 1.836134854410634\n",
      "Loss 1.8352718750042702\n",
      "Loss 1.8341851637994542\n",
      "Loss 1.8338843319035958\n",
      "Loss 1.8333719116279057\n",
      "Loss 1.8318885875251931\n",
      "Loss 1.8323161121540599\n",
      "Loss 1.832481101930958\n",
      "Loss 1.8323720501242458\n",
      "Loss 1.8324976380825042\n",
      "Loss 1.8309997188888099\n",
      "Loss 1.8304891176502427\n",
      "Loss 1.8302084840108186\n",
      "Loss 1.8298682479918758\n",
      "Loss 1.8298122735619544\n",
      "Loss 1.828808880544003\n",
      "Loss 1.8282472692175609\n",
      "Loss 1.8277699667574412\n",
      "Loss 1.8271400557955106\n",
      "Loss 1.8270978218106662\n",
      "Loss 1.826428037119466\n",
      "Loss 1.8257518328058309\n",
      "Loss 1.8257346180216834\n",
      "Loss 1.8249546357085196\n",
      "Loss 1.8251218712727229\n",
      "Loss 1.8242430069682363\n",
      "Loss 1.823520690980165\n",
      "Loss 1.8225951284875153\n",
      "Loss 1.8218869397741684\n",
      "Loss 1.8214656319179032\n",
      "Loss 1.8214319244089225\n",
      "Loss 1.8224885682039653\n",
      "Loss 1.8227251083206157\n",
      "Loss 1.8228901169336202\n",
      "Loss 1.8230213600337506\n",
      "Loss 1.8231947218486577\n",
      "Loss 1.8234223604143835\n",
      "Loss 1.8238782290521178\n",
      "Loss 1.8240821541559238\n",
      "Loss 1.82440901189191\n",
      "Loss 1.824056398817953\n",
      "Loss 1.8240000240546521\n",
      "Loss 1.823796711779303\n",
      "Loss 1.8239287471661874\n",
      "Loss 1.8243815106586976\n",
      "Loss 1.8249520760183935\n",
      "Loss 1.824831088972943\n",
      "Loss 1.8250800442379134\n",
      "Loss 1.8250267774284932\n",
      "Loss 1.8248966407464897\n",
      "Loss 1.824678177782174\n",
      "Loss 1.8246898541898808\n",
      "Loss 1.8246673067949586\n",
      "Loss 1.8246850476144743\n",
      "Loss 1.8248382219175499\n",
      "Loss 1.824797594754164\n",
      "Loss 1.8246942468060823\n",
      "Loss 1.8242835221930247\n",
      "Loss 1.8243745193846763\n",
      "Loss 1.8243552457904815\n",
      "Loss 1.8242299903669055\n",
      "Loss 1.8242752943264218\n",
      "Loss 1.8241277144569903\n",
      "Loss 1.8242354262706846\n",
      "Loss 1.8241349308215655\n",
      "Loss 1.8243770841332791\n",
      "Loss 1.824180968805696\n",
      "Loss 1.824055276020129\n",
      "Loss 1.8237757679997986\n",
      "Epoch 9/25, Loss: 1.8238\n",
      "Loss 1.926227935552597\n",
      "Loss 1.889313138127327\n",
      "Loss 1.8730994315942129\n",
      "Loss 1.8551576861739159\n",
      "Loss 1.8528537901639939\n",
      "Loss 1.8437361020843188\n",
      "Loss 1.8442534920998983\n",
      "Loss 1.8413328126817943\n",
      "Loss 1.8331140942706001\n",
      "Loss 1.8312310058474541\n",
      "Loss 1.8299455176158386\n",
      "Loss 1.8257938219606877\n",
      "Loss 1.8261350098023048\n",
      "Loss 1.8267722716501782\n",
      "Loss 1.822726778348287\n",
      "Loss 1.8249398953467608\n",
      "Loss 1.8248870212190291\n",
      "Loss 1.824165049261517\n",
      "Loss 1.8251562954250136\n",
      "Loss 1.825968342423439\n",
      "Loss 1.8236458965142568\n",
      "Loss 1.8233328358151697\n",
      "Loss 1.8255090843594592\n",
      "Loss 1.8259938052296638\n",
      "Loss 1.8294214445114136\n",
      "Loss 1.829414726816691\n",
      "Loss 1.8294934023751153\n",
      "Loss 1.8304966098495892\n",
      "Loss 1.8277539642514853\n",
      "Loss 1.82942153942585\n",
      "Loss 1.8297972488787866\n",
      "Loss 1.8280480412766338\n",
      "Loss 1.826461134968382\n",
      "Loss 1.8247088992595673\n",
      "Loss 1.8233978382519314\n",
      "Loss 1.8214347246289253\n",
      "Loss 1.8204025817561793\n",
      "Loss 1.819597820921948\n",
      "Loss 1.8195850199002486\n",
      "Loss 1.8193632240891457\n",
      "Loss 1.8189795603112477\n",
      "Loss 1.818819461975779\n",
      "Loss 1.8182686034745947\n",
      "Loss 1.8173976527831772\n",
      "Loss 1.818219877799352\n",
      "Loss 1.8166191083970278\n",
      "Loss 1.8162229388064526\n",
      "Loss 1.8160651599615811\n",
      "Loss 1.816017503373477\n",
      "Loss 1.8157000934123992\n",
      "Loss 1.8167807798993354\n",
      "Loss 1.817928524865554\n",
      "Loss 1.817735563246709\n",
      "Loss 1.817633746487123\n",
      "Loss 1.817290828704834\n",
      "Loss 1.817228457140071\n",
      "Loss 1.8162431376440484\n",
      "Loss 1.8144392687904423\n",
      "Loss 1.8123919302831262\n",
      "Loss 1.8124206483662129\n",
      "Loss 1.811108275583533\n",
      "Loss 1.8095110536102326\n",
      "Loss 1.8088781820308595\n",
      "Loss 1.8076688380632548\n",
      "Loss 1.8068049959127719\n",
      "Loss 1.805691755386916\n",
      "Loss 1.8049160813306695\n",
      "Loss 1.8039850080451545\n",
      "Loss 1.80361142170602\n",
      "Loss 1.80325632248606\n",
      "Loss 1.8021273043625792\n",
      "Loss 1.802530036966006\n",
      "Loss 1.8030653587922658\n",
      "Loss 1.8025730701233889\n",
      "Loss 1.802655442237854\n",
      "Loss 1.8011058126625261\n",
      "Loss 1.800481595373773\n",
      "Loss 1.7998157918300384\n",
      "Loss 1.7993255385266074\n",
      "Loss 1.799253372937441\n",
      "Loss 1.798148212477013\n",
      "Loss 1.797437471820087\n",
      "Loss 1.797140597478453\n",
      "Loss 1.796571252956277\n",
      "Loss 1.7963375875318752\n",
      "Loss 1.7956758845753449\n",
      "Loss 1.7949880396840217\n",
      "Loss 1.794949655932459\n",
      "Loss 1.7944094847092469\n",
      "Loss 1.7946044109066328\n",
      "Loss 1.7938834363877119\n",
      "Loss 1.7934955510821031\n",
      "Loss 1.7926940281224508\n",
      "Loss 1.7919814155900733\n",
      "Loss 1.7915623285958642\n",
      "Loss 1.791455355764677\n",
      "Loss 1.7924435266452967\n",
      "Loss 1.7925393902951356\n",
      "Loss 1.7925420625462676\n",
      "Loss 1.7926328574955464\n",
      "Loss 1.7928792045907218\n",
      "Loss 1.7929190565616477\n",
      "Loss 1.7936775973757493\n",
      "Loss 1.7942309562460734\n",
      "Loss 1.7947162444761822\n",
      "Loss 1.7944994571242692\n",
      "Loss 1.7945486094739949\n",
      "Loss 1.7942856835932643\n",
      "Loss 1.7943647936670057\n",
      "Loss 1.7945718369646506\n",
      "Loss 1.7951500139311627\n",
      "Loss 1.7950705369934439\n",
      "Loss 1.7953110966798478\n",
      "Loss 1.7954468021215053\n",
      "Loss 1.7953291421817696\n",
      "Loss 1.7951996322695551\n",
      "Loss 1.7951288772393497\n",
      "Loss 1.795164734241316\n",
      "Loss 1.7953707846623508\n",
      "Loss 1.7956017506966988\n",
      "Loss 1.7954834821007468\n",
      "Loss 1.7954290026426316\n",
      "Loss 1.7952554112721264\n",
      "Loss 1.795400539857726\n",
      "Loss 1.795286291294098\n",
      "Loss 1.7951785752035323\n",
      "Loss 1.795307781471042\n",
      "Loss 1.7950570376962423\n",
      "Loss 1.795085449163304\n",
      "Loss 1.79500446334252\n",
      "Loss 1.7952366342617356\n",
      "Loss 1.7951530902674704\n",
      "Loss 1.7950260854663704\n",
      "Loss 1.7947463846651477\n",
      "Epoch 10/25, Loss: 1.7948\n",
      "Loss 1.8809782028198243\n",
      "Loss 1.8480386018753052\n",
      "Loss 1.8389672434329987\n",
      "Loss 1.8230901330709457\n",
      "Loss 1.8202494065761565\n",
      "Loss 1.8149424016475677\n",
      "Loss 1.8156998721190862\n",
      "Loss 1.8125541132688523\n",
      "Loss 1.8039943124188318\n",
      "Loss 1.8023111925125122\n",
      "Loss 1.8008126304366372\n",
      "Loss 1.7972843739390374\n",
      "Loss 1.7969329767960769\n",
      "Loss 1.7971177377871104\n",
      "Loss 1.7927550239562988\n",
      "Loss 1.7940009830147028\n",
      "Loss 1.7942449763943167\n",
      "Loss 1.7936126689778433\n",
      "Loss 1.7953786092682888\n",
      "Loss 1.7957515840530396\n",
      "Loss 1.793681696823665\n",
      "Loss 1.793806356191635\n",
      "Loss 1.7967680654318436\n",
      "Loss 1.7982363132139048\n",
      "Loss 1.8033169787883758\n",
      "Loss 1.8042668503522874\n",
      "Loss 1.8046011311698842\n",
      "Loss 1.8050372626738889\n",
      "Loss 1.803090186591806\n",
      "Loss 1.8048175373673438\n",
      "Loss 1.804504317564349\n",
      "Loss 1.8023330197669565\n",
      "Loss 1.8007145417639703\n",
      "Loss 1.8000061971825712\n",
      "Loss 1.798196518097605\n",
      "Loss 1.7963504244056012\n",
      "Loss 1.7954335887206567\n",
      "Loss 1.7945627802767252\n",
      "Loss 1.794672820522235\n",
      "Loss 1.793578959658742\n",
      "Loss 1.792886169145747\n",
      "Loss 1.7925831130430812\n",
      "Loss 1.7919471886130267\n",
      "Loss 1.790810624753887\n",
      "Loss 1.7913320545487934\n",
      "Loss 1.7895281268332315\n",
      "Loss 1.7891064725657726\n",
      "Loss 1.7888196361934146\n",
      "Loss 1.7886220712686072\n",
      "Loss 1.7880396891236305\n",
      "Loss 1.78853065858869\n",
      "Loss 1.789210155021686\n",
      "Loss 1.7885129821412968\n",
      "Loss 1.7883986220205272\n",
      "Loss 1.7879461124701934\n",
      "Loss 1.7877750886657409\n",
      "Loss 1.7867263438304266\n",
      "Loss 1.785123043964649\n",
      "Loss 1.7831711813049802\n",
      "Loss 1.7829572943945726\n",
      "Loss 1.7815976079663292\n",
      "Loss 1.7799129152586384\n",
      "Loss 1.7791253795604858\n",
      "Loss 1.7778768721874803\n",
      "Loss 1.7769635051855674\n",
      "Loss 1.775951283059337\n",
      "Loss 1.7752551695037244\n",
      "Loss 1.7745009088954504\n",
      "Loss 1.7741660611957744\n",
      "Loss 1.7738434914605958\n",
      "Loss 1.7729019530810102\n",
      "Loss 1.7732280462235213\n",
      "Loss 1.7738122418073758\n",
      "Loss 1.7732407518254745\n",
      "Loss 1.7731655754009883\n",
      "Loss 1.7719728259114842\n",
      "Loss 1.7713667996750249\n",
      "Loss 1.7707419623396337\n",
      "Loss 1.770342170867739\n",
      "Loss 1.7703925352022052\n",
      "Loss 1.7692883051692703\n",
      "Loss 1.768732845092692\n",
      "Loss 1.7685775162872062\n",
      "Loss 1.7678735600695723\n",
      "Loss 1.7675971348075306\n",
      "Loss 1.7669392101639925\n",
      "Loss 1.7662162671486537\n",
      "Loss 1.7660196151719851\n",
      "Loss 1.7654584722505526\n",
      "Loss 1.7657315199308925\n",
      "Loss 1.7648793569043442\n",
      "Loss 1.764375099675811\n",
      "Loss 1.7634217493059814\n",
      "Loss 1.7626472180003816\n",
      "Loss 1.7621791634622372\n",
      "Loss 1.762151643652469\n",
      "Loss 1.7631530284451455\n",
      "Loss 1.7633244288028502\n",
      "Loss 1.763521103708431\n",
      "Loss 1.7636633996903897\n",
      "Loss 1.7638687437182605\n",
      "Loss 1.7639090606102756\n",
      "Loss 1.7643349678597404\n",
      "Loss 1.7645137807325675\n",
      "Loss 1.7649735581023351\n",
      "Loss 1.7646130598659786\n",
      "Loss 1.7647464222607212\n",
      "Loss 1.7645206287448052\n",
      "Loss 1.7646123893490626\n",
      "Loss 1.7649007253267548\n",
      "Loss 1.765491826539641\n",
      "Loss 1.765490935301142\n",
      "Loss 1.7657602652880997\n",
      "Loss 1.7659610789543705\n",
      "Loss 1.765870644958123\n",
      "Loss 1.7657301923067406\n",
      "Loss 1.7657517041457005\n",
      "Loss 1.7657298789943678\n",
      "Loss 1.7659448311559292\n",
      "Loss 1.7661748222162326\n",
      "Loss 1.7661681454093003\n",
      "Loss 1.7661578123833312\n",
      "Loss 1.7658015170863004\n",
      "Loss 1.7660694287332797\n",
      "Loss 1.7659866033029556\n",
      "Loss 1.7658335005763977\n",
      "Loss 1.7659754119426248\n",
      "Loss 1.7658998863305897\n",
      "Loss 1.7660431954749796\n",
      "Loss 1.7661316952338586\n",
      "Loss 1.7663200555411913\n",
      "Loss 1.7662789349438566\n",
      "Loss 1.7662822573301487\n",
      "Loss 1.7661612315898512\n",
      "Epoch 11/25, Loss: 1.7662\n",
      "Loss 1.8545949423313142\n",
      "Loss 1.8209120285511018\n",
      "Loss 1.811291675567627\n",
      "Loss 1.7962010562419892\n",
      "Loss 1.791817488670349\n",
      "Loss 1.783297613064448\n",
      "Loss 1.785490802696773\n",
      "Loss 1.784276541173458\n",
      "Loss 1.7774411385589175\n",
      "Loss 1.7752804859876632\n",
      "Loss 1.774902937412262\n",
      "Loss 1.7720117810368539\n",
      "Loss 1.772278853563162\n",
      "Loss 1.7727196473734719\n",
      "Loss 1.7693978162606556\n",
      "Loss 1.7690775042772293\n",
      "Loss 1.7696525345830356\n",
      "Loss 1.768753967417611\n",
      "Loss 1.7705597515482652\n",
      "Loss 1.7699781653285027\n",
      "Loss 1.7671318731989178\n",
      "Loss 1.7669182088700208\n",
      "Loss 1.7697821990821672\n",
      "Loss 1.7714240023990473\n",
      "Loss 1.775981462430954\n",
      "Loss 1.7769153026434092\n",
      "Loss 1.7772224009478534\n",
      "Loss 1.7775045177766255\n",
      "Loss 1.774790178866222\n",
      "Loss 1.7756071009635925\n",
      "Loss 1.775847616464861\n",
      "Loss 1.7741861531324685\n",
      "Loss 1.7728907077059601\n",
      "Loss 1.7715435784178621\n",
      "Loss 1.770196011185646\n",
      "Loss 1.768350366867251\n",
      "Loss 1.7676067115648373\n",
      "Loss 1.7669770652526304\n",
      "Loss 1.7673990272711484\n",
      "Loss 1.766442430332303\n",
      "Loss 1.765822597524015\n",
      "Loss 1.7653231359237715\n",
      "Loss 1.764591000038524\n",
      "Loss 1.763506264591759\n",
      "Loss 1.764019880546464\n",
      "Loss 1.762506633154724\n",
      "Loss 1.7621185955215009\n",
      "Loss 1.7616239180788398\n",
      "Loss 1.7610697686064\n",
      "Loss 1.7604716854572295\n",
      "Loss 1.7610555834629957\n",
      "Loss 1.7616744511173321\n",
      "Loss 1.7609434942479403\n",
      "Loss 1.7609484993307678\n",
      "Loss 1.760693922996521\n",
      "Loss 1.7608326481495584\n",
      "Loss 1.7596469423331713\n",
      "Loss 1.7580608044307808\n",
      "Loss 1.7562113115444022\n",
      "Loss 1.7561919322709243\n",
      "Loss 1.7551512029229617\n",
      "Loss 1.7535979611546761\n",
      "Loss 1.7529750756895732\n",
      "Loss 1.7516212420817465\n",
      "Loss 1.7506607332321313\n",
      "Loss 1.7497060895417675\n",
      "Loss 1.749013974479775\n",
      "Loss 1.748123408073888\n",
      "Loss 1.7477043702118638\n",
      "Loss 1.7473466207129615\n",
      "Loss 1.746460511818738\n",
      "Loss 1.7467269157038794\n",
      "Loss 1.7469613497224572\n",
      "Loss 1.7464060046382852\n",
      "Loss 1.7463204872449238\n",
      "Loss 1.7449077592554845\n",
      "Loss 1.744227109203091\n",
      "Loss 1.7436145187494083\n",
      "Loss 1.7433412933047814\n",
      "Loss 1.743357930511236\n",
      "Loss 1.7422815700224887\n",
      "Loss 1.7418406368101516\n",
      "Loss 1.7415257797542825\n",
      "Loss 1.7409400297559443\n",
      "Loss 1.7406902629207162\n",
      "Loss 1.7399896042291507\n",
      "Loss 1.7393036715874726\n",
      "Loss 1.7390056353265588\n",
      "Loss 1.7383928069505798\n",
      "Loss 1.7386728510459264\n",
      "Loss 1.7377876289860232\n",
      "Loss 1.7373130858851515\n",
      "Loss 1.7363843362433935\n",
      "Loss 1.7356857364735705\n",
      "Loss 1.7352136755742524\n",
      "Loss 1.7351346073423823\n",
      "Loss 1.73609630963237\n",
      "Loss 1.7362600078874704\n",
      "Loss 1.7365291278651267\n",
      "Loss 1.7366540693998336\n",
      "Loss 1.736866045340453\n",
      "Loss 1.737008748732361\n",
      "Loss 1.7375914225416276\n",
      "Loss 1.7379794100729318\n",
      "Loss 1.738460019270579\n",
      "Loss 1.738129032389173\n",
      "Loss 1.7381854523119524\n",
      "Loss 1.73801822481332\n",
      "Loss 1.7382462289300533\n",
      "Loss 1.7384795124801722\n",
      "Loss 1.7391412388580338\n",
      "Loss 1.7391062770304935\n",
      "Loss 1.7394866855007358\n",
      "Loss 1.7397853329045732\n",
      "Loss 1.7396564836139263\n",
      "Loss 1.7394729328309668\n",
      "Loss 1.73965747619796\n",
      "Loss 1.7396109794307564\n",
      "Loss 1.7397683450103807\n",
      "Loss 1.7401486909339825\n",
      "Loss 1.7401227650268019\n",
      "Loss 1.7400643085847136\n",
      "Loss 1.739583907098305\n",
      "Loss 1.7397825133223688\n",
      "Loss 1.7397822303581238\n",
      "Loss 1.7396090916366804\n",
      "Loss 1.7396971311015408\n",
      "Loss 1.7397120419656857\n",
      "Loss 1.739857177849888\n",
      "Loss 1.7399233644421284\n",
      "Loss 1.7400678771552238\n",
      "Loss 1.7400273049735662\n",
      "Loss 1.7399620352696656\n",
      "Loss 1.7397980328994012\n",
      "Epoch 12/25, Loss: 1.7398\n",
      "Loss 1.827454651594162\n",
      "Loss 1.8050049763917924\n",
      "Loss 1.790375695625941\n",
      "Loss 1.7745470905303955\n",
      "Loss 1.7692394871711732\n",
      "Loss 1.761143426100413\n",
      "Loss 1.7626093626022339\n",
      "Loss 1.7598666900396347\n",
      "Loss 1.7499773312939537\n",
      "Loss 1.7476866092681884\n",
      "Loss 1.7464584965055638\n",
      "Loss 1.7439592334628105\n",
      "Loss 1.7432789969444276\n",
      "Loss 1.7433770790270398\n",
      "Loss 1.7392309606870016\n",
      "Loss 1.738985060751438\n",
      "Loss 1.739931524921866\n",
      "Loss 1.7396877821286518\n",
      "Loss 1.7414892551773473\n",
      "Loss 1.7417526693940162\n",
      "Loss 1.7388500113146645\n",
      "Loss 1.739082783352245\n",
      "Loss 1.7413230127355326\n",
      "Loss 1.7436832564572493\n",
      "Loss 1.747916443014145\n",
      "Loss 1.7494025240494655\n",
      "Loss 1.749914387287917\n",
      "Loss 1.7500690138765744\n",
      "Loss 1.7476639859840788\n",
      "Loss 1.7485966604153316\n",
      "Loss 1.7486056084402146\n",
      "Loss 1.746775594819337\n",
      "Loss 1.7454240942181962\n",
      "Loss 1.7445366629256922\n",
      "Loss 1.743119527050427\n",
      "Loss 1.7414239640865061\n",
      "Loss 1.7406416816808081\n",
      "Loss 1.740011573606416\n",
      "Loss 1.7407202248237073\n",
      "Loss 1.7402287972420454\n",
      "Loss 1.7396919399790647\n",
      "Loss 1.7397389426259768\n",
      "Loss 1.7399443367054297\n",
      "Loss 1.7387606686353683\n",
      "Loss 1.7400185124079386\n",
      "Loss 1.7383828493045723\n",
      "Loss 1.738122677777676\n",
      "Loss 1.7377669020493824\n",
      "Loss 1.7373430593646302\n",
      "Loss 1.7367736204862594\n",
      "Loss 1.7373360874138626\n",
      "Loss 1.7377688833383413\n",
      "Loss 1.7371403459557948\n",
      "Loss 1.7371983679797913\n",
      "Loss 1.7369493683468211\n",
      "Loss 1.737037021368742\n",
      "Loss 1.7360385511318843\n",
      "Loss 1.7344409755694454\n",
      "Loss 1.7328623538502193\n",
      "Loss 1.7327926377654075\n",
      "Loss 1.7315511178774912\n",
      "Loss 1.7300256986195042\n",
      "Loss 1.7293086583841415\n",
      "Loss 1.7279972048103809\n",
      "Loss 1.7270293551591727\n",
      "Loss 1.7260559217676972\n",
      "Loss 1.7253024796941387\n",
      "Loss 1.7245359218295884\n",
      "Loss 1.7240357346552007\n",
      "Loss 1.7233667208211763\n",
      "Loss 1.7223102771312417\n",
      "Loss 1.722797412979934\n",
      "Loss 1.7229278075776688\n",
      "Loss 1.7224880024790763\n",
      "Loss 1.7223860438744227\n",
      "Loss 1.7211009802708501\n",
      "Loss 1.7203312945752949\n",
      "Loss 1.7197379722121435\n",
      "Loss 1.7194870647523977\n",
      "Loss 1.719601584918797\n",
      "Loss 1.7186855230434441\n",
      "Loss 1.7184908258696883\n",
      "Loss 1.7181516454521433\n",
      "Loss 1.7176110616823037\n",
      "Loss 1.7172630158242057\n",
      "Loss 1.716568059332149\n",
      "Loss 1.7159877040399902\n",
      "Loss 1.7156601083346388\n",
      "Loss 1.7153396346662821\n",
      "Loss 1.7154378021491898\n",
      "Loss 1.7146349067936886\n",
      "Loss 1.714014304895764\n",
      "Loss 1.713349102152291\n",
      "Loss 1.7126433979894253\n",
      "Loss 1.7122811233746378\n",
      "Loss 1.7122738716068366\n",
      "Loss 1.7132386239963708\n",
      "Loss 1.713471771241451\n",
      "Loss 1.7135951558688673\n",
      "Loss 1.7137651657164097\n",
      "Loss 1.7138926534428456\n",
      "Loss 1.7140983810085877\n",
      "Loss 1.7148454559833102\n",
      "Loss 1.7151317845571499\n",
      "Loss 1.7157413603862126\n",
      "Loss 1.7153698201618104\n",
      "Loss 1.7154257285762056\n",
      "Loss 1.7151012401834682\n",
      "Loss 1.7152784699748416\n",
      "Loss 1.7156523936715993\n",
      "Loss 1.7163052716931781\n",
      "Loss 1.7162964116835169\n",
      "Loss 1.7165586748007124\n",
      "Loss 1.7169241744541286\n",
      "Loss 1.7169272224954937\n",
      "Loss 1.7167272164030323\n",
      "Loss 1.7169976358179353\n",
      "Loss 1.7170679424021205\n",
      "Loss 1.717265054523444\n",
      "Loss 1.717753382946054\n",
      "Loss 1.7178605005021923\n",
      "Loss 1.7177477155992242\n",
      "Loss 1.7172259586371057\n",
      "Loss 1.7173948024021042\n",
      "Loss 1.7172301444101334\n",
      "Loss 1.717120633536861\n",
      "Loss 1.7170637024340667\n",
      "Loss 1.7169850457226858\n",
      "Loss 1.717032107017761\n",
      "Loss 1.7170470503247701\n",
      "Loss 1.7171040709555605\n",
      "Loss 1.7170242231903654\n",
      "Loss 1.7168512713819517\n",
      "Loss 1.7166563517166606\n",
      "Epoch 13/25, Loss: 1.7167\n",
      "Loss 1.7899390828609467\n",
      "Loss 1.7776970010995865\n",
      "Loss 1.7678894058863321\n",
      "Loss 1.7490379497408868\n",
      "Loss 1.7408098536729812\n",
      "Loss 1.7319483748078346\n",
      "Loss 1.7319009005171913\n",
      "Loss 1.726466635838151\n",
      "Loss 1.7168833945194881\n",
      "Loss 1.7152761877179146\n",
      "Loss 1.715267101146958\n",
      "Loss 1.713646819939216\n",
      "Loss 1.7136571448124371\n",
      "Loss 1.7142952013441495\n",
      "Loss 1.7106658608516057\n",
      "Loss 1.7104220502451062\n",
      "Loss 1.7122555819329093\n",
      "Loss 1.7115131061938074\n",
      "Loss 1.7130346769721885\n",
      "Loss 1.7132448154389859\n",
      "Loss 1.7106904220864887\n",
      "Loss 1.7112910145250233\n",
      "Loss 1.7136925999755446\n",
      "Loss 1.7165320515880982\n",
      "Loss 1.7204867542505264\n",
      "Loss 1.7220401941583707\n",
      "Loss 1.722597109807862\n",
      "Loss 1.7230706829896996\n",
      "Loss 1.7209026069271154\n",
      "Loss 1.721677907049656\n",
      "Loss 1.7216685627160533\n",
      "Loss 1.7202385256811976\n",
      "Loss 1.7188137164260402\n",
      "Loss 1.7181114095098833\n",
      "Loss 1.7168872591427395\n",
      "Loss 1.715374334288968\n",
      "Loss 1.71534888219189\n",
      "Loss 1.7146538613344493\n",
      "Loss 1.7151068004889365\n",
      "Loss 1.7143931562006474\n",
      "Loss 1.7140105401306618\n",
      "Loss 1.713993429598354\n",
      "Loss 1.713321378924126\n",
      "Loss 1.7119187109172345\n",
      "Loss 1.7124121870862112\n",
      "Loss 1.7110383478325346\n",
      "Loss 1.7106089435359264\n",
      "Loss 1.710150246831278\n",
      "Loss 1.7098949157340186\n",
      "Loss 1.7095756680369376\n",
      "Loss 1.7100529979373895\n",
      "Loss 1.7106508949972117\n",
      "Loss 1.7099779076283832\n",
      "Loss 1.71034627734511\n",
      "Loss 1.710394239674915\n",
      "Loss 1.7105954292097263\n",
      "Loss 1.709791259995678\n",
      "Loss 1.708420296629955\n",
      "Loss 1.706835805854555\n",
      "Loss 1.7070754362046718\n",
      "Loss 1.7059343553468829\n",
      "Loss 1.704503815337535\n",
      "Loss 1.7038156871852421\n",
      "Loss 1.7025690695364029\n",
      "Loss 1.7015552376141916\n",
      "Loss 1.7006802972789967\n",
      "Loss 1.6998906657144204\n",
      "Loss 1.6991294028390855\n",
      "Loss 1.6985712855967923\n",
      "Loss 1.697940123268536\n",
      "Loss 1.697048386419323\n",
      "Loss 1.697308486037784\n",
      "Loss 1.697288640541573\n",
      "Loss 1.6967837945673916\n",
      "Loss 1.6965175616105397\n",
      "Loss 1.6952953011424918\n",
      "Loss 1.6946509994624497\n",
      "Loss 1.6941338062286377\n",
      "Loss 1.6938869376122196\n",
      "Loss 1.6938123485594987\n",
      "Loss 1.692973037796256\n",
      "Loss 1.6922422404914368\n",
      "Loss 1.6919062137962824\n",
      "Loss 1.6911895392409393\n",
      "Loss 1.6909582316875458\n",
      "Loss 1.6903506750422854\n",
      "Loss 1.689730362837342\n",
      "Loss 1.6893511254814537\n",
      "Loss 1.6888447992587357\n",
      "Loss 1.688964458823204\n",
      "Loss 1.6882369825800696\n",
      "Loss 1.687706562468539\n",
      "Loss 1.6867763016108543\n",
      "Loss 1.686163294321679\n",
      "Loss 1.6859176784000898\n",
      "Loss 1.6857788839625816\n",
      "Loss 1.686790688621629\n",
      "Loss 1.687095304247068\n",
      "Loss 1.6873035250950341\n",
      "Loss 1.6876253338158131\n",
      "Loss 1.688003628543108\n",
      "Loss 1.6879627876129806\n",
      "Loss 1.6886812958497446\n",
      "Loss 1.6890390338060948\n",
      "Loss 1.6896404944317682\n",
      "Loss 1.6893375525553271\n",
      "Loss 1.6895202094205073\n",
      "Loss 1.6894394079347452\n",
      "Loss 1.689734356091657\n",
      "Loss 1.6900393368493427\n",
      "Loss 1.6907521319443042\n",
      "Loss 1.6908235288783908\n",
      "Loss 1.6911442142830486\n",
      "Loss 1.6915794895876919\n",
      "Loss 1.6915476213486298\n",
      "Loss 1.691570956527159\n",
      "Loss 1.6915539704989164\n",
      "Loss 1.6915989008141776\n",
      "Loss 1.691795908377952\n",
      "Loss 1.6922735136002303\n",
      "Loss 1.6923583059320766\n",
      "Loss 1.6923406998788724\n",
      "Loss 1.6918413464955198\n",
      "Loss 1.6920341482037498\n",
      "Loss 1.6919374418401718\n",
      "Loss 1.6918291017933498\n",
      "Loss 1.6917650328001639\n",
      "Loss 1.6918268334958702\n",
      "Loss 1.692038094341293\n",
      "Loss 1.6920782972482535\n",
      "Loss 1.692208198427244\n",
      "Loss 1.6923590516502207\n",
      "Loss 1.6923345334547804\n",
      "Loss 1.6922435013304895\n",
      "Epoch 14/25, Loss: 1.6923\n",
      "Loss 1.7579282665252685\n",
      "Loss 1.7456499963998795\n",
      "Loss 1.7367524524529776\n",
      "Loss 1.721117072403431\n",
      "Loss 1.715104671239853\n",
      "Loss 1.7070911834637323\n",
      "Loss 1.7071920694623675\n",
      "Loss 1.704519542902708\n",
      "Loss 1.6960230871041615\n",
      "Loss 1.693572344660759\n",
      "Loss 1.6931647358157418\n",
      "Loss 1.6920704565445581\n",
      "Loss 1.6916552290549645\n",
      "Loss 1.6921260801383426\n",
      "Loss 1.689048524459203\n",
      "Loss 1.6891041990369557\n",
      "Loss 1.6903041473556968\n",
      "Loss 1.6896585204866197\n",
      "Loss 1.6911321350775268\n",
      "Loss 1.6918374653458594\n",
      "Loss 1.6890608297643208\n",
      "Loss 1.6904961079900915\n",
      "Loss 1.6948452500675035\n",
      "Loss 1.6976288589338462\n",
      "Loss 1.7009895004272462\n",
      "Loss 1.7022270836279942\n",
      "Loss 1.702952294393822\n",
      "Loss 1.7030635020136833\n",
      "Loss 1.70071139327411\n",
      "Loss 1.7016835671663284\n",
      "Loss 1.702100237992502\n",
      "Loss 1.7010637954995036\n",
      "Loss 1.6994821810361112\n",
      "Loss 1.6988806524346856\n",
      "Loss 1.6977169001443047\n",
      "Loss 1.6959100499749185\n",
      "Loss 1.695332661609392\n",
      "Loss 1.6946263539791107\n",
      "Loss 1.69505334123587\n",
      "Loss 1.694270504564047\n",
      "Loss 1.6938350262002246\n",
      "Loss 1.6940120705252601\n",
      "Loss 1.6935154672001684\n",
      "Loss 1.6919821299747988\n",
      "Loss 1.6928465418550702\n",
      "Loss 1.6913173294067383\n",
      "Loss 1.6907224315024436\n",
      "Loss 1.690328625117739\n",
      "Loss 1.6902325055307272\n",
      "Loss 1.6898614897489548\n",
      "Loss 1.690275556456809\n",
      "Loss 1.6906317365628023\n",
      "Loss 1.689859084588177\n",
      "Loss 1.6903153209333066\n",
      "Loss 1.6904743321592157\n",
      "Loss 1.6907867352451598\n",
      "Loss 1.6900476899377086\n",
      "Loss 1.6887553523532275\n",
      "Loss 1.6869593233779325\n",
      "Loss 1.6869764196077983\n",
      "Loss 1.6857667862391863\n",
      "Loss 1.6844314382153172\n",
      "Loss 1.6835753921667735\n",
      "Loss 1.682343549001962\n",
      "Loss 1.6814476923025572\n",
      "Loss 1.6805136561213119\n",
      "Loss 1.6796728240909862\n",
      "Loss 1.67898273545153\n",
      "Loss 1.6783622616961382\n",
      "Loss 1.6776714925255094\n",
      "Loss 1.6765752441446546\n",
      "Loss 1.6768087581131192\n",
      "Loss 1.6769672798620512\n",
      "Loss 1.676413053113061\n",
      "Loss 1.6762841347853343\n",
      "Loss 1.6751774668066126\n",
      "Loss 1.6745164251791966\n",
      "Loss 1.6741374524128743\n",
      "Loss 1.6739319865763942\n",
      "Loss 1.6740798634588718\n",
      "Loss 1.6731247183570155\n",
      "Loss 1.6728518324872343\n",
      "Loss 1.6726991055456988\n",
      "Loss 1.6723552043665022\n",
      "Loss 1.6722965081088683\n",
      "Loss 1.6716855298710425\n",
      "Loss 1.67103787896962\n",
      "Loss 1.6706300240280954\n",
      "Loss 1.6702523790785435\n",
      "Loss 1.670362119866742\n",
      "Loss 1.6696447015005154\n",
      "Loss 1.6690105247044045\n",
      "Loss 1.6683754913332642\n",
      "Loss 1.6676828825029921\n",
      "Loss 1.66740572613164\n",
      "Loss 1.667141340635717\n",
      "Loss 1.6682472865606093\n",
      "Loss 1.6684519358070529\n",
      "Loss 1.6687004915391557\n",
      "Loss 1.6693102455854416\n",
      "Loss 1.6695835314528777\n",
      "Loss 1.6698816128922445\n",
      "Loss 1.670767584830812\n",
      "Loss 1.671234954893589\n",
      "Loss 1.6719773592494782\n",
      "Loss 1.6716439158736536\n",
      "Loss 1.6719514283398602\n",
      "Loss 1.6718735775572282\n",
      "Loss 1.6721068510276462\n",
      "Loss 1.6724393851594492\n",
      "Loss 1.672996313394727\n",
      "Loss 1.6729768195588675\n",
      "Loss 1.6732431800861274\n",
      "Loss 1.673809127289998\n",
      "Loss 1.6737069241534108\n",
      "Loss 1.6735929744973266\n",
      "Loss 1.673593250884969\n",
      "Loss 1.6737336831325191\n",
      "Loss 1.674155496293757\n",
      "Loss 1.6746498438864947\n",
      "Loss 1.6746254134522982\n",
      "Loss 1.6745269498522164\n",
      "Loss 1.6740742328738778\n",
      "Loss 1.6742094933650187\n",
      "Loss 1.674122256846428\n",
      "Loss 1.67402489066597\n",
      "Loss 1.6739907907735645\n",
      "Loss 1.6739045254560188\n",
      "Loss 1.674029357003611\n",
      "Loss 1.6740107102531654\n",
      "Loss 1.6741760245215802\n",
      "Loss 1.6743964228711345\n",
      "Loss 1.674380474973442\n",
      "Loss 1.674267330303121\n",
      "Epoch 15/25, Loss: 1.6743\n",
      "Loss 1.7415826439857482\n",
      "Loss 1.7264729517698287\n",
      "Loss 1.7160575620333354\n",
      "Loss 1.7003740999102592\n",
      "Loss 1.6926366412639617\n",
      "Loss 1.6857389450073241\n",
      "Loss 1.6863579983370645\n",
      "Loss 1.6812510892748833\n",
      "Loss 1.6733679355515374\n",
      "Loss 1.6719637484550476\n",
      "Loss 1.672194053368135\n",
      "Loss 1.672007819612821\n",
      "Loss 1.6719950967568618\n",
      "Loss 1.673721650157656\n",
      "Loss 1.6712136586507162\n",
      "Loss 1.6708504869788885\n",
      "Loss 1.6724763084159178\n",
      "Loss 1.6719856741031012\n",
      "Loss 1.6736659147237476\n",
      "Loss 1.6748268150389194\n",
      "Loss 1.6725638699247725\n",
      "Loss 1.6732767206159505\n",
      "Loss 1.675894689689512\n",
      "Loss 1.6788217701762915\n",
      "Loss 1.6819274125814438\n",
      "Loss 1.6833801616384434\n",
      "Loss 1.6842800299547336\n",
      "Loss 1.6848601421926703\n",
      "Loss 1.6824590809386353\n",
      "Loss 1.683208230594794\n",
      "Loss 1.6831744146539318\n",
      "Loss 1.6817628519237042\n",
      "Loss 1.6804422316767953\n",
      "Loss 1.6796749089044682\n",
      "Loss 1.678349303007126\n",
      "Loss 1.6763688842786684\n",
      "Loss 1.6754969965122841\n",
      "Loss 1.674509540294346\n",
      "Loss 1.6749005381571942\n",
      "Loss 1.6745113536715508\n",
      "Loss 1.6746703000184966\n",
      "Loss 1.6750178742408752\n",
      "Loss 1.6744872107893922\n",
      "Loss 1.6732255787741055\n",
      "Loss 1.6735425363646612\n",
      "Loss 1.6720349232010219\n",
      "Loss 1.6715713052546723\n",
      "Loss 1.6711543386926253\n",
      "Loss 1.670739554629034\n",
      "Loss 1.6702445625066757\n",
      "Loss 1.67067630220862\n",
      "Loss 1.6707596756632512\n",
      "Loss 1.6701358960709483\n",
      "Loss 1.6705523270699714\n",
      "Loss 1.6706764558553695\n",
      "Loss 1.6709792970865964\n",
      "Loss 1.670015950202942\n",
      "Loss 1.6687704706192017\n",
      "Loss 1.6673574754343194\n",
      "Loss 1.667630786339442\n",
      "Loss 1.6666131788980765\n",
      "Loss 1.6652151205078247\n",
      "Loss 1.664301951783044\n",
      "Loss 1.6630535974726082\n",
      "Loss 1.662125574185298\n",
      "Loss 1.6611413582527277\n",
      "Loss 1.6605241978880185\n",
      "Loss 1.6599385348488302\n",
      "Loss 1.659261318574781\n",
      "Loss 1.6587655717389924\n",
      "Loss 1.6577105432077193\n",
      "Loss 1.6579385542455647\n",
      "Loss 1.6581560825076822\n",
      "Loss 1.6577018535701005\n",
      "Loss 1.6574307315270107\n",
      "Loss 1.6561401455731768\n",
      "Loss 1.6555397913440482\n",
      "Loss 1.6550201859917397\n",
      "Loss 1.654544375403018\n",
      "Loss 1.654337910808623\n",
      "Loss 1.6534063077782408\n",
      "Loss 1.6530626156998844\n",
      "Loss 1.6528287300718836\n",
      "Loss 1.6525947569310666\n",
      "Loss 1.6525245739572187\n",
      "Loss 1.6518798689509546\n",
      "Loss 1.651246548671832\n",
      "Loss 1.6508885216035627\n",
      "Loss 1.650421945445993\n",
      "Loss 1.6506928886440064\n",
      "Loss 1.6499979571785246\n",
      "Loss 1.6493540165800116\n",
      "Loss 1.6484015191690897\n",
      "Loss 1.6478268534008493\n",
      "Loss 1.6475431519182104\n",
      "Loss 1.6473056623650093\n",
      "Loss 1.6483241475673065\n",
      "Loss 1.6486634630512218\n",
      "Loss 1.648854815291636\n",
      "Loss 1.6491772110402585\n",
      "Loss 1.6495198523349102\n",
      "Loss 1.6498230735869968\n",
      "Loss 1.6505415956082854\n",
      "Loss 1.6508650785741898\n",
      "Loss 1.6515254286641166\n",
      "Loss 1.651121161512609\n",
      "Loss 1.6512769202317032\n",
      "Loss 1.651219951753263\n",
      "Loss 1.6514923653033895\n",
      "Loss 1.6518492077480662\n",
      "Loss 1.6524481263461415\n",
      "Loss 1.6524721349030733\n",
      "Loss 1.652759650787421\n",
      "Loss 1.6534011039085557\n",
      "Loss 1.65339033343481\n",
      "Loss 1.6534174290350798\n",
      "Loss 1.6534227812850577\n",
      "Loss 1.6535003372319674\n",
      "Loss 1.6537654897094776\n",
      "Loss 1.6544148561805487\n",
      "Loss 1.6544365695685395\n",
      "Loss 1.6544538947891017\n",
      "Loss 1.6539887142132936\n",
      "Loss 1.654065711402124\n",
      "Loss 1.6540337529373168\n",
      "Loss 1.6539061883233843\n",
      "Loss 1.6539057124599696\n",
      "Loss 1.6539422489330173\n",
      "Loss 1.6540785982812098\n",
      "Loss 1.6539599218827028\n",
      "Loss 1.654092809362266\n",
      "Loss 1.654163044835582\n",
      "Loss 1.6541561270925336\n",
      "Loss 1.6540773870918288\n",
      "Epoch 16/25, Loss: 1.6541\n",
      "Loss 1.7247177624702454\n",
      "Loss 1.7090474551916122\n",
      "Loss 1.702444593111674\n",
      "Loss 1.685092948526144\n",
      "Loss 1.6785832245349883\n",
      "Loss 1.6712739260991414\n",
      "Loss 1.669714434146881\n",
      "Loss 1.6626783671975136\n",
      "Loss 1.6526177661948733\n",
      "Loss 1.6503465424776078\n",
      "Loss 1.6508066966316917\n",
      "Loss 1.6506814689437548\n",
      "Loss 1.6503438569949223\n",
      "Loss 1.6514263764449528\n",
      "Loss 1.6484248774846395\n",
      "Loss 1.647781638726592\n",
      "Loss 1.6502686086822957\n",
      "Loss 1.6503885759247674\n",
      "Loss 1.6524961068755701\n",
      "Loss 1.6528234940171243\n",
      "Loss 1.6504055580638703\n",
      "Loss 1.6516467735984108\n",
      "Loss 1.6551419999288477\n",
      "Loss 1.6580604542295139\n",
      "Loss 1.6611025226593017\n",
      "Loss 1.6618774010584905\n",
      "Loss 1.6631862349863407\n",
      "Loss 1.662843330843108\n",
      "Loss 1.6606843925755599\n",
      "Loss 1.6613022232453027\n",
      "Loss 1.661813780242397\n",
      "Loss 1.660893151909113\n",
      "Loss 1.6592872260194835\n",
      "Loss 1.6583575407196494\n",
      "Loss 1.656987513576235\n",
      "Loss 1.6555585139989852\n",
      "Loss 1.6553095528563937\n",
      "Loss 1.654636396765709\n",
      "Loss 1.6548827563799344\n",
      "Loss 1.65435978358984\n",
      "Loss 1.6541752618696632\n",
      "Loss 1.6544759137006033\n",
      "Loss 1.6538027130725772\n",
      "Loss 1.65245421056043\n",
      "Loss 1.6529061620897716\n",
      "Loss 1.6517840378310369\n",
      "Loss 1.6514257375610635\n",
      "Loss 1.650965632237494\n",
      "Loss 1.6506874258299262\n",
      "Loss 1.650303569149971\n",
      "Loss 1.6505785041696885\n",
      "Loss 1.650704954954294\n",
      "Loss 1.6500897398084964\n",
      "Loss 1.6506333024192739\n",
      "Loss 1.6508202046914535\n",
      "Loss 1.651121856804405\n",
      "Loss 1.6503308061654107\n",
      "Loss 1.6491995174720369\n",
      "Loss 1.6474981982526133\n",
      "Loss 1.6477521181007226\n",
      "Loss 1.6466362781895967\n",
      "Loss 1.6453188594214379\n",
      "Loss 1.6449342171256505\n",
      "Loss 1.643608869081363\n",
      "Loss 1.642634742452548\n",
      "Loss 1.6416969573407463\n",
      "Loss 1.641085883476841\n",
      "Loss 1.6406752970902359\n",
      "Loss 1.6399977076399153\n",
      "Loss 1.6392786056825093\n",
      "Loss 1.6383065821923\n",
      "Loss 1.6385077721542782\n",
      "Loss 1.6385681084084185\n",
      "Loss 1.6381967093976768\n",
      "Loss 1.6379858071565627\n",
      "Loss 1.6369550168906388\n",
      "Loss 1.6361650092957856\n",
      "Loss 1.6359120756311294\n",
      "Loss 1.635674023892306\n",
      "Loss 1.6356467852517962\n",
      "Loss 1.6347180013965676\n",
      "Loss 1.6343863277827821\n",
      "Loss 1.6343247454065875\n",
      "Loss 1.6343936530252299\n",
      "Loss 1.6345541622007593\n",
      "Loss 1.6339020130454107\n",
      "Loss 1.633267694129341\n",
      "Loss 1.6327633508701216\n",
      "Loss 1.6323267752735802\n",
      "Loss 1.632444413708316\n",
      "Loss 1.6316296403159152\n",
      "Loss 1.6309138422750908\n",
      "Loss 1.6301880784893548\n",
      "Loss 1.629780684544685\n",
      "Loss 1.6295172638453936\n",
      "Loss 1.6292125350174804\n",
      "Loss 1.6302392997016613\n",
      "Loss 1.6306706406571427\n",
      "Loss 1.6307782675100095\n",
      "Loss 1.6311662714779378\n",
      "Loss 1.6315227861982762\n",
      "Loss 1.6318519921337857\n",
      "Loss 1.6326997156687153\n",
      "Loss 1.6330303659060827\n",
      "Loss 1.6337596964211691\n",
      "Loss 1.6333657016450505\n",
      "Loss 1.633433425699439\n",
      "Loss 1.6333478257446377\n",
      "Loss 1.6336618552350124\n",
      "Loss 1.6339515073461965\n",
      "Loss 1.63438625344822\n",
      "Loss 1.6344520063006451\n",
      "Loss 1.634777025643703\n",
      "Loss 1.6354614722676444\n",
      "Loss 1.6353656257650127\n",
      "Loss 1.635274965434239\n",
      "Loss 1.6352330549965557\n",
      "Loss 1.6357237168186802\n",
      "Loss 1.636141471452072\n",
      "Loss 1.6368020564615726\n",
      "Loss 1.6367511842516829\n",
      "Loss 1.6368046227976925\n",
      "Loss 1.6363440175851187\n",
      "Loss 1.6364563299859725\n",
      "Loss 1.6363339566612243\n",
      "Loss 1.6362751727775922\n",
      "Loss 1.636296852353051\n",
      "Loss 1.6363631648896262\n",
      "Loss 1.6366628308675086\n",
      "Loss 1.6365940315402472\n",
      "Loss 1.6367145310239937\n",
      "Loss 1.6366862236776136\n",
      "Loss 1.6366387130039974\n",
      "Loss 1.6365607142759793\n",
      "Epoch 17/25, Loss: 1.6366\n",
      "Loss 1.6859818089008332\n",
      "Loss 1.6784516012668609\n",
      "Loss 1.6785592285792033\n",
      "Loss 1.666237744987011\n",
      "Loss 1.657910918354988\n",
      "Loss 1.6553511678179105\n",
      "Loss 1.6526570099592208\n",
      "Loss 1.643381066992879\n",
      "Loss 1.6341418024566439\n",
      "Loss 1.6321671746373176\n",
      "Loss 1.6321350118788807\n",
      "Loss 1.6321513958275318\n",
      "Loss 1.6316826089987388\n",
      "Loss 1.632378436114107\n",
      "Loss 1.631309598962466\n",
      "Loss 1.630411661155522\n",
      "Loss 1.6319626631105648\n",
      "Loss 1.6339971268508169\n",
      "Loss 1.6396015404713782\n",
      "Loss 1.6406230933666228\n",
      "Loss 1.6380590940089452\n",
      "Loss 1.6397356461394916\n",
      "Loss 1.6423494601249695\n",
      "Loss 1.6459795134762922\n",
      "Loss 1.6486737537384033\n",
      "Loss 1.6487815369550998\n",
      "Loss 1.6507269529501598\n",
      "Loss 1.6503100100159644\n",
      "Loss 1.6488532189254104\n",
      "Loss 1.6499229774872461\n",
      "Loss 1.6501635833324924\n",
      "Loss 1.6492915871739386\n",
      "Loss 1.6486226505944224\n",
      "Loss 1.6480042314178804\n",
      "Loss 1.6466197050298963\n",
      "Loss 1.6449341687228944\n",
      "Loss 1.6449066616071237\n",
      "Loss 1.6441132806476795\n",
      "Loss 1.6442818515423017\n",
      "Loss 1.6433814617097378\n",
      "Loss 1.6432163122514398\n",
      "Loss 1.6437380829027721\n",
      "Loss 1.6428513743711073\n",
      "Loss 1.6414973015405916\n",
      "Loss 1.6417700771490733\n",
      "Loss 1.640608724096547\n",
      "Loss 1.6399399901704586\n",
      "Loss 1.6394580801203846\n",
      "Loss 1.639126563789893\n",
      "Loss 1.6385949538230895\n",
      "Loss 1.6388621579899507\n",
      "Loss 1.639023370719873\n",
      "Loss 1.6382018559833742\n",
      "Loss 1.6387828237922104\n",
      "Loss 1.6387978589318015\n",
      "Loss 1.6391376417449544\n",
      "Loss 1.6383522223380573\n",
      "Loss 1.6370526711488593\n",
      "Loss 1.63528975839332\n",
      "Loss 1.635597911308209\n",
      "Loss 1.6343722885456242\n",
      "Loss 1.6330525035146743\n",
      "Loss 1.6324900304230432\n",
      "Loss 1.6312074810545891\n",
      "Loss 1.6300950168187802\n",
      "Loss 1.6291510312755904\n",
      "Loss 1.628493686211643\n",
      "Loss 1.627591665553696\n",
      "Loss 1.6268356307865917\n",
      "Loss 1.6264294842481613\n",
      "Loss 1.625351805015349\n",
      "Loss 1.625451504174206\n",
      "Loss 1.6256016585598254\n",
      "Loss 1.625207340991175\n",
      "Loss 1.6249619409004847\n",
      "Loss 1.6237043456105809\n",
      "Loss 1.622795459690032\n",
      "Loss 1.622388353492969\n",
      "Loss 1.622020707907556\n",
      "Loss 1.6218669448420406\n",
      "Loss 1.6211832689282335\n",
      "Loss 1.6205084020989697\n",
      "Loss 1.6199945257729795\n",
      "Loss 1.619683734590099\n",
      "Loss 1.6197160173023448\n",
      "Loss 1.6191048032599826\n",
      "Loss 1.6185865834115565\n",
      "Loss 1.6181273018094626\n",
      "Loss 1.6177138774716453\n",
      "Loss 1.6177170361942714\n",
      "Loss 1.6169256829822456\n",
      "Loss 1.616086292895286\n",
      "Loss 1.6150584060338236\n",
      "Loss 1.6143908293957405\n",
      "Loss 1.614008119043551\n",
      "Loss 1.613703687482824\n",
      "Loss 1.6147648544225497\n",
      "Loss 1.6151778994956796\n",
      "Loss 1.615296300463002\n",
      "Loss 1.6157546372592448\n",
      "Loss 1.6160993830107226\n",
      "Loss 1.616368211782446\n",
      "Loss 1.6170092676044667\n",
      "Loss 1.6172337660480005\n",
      "Loss 1.6179447174696695\n",
      "Loss 1.617574499721797\n",
      "Loss 1.6175676261988756\n",
      "Loss 1.6175015894075235\n",
      "Loss 1.6178752462470203\n",
      "Loss 1.6181777351010929\n",
      "Loss 1.618856183204565\n",
      "Loss 1.6189267145097255\n",
      "Loss 1.6192041269234851\n",
      "Loss 1.6198009047278186\n",
      "Loss 1.6197554318593896\n",
      "Loss 1.619587339527648\n",
      "Loss 1.6196833757508515\n",
      "Loss 1.6196433178701644\n",
      "Loss 1.6200653112084926\n",
      "Loss 1.6206484096099933\n",
      "Loss 1.620819780186188\n",
      "Loss 1.6208801106546746\n",
      "Loss 1.6204381393562488\n",
      "Loss 1.6206892784228248\n",
      "Loss 1.6206902511024475\n",
      "Loss 1.6204766508085386\n",
      "Loss 1.6205235925574941\n",
      "Loss 1.6205458306940272\n",
      "Loss 1.6207572041602099\n",
      "Loss 1.6207553071746459\n",
      "Loss 1.6209184968335029\n",
      "Loss 1.6208740292624995\n",
      "Loss 1.6208601736394983\n",
      "Loss 1.620767508069081\n",
      "Epoch 18/25, Loss: 1.6208\n",
      "Loss 1.6627746176719667\n",
      "Loss 1.6621230137348175\n",
      "Loss 1.6567383122444153\n",
      "Loss 1.6430773901939393\n",
      "Loss 1.6332572708129882\n",
      "Loss 1.6271647262573241\n",
      "Loss 1.6268493247032165\n",
      "Loss 1.6197905373573303\n",
      "Loss 1.610288319322798\n",
      "Loss 1.6078820683956145\n",
      "Loss 1.6079011366584084\n",
      "Loss 1.6084648840626081\n",
      "Loss 1.6107122554228857\n",
      "Loss 1.6130117513452258\n",
      "Loss 1.6106430002053578\n",
      "Loss 1.6104456485062837\n",
      "Loss 1.6139768789095037\n",
      "Loss 1.6157105904155307\n",
      "Loss 1.621212525555962\n",
      "Loss 1.6220293872356415\n",
      "Loss 1.619591090906234\n",
      "Loss 1.6200741626999595\n",
      "Loss 1.6224665553155153\n",
      "Loss 1.6261512346565723\n",
      "Loss 1.628560141849518\n",
      "Loss 1.62865888435107\n",
      "Loss 1.6299378807456406\n",
      "Loss 1.629378062742097\n",
      "Loss 1.6278294317064614\n",
      "Loss 1.6285946358839671\n",
      "Loss 1.628899926235599\n",
      "Loss 1.6283731819689273\n",
      "Loss 1.627084270209977\n",
      "Loss 1.6263743392509573\n",
      "Loss 1.6250391353879656\n",
      "Loss 1.623107678492864\n",
      "Loss 1.6229568783012596\n",
      "Loss 1.6223531167758138\n",
      "Loss 1.6223396611060852\n",
      "Loss 1.6215321149975062\n",
      "Loss 1.6216609556645882\n",
      "Loss 1.6219860862692197\n",
      "Loss 1.621278940868932\n",
      "Loss 1.6198056887767531\n",
      "Loss 1.6200323282877604\n",
      "Loss 1.6187231409549714\n",
      "Loss 1.6180795208063532\n",
      "Loss 1.6177816242848833\n",
      "Loss 1.6177519398197835\n",
      "Loss 1.6174082142710686\n",
      "Loss 1.6175692415588043\n",
      "Loss 1.6177127074392943\n",
      "Loss 1.6170843066359466\n",
      "Loss 1.6178880014022192\n",
      "Loss 1.6181509995677255\n",
      "Loss 1.6185872311677252\n",
      "Loss 1.6177270238859611\n",
      "Loss 1.6165904349910802\n",
      "Loss 1.615084788132522\n",
      "Loss 1.6154151909947396\n",
      "Loss 1.6144505008224581\n",
      "Loss 1.6133607062312865\n",
      "Loss 1.6132137189876465\n",
      "Loss 1.6119419399183244\n",
      "Loss 1.6110741172478749\n",
      "Loss 1.609950485039841\n",
      "Loss 1.6091900150544607\n",
      "Loss 1.6084083978130537\n",
      "Loss 1.6076293800879216\n",
      "Loss 1.6071099561963762\n",
      "Loss 1.6064875388733098\n",
      "Loss 1.6068718493398693\n",
      "Loss 1.60693777872275\n",
      "Loss 1.606462942402105\n",
      "Loss 1.6061463411887487\n",
      "Loss 1.6050559656792565\n",
      "Loss 1.6041937323127473\n",
      "Loss 1.6039553642196533\n",
      "Loss 1.6035182337745835\n",
      "Loss 1.6034864153638482\n",
      "Loss 1.602705655017017\n",
      "Loss 1.60211997812841\n",
      "Loss 1.601858848390809\n",
      "Loss 1.6012554859334514\n",
      "Loss 1.6013863634502186\n",
      "Loss 1.6009329012244247\n",
      "Loss 1.6003896396530086\n",
      "Loss 1.5998993793197653\n",
      "Loss 1.5993004094549779\n",
      "Loss 1.5993006743126446\n",
      "Loss 1.598606348502767\n",
      "Loss 1.5978341853553835\n",
      "Loss 1.597047274657475\n",
      "Loss 1.5963425931968587\n",
      "Loss 1.595972850084305\n",
      "Loss 1.595726078748703\n",
      "Loss 1.5966983472440661\n",
      "Loss 1.5971848595142364\n",
      "Loss 1.597382054870779\n",
      "Loss 1.5977910880327224\n",
      "Loss 1.5981807511218704\n",
      "Loss 1.5985601435864674\n",
      "Loss 1.599041058664183\n",
      "Loss 1.5992406547241487\n",
      "Loss 1.5999447135698228\n",
      "Loss 1.599560548348247\n",
      "Loss 1.599537453111087\n",
      "Loss 1.599527178114211\n",
      "Loss 1.5999264306704932\n",
      "Loss 1.6003005458495834\n",
      "Loss 1.6007132417930139\n",
      "Loss 1.6007674941154464\n",
      "Loss 1.601086641281052\n",
      "Loss 1.6018937840116652\n",
      "Loss 1.6018866975877597\n",
      "Loss 1.6019101825407867\n",
      "Loss 1.6018561790998165\n",
      "Loss 1.6020394094566168\n",
      "Loss 1.602454332959752\n",
      "Loss 1.6029380799333255\n",
      "Loss 1.6028966953636201\n",
      "Loss 1.603045290483803\n",
      "Loss 1.6026692569837337\n",
      "Loss 1.6028346194471081\n",
      "Loss 1.6027739521741866\n",
      "Loss 1.6027171149424144\n",
      "Loss 1.6027878602846402\n",
      "Loss 1.602747690845281\n",
      "Loss 1.6028332500679547\n",
      "Loss 1.6027785524313267\n",
      "Loss 1.6028301352671994\n",
      "Loss 1.6028741817853667\n",
      "Loss 1.6028741221858147\n",
      "Loss 1.6027257613192742\n",
      "Epoch 19/25, Loss: 1.6027\n",
      "Loss 1.6461714786291122\n",
      "Loss 1.6460716792941092\n",
      "Loss 1.6414831115802129\n",
      "Loss 1.6297815391421318\n",
      "Loss 1.6212919517755509\n",
      "Loss 1.614436770180861\n",
      "Loss 1.613011274252619\n",
      "Loss 1.6058395101875067\n",
      "Loss 1.5977189987897873\n",
      "Loss 1.5950335529446602\n",
      "Loss 1.5951576015082272\n",
      "Loss 1.596824590663115\n",
      "Loss 1.5958378300300011\n",
      "Loss 1.5966188270705086\n",
      "Loss 1.5950032823880513\n",
      "Loss 1.593988984003663\n",
      "Loss 1.5973639325534597\n",
      "Loss 1.5988069578674104\n",
      "Loss 1.6034805837430453\n",
      "Loss 1.60375103738904\n",
      "Loss 1.601044564899944\n",
      "Loss 1.602170801569115\n",
      "Loss 1.6046012822182283\n",
      "Loss 1.6083782212187847\n",
      "Loss 1.6107583061933517\n",
      "Loss 1.6108801679657057\n",
      "Loss 1.6126077636745242\n",
      "Loss 1.6125692159576075\n",
      "Loss 1.6109224675647145\n",
      "Loss 1.6119919027686118\n",
      "Loss 1.6121469673995048\n",
      "Loss 1.6113248585350812\n",
      "Loss 1.6097284797104923\n",
      "Loss 1.608452560095226\n",
      "Loss 1.6071497733422688\n",
      "Loss 1.60525788375073\n",
      "Loss 1.6050152435657141\n",
      "Loss 1.604480195218011\n",
      "Loss 1.6044741939428524\n",
      "Loss 1.6039448735862971\n",
      "Loss 1.6041243024715564\n",
      "Loss 1.604464905304568\n",
      "Loss 1.6037680782412373\n",
      "Loss 1.602179563980211\n",
      "Loss 1.6023955367538665\n",
      "Loss 1.601314015323701\n",
      "Loss 1.6006858078342803\n",
      "Loss 1.6003951796144247\n",
      "Loss 1.600050335052062\n",
      "Loss 1.599538351368904\n",
      "Loss 1.600012735210213\n",
      "Loss 1.6004338847559232\n",
      "Loss 1.5998397940622187\n",
      "Loss 1.6008613413461932\n",
      "Loss 1.6013915408199484\n",
      "Loss 1.602080900807466\n",
      "Loss 1.6010808649397732\n",
      "Loss 1.5998940143605758\n",
      "Loss 1.5984009275092916\n",
      "Loss 1.5989212976197402\n",
      "Loss 1.5979398832360252\n",
      "Loss 1.596860920777244\n",
      "Loss 1.5965253481316188\n",
      "Loss 1.5953109419252725\n",
      "Loss 1.594424996678646\n",
      "Loss 1.593157691332427\n",
      "Loss 1.5924284934374824\n",
      "Loss 1.5920520170208285\n",
      "Loss 1.5912832395754\n",
      "Loss 1.5908319767713546\n",
      "Loss 1.5901552988609797\n",
      "Loss 1.590707103262345\n",
      "Loss 1.5908338236972077\n",
      "Loss 1.5904940262839602\n",
      "Loss 1.590084716264407\n",
      "Loss 1.5889862470642517\n",
      "Loss 1.588217572631774\n",
      "Loss 1.5877246305193657\n",
      "Loss 1.5875034764673137\n",
      "Loss 1.5875692344754935\n",
      "Loss 1.586942739001027\n",
      "Loss 1.5866510619695593\n",
      "Loss 1.5864724672343358\n",
      "Loss 1.5861475426313423\n",
      "Loss 1.5861636553652145\n",
      "Loss 1.585662689430769\n",
      "Loss 1.5850572166360657\n",
      "Loss 1.5846740911223671\n",
      "Loss 1.5840948768947902\n",
      "Loss 1.5840563012361526\n",
      "Loss 1.5832519915929208\n",
      "Loss 1.5824501071935115\n",
      "Loss 1.581601022020463\n",
      "Loss 1.5808844339213473\n",
      "Loss 1.5805630093875684\n",
      "Loss 1.5804468202094237\n",
      "Loss 1.5812473534308757\n",
      "Loss 1.5817038542883737\n",
      "Loss 1.5818169795443313\n",
      "Loss 1.582143333262205\n",
      "Loss 1.5825964933515775\n",
      "Loss 1.5830629868425574\n",
      "Loss 1.5835126693214028\n",
      "Loss 1.5836744769777242\n",
      "Loss 1.584484056416012\n",
      "Loss 1.584170809613084\n",
      "Loss 1.5843875421653284\n",
      "Loss 1.5843863121778876\n",
      "Loss 1.584751238615141\n",
      "Loss 1.5850817708644\n",
      "Loss 1.5855464860233102\n",
      "Loss 1.5855777246717895\n",
      "Loss 1.5858922395347494\n",
      "Loss 1.5868534232231608\n",
      "Loss 1.5868440940794737\n",
      "Loss 1.5867786413739466\n",
      "Loss 1.5867946200391165\n",
      "Loss 1.5868962401252682\n",
      "Loss 1.5873377256233152\n",
      "Loss 1.5880769387284914\n",
      "Loss 1.5885774710257192\n",
      "Loss 1.588943313115933\n",
      "Loss 1.588685361287458\n",
      "Loss 1.588798457533121\n",
      "Loss 1.5886787078666686\n",
      "Loss 1.5888066041280353\n",
      "Loss 1.588715035699484\n",
      "Loss 1.5887223156634718\n",
      "Loss 1.5888136038114857\n",
      "Loss 1.5887436557366297\n",
      "Loss 1.5887725621416369\n",
      "Loss 1.588729937519088\n",
      "Loss 1.588674404822794\n",
      "Loss 1.5886479494776298\n",
      "Epoch 20/25, Loss: 1.5887\n",
      "Loss 1.6263131338357926\n",
      "Loss 1.6253794315457344\n",
      "Loss 1.6249782051642736\n",
      "Loss 1.6128656101226806\n",
      "Loss 1.6046921846866609\n",
      "Loss 1.6052840826908747\n",
      "Loss 1.6059848497595106\n",
      "Loss 1.597347268462181\n",
      "Loss 1.5876138339440027\n",
      "Loss 1.5844108448624612\n",
      "Loss 1.5839487987214869\n",
      "Loss 1.5844162547091643\n",
      "Loss 1.5832278671631446\n",
      "Loss 1.5846719953843524\n",
      "Loss 1.5837483325004578\n",
      "Loss 1.583310897052288\n",
      "Loss 1.5866740194488975\n",
      "Loss 1.5874553004900613\n",
      "Loss 1.5914889050784864\n",
      "Loss 1.591590223699808\n",
      "Loss 1.5888899436734971\n",
      "Loss 1.589127004146576\n",
      "Loss 1.5938780683538187\n",
      "Loss 1.5979608800758918\n",
      "Loss 1.600479096388817\n",
      "Loss 1.5999448342735951\n",
      "Loss 1.6014104233847724\n",
      "Loss 1.6010372532691275\n",
      "Loss 1.5992406294263641\n",
      "Loss 1.6005714445908865\n",
      "Loss 1.6006740780607347\n",
      "Loss 1.5996492029540241\n",
      "Loss 1.5976783932880922\n",
      "Loss 1.596950242256417\n",
      "Loss 1.595894700884819\n",
      "Loss 1.5940885695152813\n",
      "Loss 1.5936672148189028\n",
      "Loss 1.5929893570197255\n",
      "Loss 1.592925005432887\n",
      "Loss 1.59238988481462\n",
      "Loss 1.5926443084710982\n",
      "Loss 1.593259796230566\n",
      "Loss 1.5923822072910707\n",
      "Loss 1.590845344838771\n",
      "Loss 1.5910940137836669\n",
      "Loss 1.5898068356384403\n",
      "Loss 1.5892467408230964\n",
      "Loss 1.5889591360588868\n",
      "Loss 1.5889190431273714\n",
      "Loss 1.588445948445797\n",
      "Loss 1.5884008012215296\n",
      "Loss 1.5882664208114148\n",
      "Loss 1.5878344335083692\n",
      "Loss 1.5889400822255346\n",
      "Loss 1.589250923969529\n",
      "Loss 1.5897927252841848\n",
      "Loss 1.5888877964228914\n",
      "Loss 1.5881275908392052\n",
      "Loss 1.5865734262284585\n",
      "Loss 1.5870086744924385\n",
      "Loss 1.5860519309903756\n",
      "Loss 1.585154413484758\n",
      "Loss 1.58496653568177\n",
      "Loss 1.5837519821710884\n",
      "Loss 1.5827509251557863\n",
      "Loss 1.5813240783955111\n",
      "Loss 1.5808287083124046\n",
      "Loss 1.580047130838913\n",
      "Loss 1.579180722132973\n",
      "Loss 1.578692322100912\n",
      "Loss 1.5777438848874938\n",
      "Loss 1.578194623382555\n",
      "Loss 1.5779541965788357\n",
      "Loss 1.5775899877177701\n",
      "Loss 1.5773544992685318\n",
      "Loss 1.5762598420836424\n",
      "Loss 1.5754391870018725\n",
      "Loss 1.5749278619503364\n",
      "Loss 1.5746150054056434\n",
      "Loss 1.5744237512350083\n",
      "Loss 1.5736961478804365\n",
      "Loss 1.573328993320465\n",
      "Loss 1.5729868069901525\n",
      "Loss 1.5723997712419147\n",
      "Loss 1.5724847823872286\n",
      "Loss 1.5723116555602052\n",
      "Loss 1.5717601863611703\n",
      "Loss 1.5712421746077863\n",
      "Loss 1.5706592492106255\n",
      "Loss 1.5705818016462856\n",
      "Loss 1.569708588038172\n",
      "Loss 1.5690264819238497\n",
      "Loss 1.56811121076025\n",
      "Loss 1.5673933547608396\n",
      "Loss 1.5669668189977344\n",
      "Loss 1.5669112935910623\n",
      "Loss 1.5676860218195572\n",
      "Loss 1.5681441761401236\n",
      "Loss 1.5681993172204856\n",
      "Loss 1.568662499910593\n",
      "Loss 1.5690475435068112\n",
      "Loss 1.5693905586997667\n",
      "Loss 1.569874567690405\n",
      "Loss 1.570121633175474\n",
      "Loss 1.570979390178408\n",
      "Loss 1.5707201770847699\n",
      "Loss 1.5708264270229875\n",
      "Loss 1.5708669903322503\n",
      "Loss 1.5713114775430173\n",
      "Loss 1.5716747281551362\n",
      "Loss 1.5722782232739905\n",
      "Loss 1.57227680030678\n",
      "Loss 1.572580204463638\n",
      "Loss 1.5735249869133296\n",
      "Loss 1.5735839936214944\n",
      "Loss 1.573503011238986\n",
      "Loss 1.5734939371622525\n",
      "Loss 1.5735469532972675\n",
      "Loss 1.573940402935533\n",
      "Loss 1.5745660155763228\n",
      "Loss 1.5747829660600867\n",
      "Loss 1.5751696958893635\n",
      "Loss 1.574834405857373\n",
      "Loss 1.5750852552873473\n",
      "Loss 1.574999915318489\n",
      "Loss 1.574934282468425\n",
      "Loss 1.5748659056049632\n",
      "Loss 1.5748354789474979\n",
      "Loss 1.5749550824433334\n",
      "Loss 1.5748159966698059\n",
      "Loss 1.5749165689444724\n",
      "Loss 1.5750904220116861\n",
      "Loss 1.575163267989804\n",
      "Loss 1.5751093811997727\n",
      "Epoch 21/25, Loss: 1.5752\n",
      "Loss 1.6172538554668427\n",
      "Loss 1.622919381260872\n",
      "Loss 1.617897930542628\n",
      "Loss 1.6062937265634536\n",
      "Loss 1.596053615450859\n",
      "Loss 1.5917279296120008\n",
      "Loss 1.589082287464823\n",
      "Loss 1.5813932775706052\n",
      "Loss 1.5716135860151714\n",
      "Loss 1.5688482897877694\n",
      "Loss 1.5688137263059616\n",
      "Loss 1.5696216500302156\n",
      "Loss 1.5685217071038027\n",
      "Loss 1.5702170797330992\n",
      "Loss 1.5689849361181258\n",
      "Loss 1.5683022459223865\n",
      "Loss 1.571290254557834\n",
      "Loss 1.5722547262575892\n",
      "Loss 1.5757844334213358\n",
      "Loss 1.5756203818321228\n",
      "Loss 1.5731923301447006\n",
      "Loss 1.5750523729757828\n",
      "Loss 1.5789657498442609\n",
      "Loss 1.5836294089009364\n",
      "Loss 1.585643377327919\n",
      "Loss 1.5852280004895651\n",
      "Loss 1.5866084047379316\n",
      "Loss 1.5862343770478453\n",
      "Loss 1.5844318289386814\n",
      "Loss 1.5857133323550223\n",
      "Loss 1.5858465979176184\n",
      "Loss 1.5849740724824368\n",
      "Loss 1.5830345875927896\n",
      "Loss 1.5823188408332713\n",
      "Loss 1.5817272785391125\n",
      "Loss 1.5798895621134175\n",
      "Loss 1.5796815122945889\n",
      "Loss 1.5793078646534369\n",
      "Loss 1.5792967217243634\n",
      "Loss 1.5786454303115607\n",
      "Loss 1.5790537582519577\n",
      "Loss 1.5799633012641043\n",
      "Loss 1.5793041290654692\n",
      "Loss 1.5777251105958765\n",
      "Loss 1.5778338793648614\n",
      "Loss 1.5768970791801162\n",
      "Loss 1.5763513144660504\n",
      "Loss 1.5759845681736866\n",
      "Loss 1.57595387865086\n",
      "Loss 1.5753375174999238\n",
      "Loss 1.57557518844511\n",
      "Loss 1.5755814917500202\n",
      "Loss 1.5750733489135527\n",
      "Loss 1.5762899140075401\n",
      "Loss 1.576761515422301\n",
      "Loss 1.577504821888038\n",
      "Loss 1.5765369836175651\n",
      "Loss 1.575770597242076\n",
      "Loss 1.5742151548599792\n",
      "Loss 1.5745466803411643\n",
      "Loss 1.573671245604265\n",
      "Loss 1.5727621690015638\n",
      "Loss 1.572435254851977\n",
      "Loss 1.57116035557352\n",
      "Loss 1.5701475298312995\n",
      "Loss 1.568763857727701\n",
      "Loss 1.5680782173284844\n",
      "Loss 1.5673048771128935\n",
      "Loss 1.5668058743165887\n",
      "Loss 1.5665808314936502\n",
      "Loss 1.5658326956335928\n",
      "Loss 1.566241662974159\n",
      "Loss 1.5659847795228437\n",
      "Loss 1.5656217073991492\n",
      "Loss 1.5652075782775878\n",
      "Loss 1.5640524124158057\n",
      "Loss 1.5634089707708978\n",
      "Loss 1.5629720189861762\n",
      "Loss 1.5626150606855562\n",
      "Loss 1.5627059130966663\n",
      "Loss 1.561961599735566\n",
      "Loss 1.5615137110977637\n",
      "Loss 1.5610905887850797\n",
      "Loss 1.560636868093695\n",
      "Loss 1.5612155346800298\n",
      "Loss 1.5611309656778047\n",
      "Loss 1.5604742600109385\n",
      "Loss 1.559881872060624\n",
      "Loss 1.5592698027578633\n",
      "Loss 1.55911425614357\n",
      "Loss 1.5583047351142862\n",
      "Loss 1.5575079223707966\n",
      "Loss 1.556712709191025\n",
      "Loss 1.5561454574478433\n",
      "Loss 1.5558692447198064\n",
      "Loss 1.5556831541843712\n",
      "Loss 1.5565203155500373\n",
      "Loss 1.5571411357120593\n",
      "Loss 1.557165644367536\n",
      "Loss 1.5577020302593707\n",
      "Loss 1.5579893440008163\n",
      "Loss 1.558440230722521\n",
      "Loss 1.558902801657186\n",
      "Loss 1.5591765652138454\n",
      "Loss 1.560037613425936\n",
      "Loss 1.5598021907176611\n",
      "Loss 1.559853095924743\n",
      "Loss 1.5599200793935193\n",
      "Loss 1.5603234423136492\n",
      "Loss 1.5606562302600253\n",
      "Loss 1.561125273623982\n",
      "Loss 1.5612037154180662\n",
      "Loss 1.5615055569188785\n",
      "Loss 1.5620864014249098\n",
      "Loss 1.5621071681665337\n",
      "Loss 1.5621024402770503\n",
      "Loss 1.562277365678396\n",
      "Loss 1.5624360318911277\n",
      "Loss 1.5628978893235952\n",
      "Loss 1.5635590088764826\n",
      "Loss 1.5636932472108809\n",
      "Loss 1.564179880946386\n",
      "Loss 1.5638636032643356\n",
      "Loss 1.5639392178673899\n",
      "Loss 1.5637557653427123\n",
      "Loss 1.5636283297056244\n",
      "Loss 1.5634923826944171\n",
      "Loss 1.563418179769069\n",
      "Loss 1.5635272587454596\n",
      "Loss 1.5633768025178176\n",
      "Loss 1.5634065940316397\n",
      "Loss 1.5634972210950924\n",
      "Loss 1.5633909538186583\n",
      "Loss 1.563270488554862\n",
      "Epoch 22/25, Loss: 1.5633\n",
      "Loss 1.5969240963459015\n",
      "Loss 1.611076647043228\n",
      "Loss 1.610143312215805\n",
      "Loss 1.5955816657841206\n",
      "Loss 1.5827004326581955\n",
      "Loss 1.5817521672447523\n",
      "Loss 1.5805522497211184\n",
      "Loss 1.573062962964177\n",
      "Loss 1.5637774934371313\n",
      "Loss 1.560478163599968\n",
      "Loss 1.5595913929830898\n",
      "Loss 1.5610638880729675\n",
      "Loss 1.5596372534220035\n",
      "Loss 1.5612475796682495\n",
      "Loss 1.5596326287984847\n",
      "Loss 1.5593195623531937\n",
      "Loss 1.5622490182694266\n",
      "Loss 1.5627056660585934\n",
      "Loss 1.566085767902826\n",
      "Loss 1.565440423488617\n",
      "Loss 1.56282405489967\n",
      "Loss 1.563519408296455\n",
      "Loss 1.5671430263052817\n",
      "Loss 1.5717263256261746\n",
      "Loss 1.5738984124898912\n",
      "Loss 1.5734020325082998\n",
      "Loss 1.574621041726183\n",
      "Loss 1.5742118321359158\n",
      "Loss 1.5719264330329565\n",
      "Loss 1.5729904250701268\n",
      "Loss 1.573124009005485\n",
      "Loss 1.572112761642784\n",
      "Loss 1.5704688793962651\n",
      "Loss 1.5700347813437967\n",
      "Loss 1.5696690873418535\n",
      "Loss 1.5679150860342714\n",
      "Loss 1.5680643449441807\n",
      "Loss 1.5675482170048514\n",
      "Loss 1.5677394942748242\n",
      "Loss 1.567204305589199\n",
      "Loss 1.5673885726928711\n",
      "Loss 1.5675914894399188\n",
      "Loss 1.5666956873827202\n",
      "Loss 1.5648817884244701\n",
      "Loss 1.5651173287365172\n",
      "Loss 1.564282806619354\n",
      "Loss 1.5640563367782756\n",
      "Loss 1.5635504098981619\n",
      "Loss 1.5633952595506395\n",
      "Loss 1.5628750556349755\n",
      "Loss 1.5628210135300955\n",
      "Loss 1.5629630881777177\n",
      "Loss 1.56255932852907\n",
      "Loss 1.5639668620957268\n",
      "Loss 1.5644824311733245\n",
      "Loss 1.5649471988103218\n",
      "Loss 1.5639040139265228\n",
      "Loss 1.5633744222645103\n",
      "Loss 1.5623336877257137\n",
      "Loss 1.5629255069494248\n",
      "Loss 1.5620254844329395\n",
      "Loss 1.5611977639890486\n",
      "Loss 1.5609065559364501\n",
      "Loss 1.5596570550464093\n",
      "Loss 1.5588463576390192\n",
      "Loss 1.5573759491515882\n",
      "Loss 1.5567867325668905\n",
      "Loss 1.5561479226631276\n",
      "Loss 1.5555030754942825\n",
      "Loss 1.5547873112559318\n",
      "Loss 1.5539032558740025\n",
      "Loss 1.5542340771274434\n",
      "Loss 1.5539769485715318\n",
      "Loss 1.553654388060441\n",
      "Loss 1.5531395216464996\n",
      "Loss 1.5520620908313676\n",
      "Loss 1.5514501400969245\n",
      "Loss 1.5509104276161927\n",
      "Loss 1.5505780285068704\n",
      "Loss 1.550507461681962\n",
      "Loss 1.5499127381230577\n",
      "Loss 1.5494392595494666\n",
      "Loss 1.5490980664936893\n",
      "Loss 1.548519919074717\n",
      "Loss 1.548617302144275\n",
      "Loss 1.548137095154718\n",
      "Loss 1.5475075958515037\n",
      "Loss 1.5468666536970572\n",
      "Loss 1.5466270077295519\n",
      "Loss 1.5466135991480616\n",
      "Loss 1.545887750531291\n",
      "Loss 1.545129322876101\n",
      "Loss 1.544322180946668\n",
      "Loss 1.5436775275113734\n",
      "Loss 1.5431857221942198\n",
      "Loss 1.542916991499563\n",
      "Loss 1.5435614560498405\n",
      "Loss 1.5439949343459947\n",
      "Loss 1.5439727380901875\n",
      "Loss 1.5444886906683446\n",
      "Loss 1.5447855195963738\n",
      "Loss 1.5450823603249064\n",
      "Loss 1.5456030218288737\n",
      "Loss 1.5458591530357415\n",
      "Loss 1.5467348878440403\n",
      "Loss 1.5464623642586313\n",
      "Loss 1.546671614535501\n",
      "Loss 1.5467029080898673\n",
      "Loss 1.5470721679871235\n",
      "Loss 1.5473810622583737\n",
      "Loss 1.547970986720678\n",
      "Loss 1.5481052104117614\n",
      "Loss 1.548451998402587\n",
      "Loss 1.549335865587519\n",
      "Loss 1.549427996236345\n",
      "Loss 1.5493746392839942\n",
      "Loss 1.5493762980108587\n",
      "Loss 1.5495451444639998\n",
      "Loss 1.549975735575211\n",
      "Loss 1.5505843351731698\n",
      "Loss 1.5508675514912802\n",
      "Loss 1.5512646317188856\n",
      "Loss 1.5509108547708852\n",
      "Loss 1.5511220484443249\n",
      "Loss 1.5509228466701508\n",
      "Loss 1.5509971890752279\n",
      "Loss 1.5509528958421992\n",
      "Loss 1.550868420889601\n",
      "Loss 1.5509944799796556\n",
      "Loss 1.5508910549879074\n",
      "Loss 1.550982681476433\n",
      "Loss 1.551078124335318\n",
      "Loss 1.5510211169361172\n",
      "Loss 1.5509086330791018\n",
      "Epoch 23/25, Loss: 1.5509\n",
      "Loss 1.5866630029678346\n",
      "Loss 1.5988164573907853\n",
      "Loss 1.5964389717578888\n",
      "Loss 1.582029619961977\n",
      "Loss 1.5699846402406692\n",
      "Loss 1.5667504784464836\n",
      "Loss 1.5646443433420998\n",
      "Loss 1.5589727878570556\n",
      "Loss 1.5491455966896481\n",
      "Loss 1.5449552832245828\n",
      "Loss 1.5453370297496969\n",
      "Loss 1.5468739819029966\n",
      "Loss 1.5456999639822886\n",
      "Loss 1.547715828716755\n",
      "Loss 1.546281030535698\n",
      "Loss 1.5456937296688558\n",
      "Loss 1.5476011873343412\n",
      "Loss 1.5483393862843513\n",
      "Loss 1.5517650604561755\n",
      "Loss 1.550895635932684\n",
      "Loss 1.5483177444196883\n",
      "Loss 1.5490465598214755\n",
      "Loss 1.5519073942174082\n",
      "Loss 1.5566890945285559\n",
      "Loss 1.5585568816423416\n",
      "Loss 1.5580668061283918\n",
      "Loss 1.5595304458450387\n",
      "Loss 1.559006954154798\n",
      "Loss 1.5570828691227683\n",
      "Loss 1.5585619882146518\n",
      "Loss 1.5591351857108455\n",
      "Loss 1.5585209506563842\n",
      "Loss 1.5566452922965541\n",
      "Loss 1.5559969532840392\n",
      "Loss 1.5553493020704814\n",
      "Loss 1.5537096126212013\n",
      "Loss 1.553763301146997\n",
      "Loss 1.5530948461043208\n",
      "Loss 1.5538091174302957\n",
      "Loss 1.553546454563737\n",
      "Loss 1.5535846191644669\n",
      "Loss 1.553828795509679\n",
      "Loss 1.5531504240146903\n",
      "Loss 1.5512811247327112\n",
      "Loss 1.5513532614707948\n",
      "Loss 1.5505243190863858\n",
      "Loss 1.5502490066847903\n",
      "Loss 1.549777460731566\n",
      "Loss 1.5495139040387407\n",
      "Loss 1.5490487458109856\n",
      "Loss 1.5488844719353845\n",
      "Loss 1.5490159343526912\n",
      "Loss 1.5485109822480183\n",
      "Loss 1.5500053460509688\n",
      "Loss 1.5508213669820266\n",
      "Loss 1.5517629858957869\n",
      "Loss 1.5506390451443823\n",
      "Loss 1.5497122661204175\n",
      "Loss 1.5484883365691717\n",
      "Loss 1.5489212481081487\n",
      "Loss 1.5481462110945436\n",
      "Loss 1.5474461761213119\n",
      "Loss 1.5472117587309036\n",
      "Loss 1.5460691297985614\n",
      "Loss 1.5452088281924907\n",
      "Loss 1.5437943236033123\n",
      "Loss 1.5430950284182137\n",
      "Loss 1.5425331991034394\n",
      "Loss 1.541917750990909\n",
      "Loss 1.5417875124982425\n",
      "Loss 1.541035777540274\n",
      "Loss 1.5418052722927598\n",
      "Loss 1.541523303209919\n",
      "Loss 1.5411752169116124\n",
      "Loss 1.5407266630967458\n",
      "Loss 1.5399361614020248\n",
      "Loss 1.5391953388669275\n",
      "Loss 1.5387472000259619\n",
      "Loss 1.538230190729793\n",
      "Loss 1.5381081579178573\n",
      "Loss 1.5374695132838354\n",
      "Loss 1.5369224552265028\n",
      "Loss 1.536357882008495\n",
      "Loss 1.5360518200056894\n",
      "Loss 1.5362888768841239\n",
      "Loss 1.5360172619791919\n",
      "Loss 1.5353517982740512\n",
      "Loss 1.5349582365087489\n",
      "Loss 1.5345721990740702\n",
      "Loss 1.534330239991347\n",
      "Loss 1.5335824021729794\n",
      "Loss 1.5328144371315189\n",
      "Loss 1.531975119421559\n",
      "Loss 1.5313709015605297\n",
      "Loss 1.5308106835955069\n",
      "Loss 1.530507557777067\n",
      "Loss 1.5309846797370419\n",
      "Loss 1.531416417773889\n",
      "Loss 1.531340903904703\n",
      "Loss 1.5318198644518852\n",
      "Loss 1.532077905630121\n",
      "Loss 1.5324745988027721\n",
      "Loss 1.5330208327816528\n",
      "Loss 1.5332189913609853\n",
      "Loss 1.5341060146490733\n",
      "Loss 1.5338783572136232\n",
      "Loss 1.5340865692245627\n",
      "Loss 1.534159758951929\n",
      "Loss 1.5346572530925822\n",
      "Loss 1.5351338993744417\n",
      "Loss 1.5355422540720518\n",
      "Loss 1.5355882200332625\n",
      "Loss 1.5358797746791248\n",
      "Loss 1.5365627242337194\n",
      "Loss 1.5366506791218468\n",
      "Loss 1.5365108824187312\n",
      "Loss 1.536629831408843\n",
      "Loss 1.5367967072432325\n",
      "Loss 1.5372636644379432\n",
      "Loss 1.537813428501288\n",
      "Loss 1.5380792239234466\n",
      "Loss 1.5382997238538305\n",
      "Loss 1.5379409868300447\n",
      "Loss 1.5381807065923367\n",
      "Loss 1.5380430646324157\n",
      "Loss 1.5382000343903663\n",
      "Loss 1.5379954594279837\n",
      "Loss 1.5380389867536723\n",
      "Loss 1.5381829048681628\n",
      "Loss 1.5381186811969831\n",
      "Loss 1.5382766478616772\n",
      "Loss 1.5383436770014691\n",
      "Loss 1.538260189016959\n",
      "Loss 1.5381481557506234\n",
      "Epoch 24/25, Loss: 1.5382\n",
      "Loss 1.5623391890525817\n",
      "Loss 1.5776960802078248\n",
      "Loss 1.5789846058686574\n",
      "Loss 1.5711452899873257\n",
      "Loss 1.5587886660099028\n",
      "Loss 1.5578617133696875\n",
      "Loss 1.557341871857643\n",
      "Loss 1.5493307232111693\n",
      "Loss 1.5408880822526083\n",
      "Loss 1.5358494030237198\n",
      "Loss 1.5348474303158848\n",
      "Loss 1.5363859481116136\n",
      "Loss 1.5357512186582272\n",
      "Loss 1.5369360444801194\n",
      "Loss 1.534616888721784\n",
      "Loss 1.5342661530524493\n",
      "Loss 1.5367810309985104\n",
      "Loss 1.5371974771883752\n",
      "Loss 1.540922509902402\n",
      "Loss 1.5401596868932248\n",
      "Loss 1.537414772084781\n",
      "Loss 1.538782642185688\n",
      "Loss 1.5418081236144772\n",
      "Loss 1.5462293245146672\n",
      "Loss 1.5495497584104538\n",
      "Loss 1.5490263121173933\n",
      "Loss 1.5499799447368692\n",
      "Loss 1.549422384138618\n",
      "Loss 1.5476342168964188\n",
      "Loss 1.549381562014421\n",
      "Loss 1.5494528943684793\n",
      "Loss 1.5489603381603956\n",
      "Loss 1.5473328706351193\n",
      "Loss 1.546396400472697\n",
      "Loss 1.5452831307819912\n",
      "Loss 1.5441847254832586\n",
      "Loss 1.5441011836399903\n",
      "Loss 1.5433854059482877\n",
      "Loss 1.5437406012797967\n",
      "Loss 1.5434263003617525\n",
      "Loss 1.544105521600421\n",
      "Loss 1.5444767420490584\n",
      "Loss 1.5436644337898078\n",
      "Loss 1.5418559609895404\n",
      "Loss 1.5420810022486582\n",
      "Loss 1.5410761905234793\n",
      "Loss 1.5409133391684675\n",
      "Loss 1.5402928330376744\n",
      "Loss 1.539888661236179\n",
      "Loss 1.5393429738640785\n",
      "Loss 1.5392458737597745\n",
      "Loss 1.5391703220055653\n",
      "Loss 1.5385754321656138\n",
      "Loss 1.5401217314711324\n",
      "Loss 1.5406136121533134\n",
      "Loss 1.5413964916339942\n",
      "Loss 1.540398249772557\n",
      "Loss 1.5401551606326267\n",
      "Loss 1.5389447538630436\n",
      "Loss 1.5394260698954265\n",
      "Loss 1.5385852530061221\n",
      "Loss 1.537854523697207\n",
      "Loss 1.5374914098921277\n",
      "Loss 1.5363479627668857\n",
      "Loss 1.535498696400569\n",
      "Loss 1.5342015389962629\n",
      "Loss 1.5336690589207322\n",
      "Loss 1.5330765434924294\n",
      "Loss 1.5326013406722443\n",
      "Loss 1.5322044946040425\n",
      "Loss 1.5320897263036648\n",
      "Loss 1.5323899490965738\n",
      "Loss 1.5321883868844541\n",
      "Loss 1.5317425717292605\n",
      "Loss 1.5311995380719503\n",
      "Loss 1.5302567270006004\n",
      "Loss 1.529266394299346\n",
      "Loss 1.5287590646896607\n",
      "Loss 1.5282698526638974\n",
      "Loss 1.528301847308874\n",
      "Loss 1.52766699190493\n",
      "Loss 1.5269293482347233\n",
      "Loss 1.5265070460575172\n",
      "Loss 1.5259926402568817\n",
      "Loss 1.5259513140636332\n",
      "Loss 1.5257097453918569\n",
      "Loss 1.5250216469956541\n",
      "Loss 1.5244035919281569\n",
      "Loss 1.5239196531223447\n",
      "Loss 1.5238048702279727\n",
      "Loss 1.5229062897949428\n",
      "Loss 1.5220944217171357\n",
      "Loss 1.521188402098994\n",
      "Loss 1.5206224159357395\n",
      "Loss 1.5200056447794563\n",
      "Loss 1.5196891563696167\n",
      "Loss 1.520261871003613\n",
      "Loss 1.5206891821902626\n",
      "Loss 1.5206099815139866\n",
      "Loss 1.5209771578371525\n",
      "Loss 1.5212543500768076\n",
      "Loss 1.5217923644301938\n",
      "Loss 1.522153962752194\n",
      "Loss 1.5222780406647003\n",
      "Loss 1.5232698061693282\n",
      "Loss 1.5229464400208221\n",
      "Loss 1.5230690822645883\n",
      "Loss 1.5232147018114726\n",
      "Loss 1.5236894768804585\n",
      "Loss 1.5242879289442843\n",
      "Loss 1.5247866091588596\n",
      "Loss 1.5248767791262694\n",
      "Loss 1.525136564331772\n",
      "Loss 1.5260095848273814\n",
      "Loss 1.5261935525355133\n",
      "Loss 1.5259681026277871\n",
      "Loss 1.525972458017178\n",
      "Loss 1.52612006236436\n",
      "Loss 1.5265674162712417\n",
      "Loss 1.5270892229874928\n",
      "Loss 1.5272624961748595\n",
      "Loss 1.5276623950141375\n",
      "Loss 1.5273071422567213\n",
      "Loss 1.5277329022076822\n",
      "Loss 1.5275914524841308\n",
      "Loss 1.527505147154369\n",
      "Loss 1.527325258780652\n",
      "Loss 1.527365909316577\n",
      "Loss 1.5275297409480857\n",
      "Loss 1.527397615469419\n",
      "Loss 1.5275332921515894\n",
      "Loss 1.527581735343644\n",
      "Loss 1.5274354000243926\n",
      "Loss 1.5272501010770227\n",
      "Epoch 25/25, Loss: 1.5273\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(seq2seq, train_pairs_final, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76c0d5-451d-45ea-b3e7-fcaacf9e91a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
